{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recordings segments loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from functools import reduce\n",
    "\n",
    "# is_single_speaker_segment [VALIDATED]\n",
    "# validates if a segment has a single speaker who belongs to the speakers list. \n",
    "def is_single_speaker_segment(segment, valid_speakers_ids = ['A', 'B']):\n",
    "    return len(segment['speakers']) == 1 and segment['speakers'][0]['speaker_id'] in valid_speakers_ids\n",
    "\n",
    "# is_valid_segment [VALIDATED]\n",
    "# validates if a segment meets a maximum number of speakers,\n",
    "# and that all the speakers in the segment belong to a list.\n",
    "def is_valid_segment(segment, maximum_speakers_length = 2, valid_speakers_ids = ['A', 'B']):\n",
    "    speakers_ids = [speaker['speaker_id'] for speaker in segment['speakers']]\n",
    "    speakers_ids = list(set(speakers_ids))\n",
    "    return len(speakers_ids) <= maximum_speakers_length and \\\n",
    "        all(speaker_id in valid_speakers_ids for speaker_id in speakers_ids)\n",
    "\n",
    "# load_recordings_segments [VALIDATED]\n",
    "# loads the recordings segments data from the .json files located in a directory \n",
    "def load_recordings_segments(directory, validation_function):\n",
    "    filenames = [filename for filename in os.listdir(directory) if os.path.isfile(os.path.join(directory, filename))]\n",
    "    filenames.sort()\n",
    "    recordings_segments = {}\n",
    "    recordings_length = len(filenames)\n",
    "    recordings_count = 0\n",
    "    segments_original = 0\n",
    "    segments_filtered = 0\n",
    "    for filename in filenames:\n",
    "        recording_id = filename.split('.')[0]\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        file = open(filepath, 'r')\n",
    "        recordings_segments[recording_id] = [json.loads(line) for line in file.readlines()]\n",
    "        file.close()\n",
    "        segments_original += len(recordings_segments[recording_id])\n",
    "        recordings_segments[recording_id] = list(filter(validation_function, recordings_segments[recording_id]))\n",
    "        segments_filtered += len(recordings_segments[recording_id])\n",
    "        recordings_count += 1\n",
    "        print(directory + ' loading ' + str(recordings_count) + '/' + str(recordings_length), end = '\\r')\n",
    "    print(directory, 'loaded', str(recordings_count) + '/' + str(recordings_length) + ',', round(segments_filtered / segments_original, 2), 'segments left.')\n",
    "    return recordings_segments\n",
    "\n",
    "# speakers_get_indexes [VALIDATED]\n",
    "# used to convert a (speakers_ids, index) list to a speakers_ids => [indexes] dictionary\n",
    "def speakers_get_indexes(accumulator, speakers_tuple):\n",
    "    speaker_ids, index = speakers_tuple\n",
    "    speaker_ids = ','.join(speaker_ids)\n",
    "    if speaker_ids in accumulator:\n",
    "        accumulator[speaker_ids].append(index)\n",
    "    else:\n",
    "        accumulator[speaker_ids] = [index]\n",
    "    return accumulator\n",
    "\n",
    "# balance_segments [VALIDATED]\n",
    "# balances the recording segments data to meet a minimum of speakers per recording,\n",
    "# and a minimum of segments per speaker.\n",
    "def balance_segments(recordings_segments,\n",
    "                     minimum_speakers_length = 2,\n",
    "                     minimum_speaker_segments = 3,\n",
    "                     include_overlaps = False):\n",
    "    new_recordings_segments = {}\n",
    "    for recording_id in recordings_segments:\n",
    "        recording_segments = recordings_segments[recording_id]\n",
    "        # ----- Obtaining speakers indexes ----- #\n",
    "        speakers_indexes = [(sorted(list(set([speaker['speaker_id'] for speaker in segment['speakers']]))), index) for index, segment in enumerate(recording_segments)]\n",
    "        speakers_indexes = reduce(speakers_get_indexes, speakers_indexes, {})\n",
    "        # ----- Removing overlaps ----- #\n",
    "        if not include_overlaps:\n",
    "            for speakers_ids in list(speakers_indexes.keys()):\n",
    "                if len(speakers_ids.split(',')) > 1:\n",
    "                    del speakers_indexes[speakers_ids]\n",
    "        speakers_lengths = [(speakers_ids, len(speakers_indexes[speakers_ids])) for speakers_ids in speakers_indexes]\n",
    "        speakers_lengths.sort(key = lambda x: x[1])\n",
    "        speakers_lengths_min = speakers_lengths[0][1]\n",
    "        if len(speakers_lengths) >= minimum_speakers_length and speakers_lengths_min >= minimum_speaker_segments:\n",
    "            recording_indexes = []\n",
    "            for speakers_ids in speakers_indexes:\n",
    "                speakers_indexes[speakers_ids] = speakers_indexes[speakers_ids][:speakers_lengths_min]\n",
    "                recording_indexes += speakers_indexes[speakers_ids]\n",
    "            new_recordings_segments[recording_id] = [segment for index, segment in enumerate(recordings_segments[recording_id]) if index in recording_indexes]\n",
    "    print('Recordings left: ' + str(len(new_recordings_segments)) + '/' + str(len(recordings_segments)))\n",
    "    return new_recordings_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recordings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def generate_speaker_model(speakers_segments_indexes,\n",
    "                           recordings_segments,\n",
    "                           segments_length,\n",
    "                           vector = 'ivectors',\n",
    "                           selection = 'first',\n",
    "                           indexes = []):\n",
    "    if selection == 'first':\n",
    "        selected_segments = [recordings_segments[recording_id][index] for recording_id, index, real in speakers_segments_indexes[:segments_length]]\n",
    "    elif selection == 'random':\n",
    "        selected_segments = [recordings_segments[recording_id][index] for recording_id, index, real in random.sample(speakers_segments_indexes, segments_length if segments_length < len(speakers_segments_indexes) else len(speakers_segments_indexes))]\n",
    "    else:\n",
    "        print('ERROR: unknown speaker model segments selection strategy.')\n",
    "    selected_vectors = [np.asarray(segment[vector][0]['value']) for segment in selected_segments]\n",
    "    return np.sum(selected_vectors, 0) / len(selected_vectors)\n",
    "\n",
    "def get_speakers_segments_indexes(acc, recording_id_index_real, recordings_segments):\n",
    "    recording_id, index, real = recording_id_index_real\n",
    "    segment = recordings_segments[recording_id][index]\n",
    "    speakers_ids = ','.join(sorted([speaker['speaker_id'] for speaker in segment['speakers']]))\n",
    "    if speakers_ids not in acc:\n",
    "        acc[speakers_ids] = []\n",
    "    acc[speakers_ids].append(recording_id_index_real)\n",
    "    return acc\n",
    "\n",
    "class Recordings_dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 recordings_segments,\n",
    "                 recordings_ids = None,\n",
    "                 vector = 'ivectors',\n",
    "                 models_container_length = 2,\n",
    "                 models_container_include_zeros = True,\n",
    "                 models_container_include_overlaps = False,\n",
    "                 models_generation_lengths = [3],\n",
    "                 models_generation_selection = 'first',\n",
    "                 include_false_segments = 'models'):\n",
    "        # ----- Saving the recordings ids ----- #\n",
    "        if recordings_ids is None:\n",
    "            recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "        self.recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids] \n",
    "        # ----- Saving the recordings segments ----- #\n",
    "        self.recordings_segments = recordings_segments\n",
    "        # ----- Saving the arguments ----- #\n",
    "        self.vector = vector\n",
    "        self.models_container_length = models_container_length\n",
    "        self.models_container_include_zeros = models_container_include_zeros\n",
    "        self.models_container_include_overlaps = models_container_include_overlaps\n",
    "        self.models_generation_lengths = models_generation_lengths\n",
    "        self.models_generation_selection = models_generation_selection\n",
    "        self.include_false_segments = include_false_segments\n",
    "        \n",
    "        self.recordings_data = {}\n",
    "        self.recordings_models = {}\n",
    "        \n",
    "        # ----- Initializing the recordings data ----- #\n",
    "        for recording_id in self.recordings_ids:\n",
    "            self.recordings_data[recording_id] = {}\n",
    "        \n",
    "        # ----- Saving the recordings segments indexes ----- #\n",
    "        for recording_id in self.recordings_data:\n",
    "            recording_data = self.recordings_data[recording_id]\n",
    "            recording_data['recording_segments_indexes'] = [(recording_id, index, True) for index, segment in enumerate(self.recordings_segments[recording_id])]\n",
    "            \n",
    "        # ----- Obtaining the recordings speakers segments indexes ----- #\n",
    "        for recording_id in self.recordings_data:\n",
    "            recording_data = self.recordings_data[recording_id]\n",
    "            recording_data['speakers_segments_indexes'] = reduce(lambda acc, recording_id_index_real: get_speakers_segments_indexes(acc, recording_id_index_real, self.recordings_segments), recording_data['recording_segments_indexes'], {})\n",
    "            # ----- Obtaining the max speaker segments length ----- #\n",
    "            recording_data['speakers_segments_indexes_lengths_max'] = max([len(recording_data['speakers_segments_indexes'][speakers_ids]) for speakers_ids in recording_data['speakers_segments_indexes']])\n",
    "      \n",
    "        # ----- Generating the recordings speakers models ----- #\n",
    "        for recording_id in self.recordings_data:\n",
    "            self.recordings_models[recording_id] = []\n",
    "            recording_data = self.recordings_data[recording_id]\n",
    "            recording_data['speakers_models'] = {}\n",
    "            for speakers_ids in recording_data['speakers_segments_indexes']:\n",
    "                recording_data['speakers_models'][speakers_ids] = {}\n",
    "                for models_generation_length in models_generation_lengths:\n",
    "                    speakers_model = generate_speaker_model(recording_data['speakers_segments_indexes'][speakers_ids], self.recordings_segments, models_generation_length, self.vector, self.models_generation_selection)\n",
    "                    model_segment = {}\n",
    "                    model_segment[vector] = [{ 'value': speakers_model }]\n",
    "                    model_segment['speakers'] = [{ 'speaker_id': speakers_ids }]\n",
    "                    self.recordings_models[recording_id].append(model_segment)\n",
    "                    recording_data['speakers_models'][speakers_ids][models_generation_length] = [speakers_model]\n",
    "        \n",
    "        # ----- Generating the recordings speakers models permutations ----- #\n",
    "        for recording_id in self.recordings_data:\n",
    "            recording_data = self.recordings_data[recording_id]\n",
    "            if self.models_container_include_zeros:\n",
    "                recording_data['permutations'] = list(itertools.permutations(list(recording_data['speakers_models'].keys()) + ['0' for _ in range(self.models_container_length)], self.models_container_length))\n",
    "            else:\n",
    "                recording_data['permutations'] = list(itertools.permutations(list(recording_data['speakers_models'].keys()), self.models_container_length))\n",
    "            recording_data['permutations'] = sorted(set(recording_data['permutations']))\n",
    "            if not self.models_container_include_overlaps:\n",
    "                recording_data['permutations'] = [permutation for permutation in recording_data['permutations'] if all(len(speakers_ids.split(',')) == 1 for speakers_ids in permutation)]\n",
    "\n",
    "        # ----- Generatign false segments ----- #\n",
    "        if self.include_false_segments == 'segments':\n",
    "            for recording_id in self.recordings_data:\n",
    "                recording_data = self.recordings_data[recording_id]\n",
    "                other_recordings_segments_indexes = []\n",
    "                for other_recording_id in self.recordings_segments:\n",
    "                    if other_recording_id != recording_id:\n",
    "                        other_recordings_segments_indexes += [(other_recording_id, index, False) for index, segment in enumerate(self.recordings_segments[other_recording_id])]\n",
    "                if len(other_recordings_segments_indexes) >= recording_data['speakers_segments_indexes_lengths_max']:\n",
    "                    other_recordings_segments_indexes = random.sample(other_recordings_segments_indexes, recording_data['speakers_segments_indexes_lengths_max'])\n",
    "                    options = [recording_data['recording_segments_indexes'], other_recordings_segments_indexes]\n",
    "                    options_lengths = [len(option) for option in options]\n",
    "                    new_recording_segments_indexes = []\n",
    "                    while sum(options_lengths) > 0:\n",
    "                        options_indexes = list(itertools.chain(*[[index] * len(option) for index, option in enumerate(options)]))\n",
    "                        option_index = random.choice(options_indexes)\n",
    "                        new_recording_segments_indexes.append(options[option_index].pop(0))\n",
    "                        options_lengths = [len(option) for option in options]\n",
    "                    recording_data['recording_segments_indexes'] = new_recording_segments_indexes\n",
    "        elif self.include_false_segments == 'models':\n",
    "            for recording_id in self.recordings_data:\n",
    "                recording_data = self.recordings_data[recording_id]\n",
    "                other_recordings_segments_indexes = []\n",
    "                for other_recording_id in self.recordings_models:\n",
    "                    if other_recording_id != recording_id:\n",
    "                        other_recordings_segments_indexes += [(other_recording_id, index, False) for index, segment in enumerate(self.recordings_models[other_recording_id])]\n",
    "                other_recordings_segments_indexes = random.sample(other_recordings_segments_indexes, int(0.5 * recording_data['speakers_segments_indexes_lengths_max'] if recording_data['speakers_segments_indexes_lengths_max'] < len(other_recordings_segments_indexes) else len(other_recordings_segments_indexes)))\n",
    "                \n",
    "                options = [recording_data['recording_segments_indexes'], other_recordings_segments_indexes]\n",
    "                options_lengths = [len(option) for option in options]\n",
    "                new_recording_segments_indexes = []\n",
    "                while sum(options_lengths) > 0:\n",
    "                    options_indexes = list(itertools.chain(*[[index] * len(option) for index, option in enumerate(options)]))\n",
    "                    option_index = random.choice(options_indexes)\n",
    "                    new_recording_segments_indexes.append(options[option_index].pop(0))\n",
    "                    options_lengths = [len(option) for option in options]\n",
    "                recording_data['recording_segments_indexes'] = new_recording_segments_indexes\n",
    "                \n",
    "        # ----- Obtaining the dataset length ----- #\n",
    "        self.recordings_length = 0\n",
    "        self.recordings_map = []\n",
    "        for recording_id in self.recordings_data:\n",
    "            recording_data = self.recordings_data[recording_id]\n",
    "            recording_data['permutations_map'] = []\n",
    "            recording_data['permutations_length'] = 0\n",
    "            for index, permutation in enumerate(recording_data['permutations']):\n",
    "                speakers_models_length = int(np.prod([np.sum([len(recording_data['speakers_models'][speakers_ids][models_generation_length]) for models_generation_length in recording_data['speakers_models'][speakers_ids]]) for speakers_ids in permutation if speakers_ids != '0']))\n",
    "                recording_data['permutations_map'].append((recording_data['permutations_length'], recording_data['permutations_length'] + speakers_models_length - 1, index))\n",
    "                recording_data['permutations_length'] += speakers_models_length\n",
    "            recording_data['length'] = len(recording_data['recording_segments_indexes']) * recording_data['permutations_length']\n",
    "            self.recordings_map.append((self.recordings_length, self.recordings_length + recording_data['length'] - 1, recording_id))\n",
    "            self.recordings_length += recording_data['length']\n",
    "    def __len__(self):\n",
    "        return self.recordings_length\n",
    "    def __getitem__(self, idx):\n",
    "        recording_limits = list(filter(lambda recording_limits: recording_limits[0] <= idx and idx <= recording_limits[1], self.recordings_map))[0]\n",
    "        recording_idx = idx - recording_limits[0]\n",
    "        recording_id = recording_limits[2]\n",
    "        recording_data = self.recordings_data[recording_id]\n",
    "        \n",
    "        segment_id, segment_idx = divmod(recording_idx, recording_data['permutations_length'])\n",
    "        segment_recording_id, segment_index, segment_real = recording_data['recording_segments_indexes'][segment_id]\n",
    "        if not segment_real and self.include_false_segments == 'models':\n",
    "            segment = self.recordings_models[segment_recording_id][segment_index]\n",
    "        else:\n",
    "            segment = self.recordings_segments[segment_recording_id][segment_index]\n",
    "        vector = np.asarray(segment[self.vector][0]['value'])\n",
    "        \n",
    "        permutation_limits = list(filter(lambda permutation_limits: permutation_limits[0] <= segment_idx and segment_idx <= permutation_limits[1], recording_data['permutations_map']))[0]\n",
    "        permutation_idx = segment_idx - permutation_limits[0]\n",
    "        permutation_index = permutation_limits[2]\n",
    "        permutation = recording_data['permutations'][permutation_index]\n",
    "        \n",
    "        speakers_models_lengths = [np.sum([len(recording_data['speakers_models'][speakers_ids][models_generation_length]) for models_generation_length in recording_data['speakers_models'][speakers_ids]])  if speakers_ids != '0' else 1 for speakers_ids in permutation]\n",
    "        models_container = []\n",
    "        model_index = permutation_idx\n",
    "        for i, length_i in enumerate(speakers_models_lengths):\n",
    "            if i != len(speakers_models_lengths) - 1:\n",
    "                model_index, remainder = divmod(model_index, np.sum(speakers_models_lengths[i + 1:]))\n",
    "            else:\n",
    "                model_index = remainder\n",
    "            models_container.append(recording_data['speakers_models'][permutation[i]][self.models_generation_lengths[model_index]][0] if permutation[i] != '0' else np.random.uniform(-0.1, 0.1, len(vector)))\n",
    "        \n",
    "        models_weigths = np.asarray([len(recording_data['speakers_segments_indexes'][speakers_ids]) if speakers_ids != '0' else recording_data['speakers_segments_indexes_lengths_max'] for speakers_ids in permutation])\n",
    "        models_weigths_sum = np.sum(models_weigths)\n",
    "        models_weigths = np.ones(len(models_weigths)) - models_weigths / models_weigths_sum\n",
    "        \n",
    "        targets_ids = [speaker['speaker_id'] for speaker in segment['speakers']]\n",
    "        \n",
    "        x = [vector] + models_container\n",
    "        if segment_real:\n",
    "            if self.models_container_include_overlaps:\n",
    "                targets_ids = ','.join(sorted(list(set(targets_ids))))\n",
    "                y = np.asarray([speakers_ids == targets_ids for speakers_ids in permutation], dtype = float)\n",
    "            else:\n",
    "                y = np.asarray([speaker_id in targets_ids for speaker_id in permutation], dtype = float) / len(targets_ids)\n",
    "        else:\n",
    "            y = np.zeros(len(permutation))\n",
    "        z = models_weigths\n",
    "\n",
    "        return x, y, z, segment_real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load live_graph.py\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Live_graph:\n",
    "    def __init__(self, validation_threshold):\n",
    "        self.plt_count = -1\n",
    "        self.validation_threshold = validation_threshold\n",
    "        self.plt_thr = ([self.plt_count], [self.validation_threshold])\n",
    "        self.plt_loss = ([self.plt_count], [1])\n",
    "        self.plt_valid = ([self.plt_count], [1])\n",
    "        self.plt_test = ([self.plt_count], [1])\n",
    "        self.fig = plt.figure()\n",
    "        self.ax = self.fig.add_subplot()\n",
    "        self.line0, = self.ax.plot(self.plt_thr[0], self.plt_thr[1], 'k--', label = 'Threshold') # Threshold line\n",
    "        self.line1, = self.ax.plot(self.plt_loss[0], self.plt_loss[1], '--', label = 'Training') # Training loss\n",
    "        self.line2, = self.ax.plot(self.plt_valid[0], self.plt_valid[1], label = 'Validation')   # Validation loss\n",
    "        self.line3, = self.ax.plot(self.plt_test[0], self.plt_test[1], label = 'Test')           # Test loss\n",
    "        self.ax.set_xlabel('Epoch')\n",
    "        self.ax.set_ylabel('Loss')\n",
    "        self.ax.legend()\n",
    "        self.ax.set_xlim(-1, 0)\n",
    "        self.ax.set_ylim(0, 0.5)\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.canvas.flush_events()\n",
    "    def step(self, training, validation, test = -1):\n",
    "        self.plt_count += 1\n",
    "        self.plt_thr[0].append(self.plt_count)\n",
    "        self.plt_thr[1].append(self.validation_threshold)\n",
    "        self.plt_loss[0].append(self.plt_count)\n",
    "        self.plt_loss[1].append(training)\n",
    "        self.plt_valid[0].append(self.plt_count)\n",
    "        self.plt_valid[1].append(validation)\n",
    "        self.plt_test[0].append(self.plt_count)\n",
    "        self.plt_test[1].append(test)\n",
    "        self.line0.set_xdata(self.plt_thr[0])\n",
    "        self.line0.set_ydata(self.plt_thr[1])\n",
    "        self.line1.set_xdata(self.plt_loss[0])\n",
    "        self.line1.set_ydata(self.plt_loss[1])\n",
    "        self.line2.set_xdata(self.plt_valid[0])\n",
    "        self.line2.set_ydata(self.plt_valid[1])\n",
    "        self.line3.set_xdata(self.plt_test[0])\n",
    "        self.line3.set_ydata(self.plt_test[1])\n",
    "        self.ax.set_xlim(0, self.plt_count + 1)\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.canvas.flush_events()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, models_container_length, vector_length):\n",
    "        super().__init__()\n",
    "        n = models_container_length\n",
    "        m = vector_length\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv1d((n + 1), n ** 3, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(n ** 3, n ** 2, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(n ** 2, n, 3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear((m - 6) * n, n * 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n * 32, n * 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n * 16, n),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = torch.stack(input, 1)\n",
    "        x = self.cnn1(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self):\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device('cuda:0')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "    def get_net(self,\n",
    "                recordings_segments,\n",
    "                recordings_ids = None,\n",
    "                vector = 'ivectors',\n",
    "                vector_length = 128,\n",
    "                models_container_length = 2,\n",
    "                models_container_include_zeros = True,\n",
    "                models_container_include_overlaps = False,\n",
    "                models_generation_lengths = [3],\n",
    "                models_generation_selection = 'first',\n",
    "                balance_segments = True,\n",
    "                balance_segments_selection = 'copy',\n",
    "                batch_size = 16,\n",
    "                num_workers = 8,\n",
    "                test_recordings_segments = None):\n",
    "        \n",
    "        if recordings_ids is None:\n",
    "            recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "        self.recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "        \n",
    "        train_length = int(len(self.recordings_ids) * 0.7)\n",
    "        valid_length = len(self.recordings_ids) - train_length\n",
    "        \n",
    "        valid_recordings_ids = sorted(random.sample(self.recordings_ids, valid_length))\n",
    "        train_recordings_ids = [recording_id for recording_id in self.recordings_ids if recording_id not in valid_recordings_ids]\n",
    "\n",
    "        train_dataset = Recordings_dataset(recordings_segments,\n",
    "                                           train_recordings_ids, \n",
    "                                           vector,\n",
    "                                           models_container_length,\n",
    "                                           models_container_include_zeros,\n",
    "                                           models_container_include_overlaps,\n",
    "                                           models_generation_lengths,\n",
    "                                           models_generation_selection)\n",
    "        \n",
    "        valid_dataset = Recordings_dataset(recordings_segments,\n",
    "                                           valid_recordings_ids, \n",
    "                                           vector,\n",
    "                                           models_container_length,\n",
    "                                           models_container_include_zeros,\n",
    "                                           models_container_include_overlaps,\n",
    "                                           models_generation_lengths,\n",
    "                                           models_generation_selection)\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers = num_workers)\n",
    "        valid_dataloader = DataLoader(valid_dataset, batch_size = batch_size, shuffle=True, num_workers = num_workers)\n",
    "        \n",
    "        if test_recordings_segments is not None:\n",
    "            test_recordings_ids = [recording_id for recording_id in test_recordings_segments]\n",
    "            test_dataset = Recordings_dataset(test_recordings_segments,\n",
    "                                              test_recordings_ids,\n",
    "                                              vector,\n",
    "                                              models_container_length,\n",
    "                                              models_container_include_zeros,\n",
    "                                              models_container_include_overlaps,\n",
    "                                              models_generation_lengths,\n",
    "                                              models_generation_selection)\n",
    "            test_dataloader = DataLoader(test_dataset, batch_size = batch_size, num_workers = num_workers)\n",
    "\n",
    "        net = Net(models_container_length, vector_length).to(self.device)\n",
    "        optimizer = optim.Adam(net.parameters(), lr = 0.0001)\n",
    "\n",
    "        epochs = 20\n",
    "        validation_threshold = 0.03\n",
    "\n",
    "        live_graph = Live_graph(validation_threshold)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_losses = []\n",
    "            for input, target, weigth, segment_real in train_dataloader:\n",
    "                input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                target = target.to(self.device, non_blocking = True).float()\n",
    "                weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                criterion = nn.BCELoss(weigth)\n",
    "                net.zero_grad()\n",
    "                output = net(input)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_losses.append(loss.data)\n",
    "                print('train: ' + str(len(train_losses)) + '/' + str(len(train_dataloader)) + '          ', end = '\\r')\n",
    "            train_loss = np.sum(train_losses) / len(train_losses)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                validation_losses = []\n",
    "                for input, target, weigth, segment_real in valid_dataloader:\n",
    "                    input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                    target = target.to(self.device, non_blocking = True).float()\n",
    "                    weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                    criterion = nn.BCELoss(weigth)\n",
    "                    output = net(input)\n",
    "                    loss = criterion(output, target)\n",
    "                    validation_losses.append(loss.data)\n",
    "                    print('validation: ' + str(len(validation_losses)) + '/' + str(len(valid_dataloader)) + '          ', end = '\\r')\n",
    "                validation_loss = np.sum(validation_losses) / len(validation_losses)\n",
    "                \n",
    "                test_loss = -1\n",
    "                if test_recordings_segments is not None:\n",
    "                    test_losses = []\n",
    "                    for input, target, weigth in test_dataloader:\n",
    "                        input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                        target = target.to(self.device, non_blocking = True).float()\n",
    "                        weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                        criterion = nn.BCELoss(weigth)\n",
    "                        output = net(input)\n",
    "                        loss = criterion(output, target)\n",
    "                        test_losses.append(loss.data)\n",
    "                        print('test: ' + str(len(test_losses)) + '/' + str(len(test_dataloader)) + '          ', end = '\\r')\n",
    "                    test_loss = np.sum(test_losses) / len(test_losses)\n",
    "\n",
    "            live_graph.step(train_loss, validation_loss, test_loss)\n",
    "\n",
    "            if validation_loss <= validation_threshold:\n",
    "                print('Done training.')\n",
    "                break\n",
    "        return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import kaldi_utils\n",
    "\n",
    "def tracking_tester(recordings_segments,\n",
    "                    recordings_ids = None,\n",
    "                    scoring_function = None,\n",
    "                    groundtruth_filepath = '',\n",
    "                    groundtruth_valid_speakers_ids = ['A', 'B'],\n",
    "                    vector = 'ivectors',\n",
    "                    models_container_length = 2,\n",
    "                    models_container_include_overlaps = False,\n",
    "                    models_generation_length = 3,\n",
    "                    models_generation_selection = 'first',\n",
    "                    save_dir = 'tmp'):\n",
    "\n",
    "    if recordings_ids is None:\n",
    "        recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "    recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "    recordings_ids.sort()\n",
    "    \n",
    "    results = {}\n",
    "    results_reduced = {}\n",
    "    results_rttm = ''\n",
    "    results_scores = {}\n",
    "    eer_scores = ''\n",
    "    dcf_scores = ''\n",
    "    dcf_trials = ''\n",
    "    for i, recording_id in enumerate(recordings_ids):\n",
    "        print('tracking running: recording ' + str(i + 1) + '/' + str(len(recordings_ids)), end = '\\r')\n",
    "        # ----- Generating the models of each speaker in this recording ----- #\n",
    "        recording_dataset = Recordings_dataset(recordings_segments,\n",
    "                                               recording_id,\n",
    "                                               vector = vector,\n",
    "                                               models_container_length = models_container_length,\n",
    "                                               models_container_include_zeros = False,\n",
    "                                               models_container_include_overlaps = models_container_include_overlaps,\n",
    "                                               models_generation_lengths = [models_generation_length],\n",
    "                                               models_generation_selection = models_generation_selection)\n",
    "        speakers_models = recording_dataset.recordings_data[recording_id]['speakers_models']\n",
    "        speakers_segments_indexes_lengths_max = recording_dataset.recordings_data[recording_id]['speakers_segments_indexes_lengths_max']\n",
    "        speakers_ids = [speakers_ids for speakers_ids in speakers_models]\n",
    "        models_container = [speakers_models[speakers_ids][models_generation_length][0] for speakers_ids in speakers_models if models_container_include_overlaps or len(speakers_ids.split(',')) == 1]\n",
    "        # ----- Filling with 0's the remaining spaces of the speaker's models container ----- #\n",
    "        for i in range(models_container_length - len(models_container)):\n",
    "            models_container.append(np.random.uniform(-0.1, 0.1, len(models_container[0])))\n",
    "            \n",
    "        # ----- Obtaining the recording segments indexes ----- #\n",
    "        recording_segments_indexes = [(recording_id, index, True) for index, segment, in enumerate(recordings_segments[recording_id])]\n",
    "        \n",
    "        # ----- Generating the false segments indexes ----- #\n",
    "        other_recordings_segments = {}\n",
    "        other_recordings_segments_indexes = []\n",
    "        \n",
    "        for other_recording_id in recordings_segments:\n",
    "            if other_recording_id != recording_id:\n",
    "                other_recordings_segments[other_recording_id] = []\n",
    "                #other_recordings_segments_indexes += [(other_recording_id, index, False) for index, segment in enumerate(recordings_segments[other_recording_id])]\n",
    "                other_dataset = Recordings_dataset(recordings_segments,\n",
    "                                                   other_recording_id,\n",
    "                                                   vector = vector,\n",
    "                                                   models_container_length = models_container_length,\n",
    "                                                   models_container_include_zeros = False,\n",
    "                                                   models_container_include_overlaps = models_container_include_overlaps,\n",
    "                                                   models_generation_lengths = [models_generation_length],\n",
    "                                                   models_generation_selection = models_generation_selection)\n",
    "                other_speakers_models = other_dataset.recordings_data[other_recording_id]['speakers_models']\n",
    "                other_speakers_segments = [other_dataset.recordings_data[other_recording_id]['speakers_segments_indexes'][speakers_ids][0] for speakers_ids in other_speakers_models]\n",
    "                other_speakers_segments = [copy.deepcopy(recordings_segments[segment_recording_id][segment_index]) for segment_recording_id, segment_index, segment_real in other_speakers_segments]\n",
    "                other_speakers_models = [other_speakers_models[speakers_ids][models_generation_length][0] for speakers_ids in other_speakers_models]\n",
    "                for index, segment in enumerate(other_speakers_segments):\n",
    "                    other_speakers_segments[index][vector][0]['value'] = other_speakers_models[index]\n",
    "                    other_recordings_segments[other_recording_id].append(other_speakers_segments[index])\n",
    "                    other_recordings_segments_indexes.append((other_recording_id, len(other_recordings_segments[other_recording_id]) - 1, False))                \n",
    "\n",
    "        #other_recordings_segments_indexes = random.sample(other_recordings_segments_indexes, speakers_segments_indexes_lengths_max if speakers_segments_indexes_lengths_max < len(other_recordings_segments_indexes) else len(other_recordings_segments_indexes))    \n",
    "        options = [recording_segments_indexes, other_recordings_segments_indexes]\n",
    "        options_lengths = [len(option) for option in options]\n",
    "        new_recording_segments_indexes = []\n",
    "        while sum(options_lengths) > 0:\n",
    "            options_indexes = list(itertools.chain(*[[index] * len(option) for index, option in enumerate(options)]))\n",
    "            option_index = random.choice(options_indexes)\n",
    "            new_recording_segments_indexes.append(options[option_index].pop(0))\n",
    "            options_lengths = [len(option) for option in options]\n",
    "        recording_segments_indexes = new_recording_segments_indexes\n",
    "        \n",
    "        # ----- Obtaining the recording tracking results ----- #\n",
    "        results[recording_id] = []\n",
    "        results_scores[recording_id] = []\n",
    "        for segment_recording_id, segment_index, segment_real in recording_segments_indexes:\n",
    "            #segment = recordings_segments[segment_recording_id][segment_index]\n",
    "            if segment_real:\n",
    "                segment = recordings_segments[segment_recording_id][segment_index]\n",
    "            else:\n",
    "                segment = other_recordings_segments[segment_recording_id][segment_index]\n",
    "            segment_vector = np.asarray(segment[vector][0]['value'])\n",
    "            segment_vector_id = segment[vector][0]['ivector_id' if vector == 'ivectors' else 'xvector_id']\n",
    "            \n",
    "            scores = scoring_function(segment_vector, models_container)\n",
    "            \n",
    "            targets_ids = sorted([speaker['speaker_id'] for speaker in segment['speakers']])\n",
    "            labels = ['target' if segment_real and targets_ids == sorted(speaker_id.split(',')) else 'nontarget' for speaker_id in speakers_ids]\n",
    "            \n",
    "            utterances = [recording_id + '_' + speaker_id for speaker_id in speakers_ids]\n",
    "            \n",
    "            # utt1, utt2, score, target/nontarget\n",
    "            scores_labels = list(zip([segment_vector_id for speaker_id in speakers_ids], utterances, labels, scores))\n",
    "            results_scores[recording_id].append(scores_labels)\n",
    "            \n",
    "            if segment_real:\n",
    "                index = np.argmax(scores)\n",
    "                results[recording_id].append({ 'begining': segment['begining'], 'ending': segment['ending'], 'speaker_id': index })\n",
    "                if len(results[recording_id]) > 2:\n",
    "                    if results[recording_id][len(results[recording_id]) - 1]['speaker_id'] == results[recording_id][len(results[recording_id]) - 3]['speaker_id']:\n",
    "                        if results[recording_id][len(results[recording_id]) - 1]['speaker_id'] != results[recording_id][len(results[recording_id]) - 2]['speaker_id']:\n",
    "                            results[recording_id][len(results[recording_id]) - 2]['speaker_id'] = results[recording_id][len(results[recording_id]) - 1]['speaker_id']\n",
    "                            results[recording_id][len(results[recording_id]) - 1]['modified'] = True\n",
    "        results_reduced[recording_id] = []\n",
    "        last_speaker_id = -1\n",
    "        last_speaker = { 'begining': 0, 'ending': 0, 'speaker_id': -1 }\n",
    "        for segment in results[recording_id] + [{ 'begining': 0, 'ending': 0, 'speaker_id': -1 }]:\n",
    "            begining = segment['begining']\n",
    "            ending = segment['ending']\n",
    "            speaker_id = segment['speaker_id']\n",
    "            if last_speaker_id != speaker_id:\n",
    "                if last_speaker_id != -1:\n",
    "                    results_reduced[recording_id].append(last_speaker)\n",
    "                last_speaker_id = speaker_id\n",
    "                last_speaker = { 'begining': begining, 'ending': ending, 'speaker_id': speaker_id }\n",
    "            else:\n",
    "                if begining <= last_speaker['ending']:\n",
    "                    last_speaker['ending'] = ending\n",
    "                else:\n",
    "                    if last_speaker_id != -1:\n",
    "                        results_reduced[recording_id].append(last_speaker)\n",
    "                    last_speaker_id = speaker_id\n",
    "                    last_speaker = { 'begining': begining, 'ending': ending, 'speaker_id': speaker_id }\n",
    "        for scores_labels in results_scores[recording_id]:\n",
    "            for score_label in scores_labels:\n",
    "                # ('iaab_000-00000000-00000099', 'iaab_B', 'target', 0.9978078)\n",
    "                eer_score = '{:f}'.format(score_label[3]) + ' ' + score_label[2]\n",
    "                eer_scores += eer_score + '\\n'\n",
    "                dcf_score = score_label[0] + ' ' + score_label[1] + ' ' + '{:f}'.format(score_label[3])\n",
    "                dcf_scores += dcf_score + '\\n'\n",
    "                dcf_trial = score_label[0] + ' ' + score_label[1] + ' '+ score_label[2]\n",
    "                dcf_trials += dcf_trial + '\\n'\n",
    "        for segment in results_reduced[recording_id]:\n",
    "            result_rttm = 'SPEAKER ' + recording_id + ' 0 ' + str(segment['begining']) + ' ' + str(round(segment['ending'] - segment['begining'], 2)) + ' <NA> <NA> ' + str(segment['speaker_id']) + ' <NA> <NA>'\n",
    "            results_rttm += result_rttm + '\\n'\n",
    "    print('traking done: recording', str(i + 1) + '/' + str(len(recordings_ids)), '          ')\n",
    "\n",
    "    file = open(groundtruth_filepath, 'r')\n",
    "    groundtruth_rttm = ''.join([line for line in file.readlines() if (line.split(' ')[1] in recordings_ids) and \\\n",
    "                    (line.split(' ')[7] in groundtruth_valid_speakers_ids)])\n",
    "    file.close()\n",
    "    \n",
    "    !mkdir -p $save_dir\n",
    "    \n",
    "    file = open(save_dir + '/eer.scores', 'w')\n",
    "    file.write(eer_scores)\n",
    "    file.close()\n",
    "    \n",
    "    file = open(save_dir + '/dcf.scores', 'w')\n",
    "    file.write(dcf_scores)\n",
    "    file.close()\n",
    "    \n",
    "    file = open(save_dir + '/dcf.trials', 'w')\n",
    "    file.write(dcf_trials)\n",
    "    file.close()\n",
    "    \n",
    "    file = open(save_dir + '/groundtruth.rttm', 'w')\n",
    "    file.write(groundtruth_rttm)\n",
    "    file.close()\n",
    "    \n",
    "    file = open(save_dir + '/results.rttm', 'w')\n",
    "    file.write(results_rttm)\n",
    "    file.close()\n",
    "    \n",
    "    output_der = kaldi_utils.md_eval(save_dir + '/groundtruth.rttm', save_dir + '/results.rttm', log_directory=save_dir)\n",
    "    output_eer = kaldi_utils.compute_eer(save_dir + '/eer.scores', log_directory=save_dir)\n",
    "    output_dcf = kaldi_utils.compute_min_dcf(save_dir + '/dcf.scores', save_dir + '/dcf.trials', log_directory=save_dir)\n",
    "\n",
    "    return { 'der': output_der, 'eer': output_eer, 'dcf': output_dcf }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading recordings segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_directory = '../exp/augmented5/callhome1/json'\n",
    "a_groundtruth = '../exp/augmented5/callhome1/segments_augmented_1.0_0.5_ABZ.rttm'\n",
    "b_directory = '../exp/augmented5/callhome2/json'\n",
    "b_groundtruth = '../exp/augmented5/callhome2/segments_augmented_1.0_0.5_ABZ.rttm'\n",
    "maximum_speakers_length = 2\n",
    "valid_speakers_ids = ['A', 'B']\n",
    "models_container_length = 2\n",
    "models_container_include_zeros = True\n",
    "models_container_include_overlaps = False\n",
    "models_generation_selection = 'first'\n",
    "balance_segments_selection = 'copy'\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../exp/augmented5/callhome1/json loaded 249/249, 0.61 segments left.\n",
      "../exp/augmented5/callhome2/json loaded 250/250, 0.65 segments left.\n"
     ]
    }
   ],
   "source": [
    "a_recordings_segments = load_recordings_segments(a_directory,\n",
    "  lambda segment: is_valid_segment(segment, maximum_speakers_length, valid_speakers_ids))\n",
    "b_recordings_segments = load_recordings_segments(b_directory,\n",
    "  lambda segment: is_valid_segment(segment, maximum_speakers_length, valid_speakers_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../exp/augmented5/callhome1/json loaded 249/249, 0.61 segments left.\n",
      "../exp/augmented5/callhome2/json loaded 250/250, 0.65 segments left.\n"
     ]
    }
   ],
   "source": [
    "a_recordings_test_segments = load_recordings_segments(a_directory,\n",
    "  lambda segment: is_valid_segment(segment, maximum_speakers_length, valid_speakers_ids))\n",
    "b_recordings_test_segments = load_recordings_segments(b_directory,\n",
    "  lambda segment: is_valid_segment(segment, maximum_speakers_length, valid_speakers_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_selector(vector, models_container, net):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    with torch.no_grad():\n",
    "        input = [torch.Tensor([nparray]).to(device, non_blocking = True).float() for nparray in [vector] + models_container]\n",
    "        output = net(input)\n",
    "        return output.cpu().data.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ivectors 128 20 0\n",
      "Recordings left: 248/249\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 134/3058                \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4b623a5474ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                       \u001b[0mmodels_generation_selection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels_generation_selection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                       \u001b[0mbalance_segments_selection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbalance_segments_selection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                                       batch_size = batch_size)\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mb_trainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             b_net = b_trainer.get_net(balance_segments(b_recordings_segments,maximum_speakers_length,1,False),\n",
      "\u001b[0;32m<ipython-input-5-e471233ab000>\u001b[0m in \u001b[0;36mget_net\u001b[0;34m(self, recordings_segments, recordings_ids, vector, vector_length, models_container_length, models_container_include_zeros, models_container_include_overlaps, models_generation_lengths, models_generation_selection, balance_segments, balance_segments_selection, batch_size, num_workers, test_recordings_segments)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweigth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_real\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py36/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py36/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    282\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py36/lib/python3.6/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py36/lib/python3.6/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mrecv_handle\u001b[0;34m(conn)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;34m'''Receive a handle over a local connection.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAF_UNIX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mrecvfds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mDupFd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py36/lib/python3.6/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mrecvfds\u001b[0;34m(sock, size)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mbytes_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mancdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecvmsg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCMSG_SPACE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mancdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for vector in ['ivectors']:\n",
    "    vector_length = 128 if vector == 'ivectors' else 128\n",
    "    for models_generation_length in [20]:\n",
    "        for i in range(3):\n",
    "            print(vector, vector_length, models_generation_length, i)\n",
    "            a_trainer = Trainer()\n",
    "            a_net = a_trainer.get_net(balance_segments(a_recordings_segments,maximum_speakers_length,1,False),\n",
    "                                      vector = vector,\n",
    "                                      vector_length = vector_length,\n",
    "                                      models_container_length = models_container_length,\n",
    "                                      models_container_include_zeros = models_container_include_zeros,\n",
    "                                      models_container_include_overlaps = models_container_include_overlaps,\n",
    "                                      models_generation_lengths = [models_generation_length],\n",
    "                                      models_generation_selection = models_generation_selection,\n",
    "                                      balance_segments_selection = balance_segments_selection,\n",
    "                                      batch_size = batch_size)\n",
    "            b_trainer = Trainer()\n",
    "            b_net = b_trainer.get_net(balance_segments(b_recordings_segments,maximum_speakers_length,1,False),\n",
    "                                      vector = vector,\n",
    "                                      vector_length = vector_length,\n",
    "                                      models_container_length = models_container_length,\n",
    "                                      models_container_include_zeros = models_container_include_zeros,\n",
    "                                      models_container_include_overlaps = models_container_include_overlaps,\n",
    "                                      models_generation_lengths = [models_generation_length],\n",
    "                                      models_generation_selection = models_generation_selection,\n",
    "                                      balance_segments_selection = balance_segments_selection,\n",
    "                                      batch_size = batch_size)\n",
    "            \n",
    "            test_id = '20200501_callhome_fc4_' + vector + '_' + str(models_generation_length) + '_' + str(i)\n",
    "            \n",
    "            a_results = tracking_tester(a_recordings_test_segments,\n",
    "                                        scoring_function = lambda vector, models_container: net_selector(vector, models_container, b_net),\n",
    "                                        groundtruth_filepath = a_groundtruth,\n",
    "                                        groundtruth_valid_speakers_ids = ['A', 'B'],\n",
    "                                        vector = vector,\n",
    "                                        models_container_length = models_container_length,\n",
    "                                        models_container_include_overlaps = models_container_include_overlaps,\n",
    "                                        models_generation_length = models_generation_length,\n",
    "                                        models_generation_selection = models_generation_selection,\n",
    "                                        save_dir = 'batch/' + test_id + '_a')\n",
    "        \n",
    "\n",
    "            b_results = tracking_tester(b_recordings_test_segments,\n",
    "                                        scoring_function = lambda vector, models_container: net_selector(vector, models_container, a_net),\n",
    "                                        groundtruth_filepath = b_groundtruth,\n",
    "                                        groundtruth_valid_speakers_ids = ['A', 'B'],\n",
    "                                        vector = vector,\n",
    "                                        models_container_length = models_container_length,\n",
    "                                        models_container_include_overlaps = models_container_include_overlaps,\n",
    "                                        models_generation_length = models_generation_length,\n",
    "                                        models_generation_selection = models_generation_selection,\n",
    "                                        save_dir = 'batch/' + test_id + '_b')\n",
    "            \n",
    "            print(a_results)\n",
    "            print(b_results)\n",
    "            output_der = (a_results['der'] + b_results['der']) / 2\n",
    "            output_eer = (a_results['eer'] + b_results['eer']) / 2\n",
    "            output_dcf = (a_results['dcf'] + b_results['dcf']) / 2\n",
    "            results = { 'der': output_der, 'eer': output_eer, 'dcf': output_dcf }\n",
    "            print(results)\n",
    "            \n",
    "            file = open('batch/results.csv', 'a')\n",
    "            file.write(test_id + ', ' + json.dumps(a_results) + ', ' + json.dumps(b_results) + ', ' + json.dumps(results) + '\\n')\n",
    "            file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
