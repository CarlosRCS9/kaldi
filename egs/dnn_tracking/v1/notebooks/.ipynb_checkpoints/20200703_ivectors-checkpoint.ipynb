{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "spath = '../'\n",
    "sys.path.insert(0,spath)\n",
    "from scripts.models import get_rttm_segments_features, sort_segments_by_speakers, Ivector\n",
    "from scripts.notebook import limit_speakers_number, get_speakers_segments_indexes, get_speakers_models, get_speakers_permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_rttm     = '../exp/dihardii/development/ref_augmented_0_1.5_0.5_0.5.rttm'\n",
    "dev_segments = '../exp/dihardii/development/augmented_0/segments'\n",
    "dev_ivectors = '../exp/dihardii/development/augmented_0/exp/make_ivectors/ivector.txt'\n",
    "dev_files_segments = get_rttm_segments_features(dev_rttm, dev_segments, dev_ivectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_rttm     = '../exp/dihardii/evaluation/ref_augmented_0_1.5_0.5_0.5.rttm'\n",
    "eval_segments = '../exp/dihardii/evaluation/augmented_0/segments'\n",
    "eval_ivectors = '../exp/dihardii/evaluation/augmented_0/exp/make_ivectors/ivector.txt'\n",
    "eval_files_segments = get_rttm_segments_features(eval_rttm, eval_segments, eval_ivectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 93673 of 94517: 0.991070389453749\n",
      "Kept 87295 of 88018: 0.9917857710922766\n"
     ]
    }
   ],
   "source": [
    "dev_files_segments_lim = limit_speakers_number(dev_files_segments, 2, log = True)\n",
    "eval_files_segments_lim = limit_speakers_number(eval_files_segments, 2, log = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy\n",
    "\n",
    "class Files_dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 files_segments,\n",
    "                 models_generation_lengths = [3],\n",
    "                 models_container_length = 2,\n",
    "                 include_zeros = True,\n",
    "                 include_overlaps = False,\n",
    "                 feature='ivectors'):\n",
    "        self.files_segments = files_segments\n",
    "        self.include_overlaps = include_overlaps\n",
    "        self.feature = feature\n",
    "        self.speakers_segments_indexes = {}\n",
    "        self.speakers_models = {}\n",
    "        self.speakers_permutations = {}\n",
    "        self.lookup = []\n",
    "        self.length = 0\n",
    "        for file_id, segments in self.files_segments.items():\n",
    "            self.speakers_segments_indexes[file_id] = get_speakers_segments_indexes(enumerate(segments))\n",
    "            self.speakers_models[file_id] = get_speakers_models(segments,\n",
    "                                                                self.speakers_segments_indexes[file_id],\n",
    "                                                                models_generation_lengths)\n",
    "            self.speakers_permutations[file_id] = get_speakers_permutations(self.speakers_models[file_id],\n",
    "                                                                            models_container_length,\n",
    "                                                                            include_zeros,\n",
    "                                                                            include_overlaps)\n",
    "            for index, permutation in enumerate(self.speakers_permutations[file_id]):\n",
    "                models_length = numpy.prod([len(self.speakers_models[file_id][speakers_names].keys())\\\n",
    "                if speakers_names != '0' else 1 for speakers_names in permutation])\n",
    "                length = models_length * len(segments)\n",
    "                self.lookup.append({\\\n",
    "                                    'file_id': file_id,\\\n",
    "                                    'permutation_index': index,\\\n",
    "                                    'models_length': models_length,\\\n",
    "                                    'segments_length': len(segments),\\\n",
    "                                    'permutation_length': length,\\\n",
    "                                    'onset': self.length,\\\n",
    "                                    'end': self.length + length - 1 })\n",
    "                self.length += length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        lookup = [value for value in self.lookup if value['onset'] <= idx and idx <= value['end']][0]\n",
    "        index = idx - lookup['onset']\n",
    "        permutation = self.speakers_permutations[lookup['file_id']][lookup['permutation_index']]\n",
    "        remainder, segment_index = divmod(index, lookup['segments_length'])\n",
    "        models_container = []\n",
    "        for index, speakers_names in enumerate(permutation):\n",
    "            models_lengths = [len(self.speakers_models[lookup['file_id']][speakers_names].keys()) if speakers_names != '0' else 1 for speakers_names in permutation][index + 1:]\n",
    "            if index != len(permutation) - 1:\n",
    "                model_index, remainder = divmod(remainder, int(numpy.prod(models_lengths)))\n",
    "            else:\n",
    "                model_index = remainder\n",
    "            if speakers_names != '0':\n",
    "                models_container.append(self.speakers_models[lookup['file_id']][speakers_names][list(self.speakers_models[lookup['file_id']][speakers_names].keys())[model_index]])\n",
    "            else:\n",
    "                # TODO: improve\n",
    "                models_container.append({ 'ivectors': [Ivector(numpy.random.uniform(-0.1, 0.1, 400).astype(numpy.float32))] })\n",
    "        segment = self.files_segments[lookup['file_id']][segment_index]\n",
    "        segment_speakers = [speaker.get_name() for speaker in segment.get_speakers()]\n",
    "        x = [value[self.feature][0].get_value() for value\\\n",
    "             in models_container + [{ 'ivectors': segment.get_ivectors() }]]\n",
    "        if self.include_overlaps:\n",
    "            segment_speakers = ','.join(sorted(set(segment_speakers)))\n",
    "            y = numpy.asarray([speakers_names == segment_speakers for speakers_names in permutation], dtype = numpy.float32)\n",
    "        else:\n",
    "            y = numpy.asarray([speakers_names in segment_speakers for speakers_names in permutation], dtype = numpy.float32) / len(segment_speakers)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/containeruser/conda/lib/python3.7/site-packages/graphql/type/directives.py:55: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  assert isinstance(locations, collections.Iterable), 'Must provide locations for directive.'\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning\n",
    "import torch\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class DNNModel(pytorch_lightning.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        m = 400 # embedding length\n",
    "        n = 2   # models container length\n",
    "        self.cnn1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d((n + 1), n ** 3, 3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv1d(n ** 3, n ** 2, 3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv1d(n ** 2, n, 3),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        self.fc1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear((m - 6) * n, n * 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(n * 32, n * 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(n * 16, n),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.stack(x, 1)\n",
    "        x = self.cnn1(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        criterion = torch.nn.BCELoss()\n",
    "        loss = criterion(self(x), y)\n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | cnn1 | Sequential | 206   \n",
      "1 | fc1  | Sequential | 52 K  \n",
      "/home/containeruser/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c56e01aebe1406cabc5511631a14e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loader = DataLoader(Files_dataset(dev_files_segments_lim),\n",
    "                          batch_size = 32,\n",
    "                          shuffle = True)\n",
    "\n",
    "model = DNNModel()\n",
    "trainer = pytorch_lightning.Trainer(gpus = 1, progress_bar_refresh_rate = 20)    \n",
    "trainer.fit(model, train_loader)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
