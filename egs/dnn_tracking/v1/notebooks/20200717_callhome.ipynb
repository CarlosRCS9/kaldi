{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "spath = '../'\n",
    "sys.path.insert(0,spath)\n",
    "from scripts.models import get_rttm_segments_features, sort_segments_by_speakers, Ivector\n",
    "from scripts.notebook import\\\n",
    "get_first_speakers,\\\n",
    "limit_segments_speakers_names,\\\n",
    "limit_segments_speakers_length,\\\n",
    "balance_speakers_segments_length,\\\n",
    "get_speakers_segments_indexes,\\\n",
    "get_speakers_models,\\\n",
    "get_speakers_permutations\n",
    "\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iaaa 0.0\n",
      "iaaa 0.7\n",
      "iaaa 1.4\n",
      "iaaa 2.1\n",
      "iaaa 2.8\n",
      "iaaa 3.9\n",
      "iaaa 4.75\n",
      "iaaa 5.45\n",
      "iaaa 6.15\n",
      "iaaa 6.85\n",
      "iaaa 7.55\n",
      "iaaa 8.713\n",
      "iaaa 9.413\n",
      "iaaa 10.653\n",
      "iaaa 11.353\n",
      "iaaa 12.053\n",
      "iaaa 13.403\n",
      "iaaa 14.103\n",
      "iaaa 14.803\n",
      "iaaa 15.483\n",
      "iaaa 16.503\n",
      "iaaa 17.203\n",
      "iaaa 17.903\n",
      "iaaa 18.603\n",
      "iaaa 19.513\n",
      "iaaa 20.213\n",
      "iaaa 20.913\n",
      "iaaa 21.613\n",
      "iaaa 22.903\n",
      "iaaa 23.603\n",
      "iaaa 24.303\n",
      "iaaa 25.253\n",
      "iaaa 25.853\n",
      "iaaa 26.553\n",
      "iaaa 28.153\n",
      "iaaa 28.853\n",
      "iaaa 29.553\n",
      "iaaa 30.253\n",
      "iaaa 30.972\n",
      "iaaa 32.512\n",
      "iaaa 33.212\n",
      "iaaa 33.912\n",
      "iaaa 34.612\n",
      "iaaa 35.312\n",
      "iaaa 36.012\n",
      "iaaa 36.542\n",
      "iaaa 37.522\n",
      "iaaa 38.112\n",
      "iaaa 38.812\n",
      "iaaa 39.512\n",
      "iaaa 40.376\n",
      "iaaa 41.076\n",
      "iaaa 42.168\n",
      "iaaa 43.538\n",
      "iaaa 44.528\n",
      "iaaa 45.378\n",
      "iaaa 47.128\n",
      "iaaa 47.828\n",
      "iaaa 48.528\n",
      "iaaa 49.228\n",
      "iaaa 49.928\n",
      "iaaa 50.678\n",
      "iaaa 53.73\n",
      "iaaa 54.43\n",
      "iaaa 55.13\n",
      "iaaa 55.83\n",
      "iaaa 56.53\n",
      "iaaa 57.23\n",
      "iaaa 57.93\n",
      "iaaa 58.63\n",
      "iaaa 60.23\n",
      "iaaa 60.93\n",
      "iaaa 61.63\n",
      "iaaa 62.33\n",
      "iaaa 63.03\n",
      "iaaa 64.29\n",
      "iaaa 64.99\n",
      "iaaa 65.69\n",
      "iaaa 66.39\n",
      "iaaa 67.63\n",
      "iaaa 69.06\n",
      "iaaa 69.76\n",
      "iaaa 70.46\n",
      "iaaa 71.16\n",
      "iaaa 72.35\n",
      "iaaa 73.05\n",
      "iaaa 73.75\n",
      "iaaa 74.45\n",
      "iaaa 75.15\n",
      "iaaa 75.85\n",
      "iaaa 77.03\n",
      "iaaa 77.73\n",
      "iaaa 78.43\n",
      "iaaa 79.13\n",
      "iaaa 79.83\n",
      "iaaa 80.53\n",
      "iaaa 81.23\n",
      "iaaa 82.32\n",
      "iaaa 83.02\n",
      "iaaa 83.72\n",
      "iaaa 84.42\n",
      "iaaa 85.71\n",
      "iaaa 86.26\n",
      "iaaa 86.96\n",
      "iaac 0.0\n",
      "iaac 0.7\n",
      "iaac 2.12\n",
      "iaac 2.82\n",
      "iaac 3.52\n",
      "iaac 4.22\n",
      "iaac 5.84\n",
      "iaac 6.54\n",
      "iaac 7.24\n",
      "iaac 7.94\n",
      "iaac 8.64\n",
      "iaac 9.63\n",
      "iaac 10.15\n",
      "iaac 11.32\n",
      "iaac 12.02\n",
      "iaac 12.72\n",
      "iaac 13.42\n",
      "iaac 14.12\n",
      "iaac 14.87\n",
      "iaac 15.87\n",
      "iaac 16.57\n",
      "iaac 17.27\n",
      "iaac 17.97\n",
      "iaac 18.67\n",
      "iaac 19.23\n",
      "iaac 19.93\n",
      "iaac 20.5\n",
      "iaac 21.2\n",
      "iaac 22.23\n",
      "iaac 22.77\n",
      "iaac 23.47\n",
      "iaac 24.17\n",
      "iaac 25.172\n",
      "iaac 25.872\n",
      "iaac 26.572\n",
      "iaac 27.272\n",
      "iaac 27.972\n",
      "iaac 28.672\n",
      "iaac 29.372\n",
      "iaac 30.262\n",
      "iaac 31.352\n",
      "iaac 32.052\n",
      "iaac 33.287\n",
      "iaac 33.987\n",
      "iaac 34.687\n",
      "iaac 35.377\n",
      "iaac 36.077\n",
      "iaac 36.777\n",
      "iaac 37.627\n",
      "iaac 38.327\n",
      "iaac 39.867\n",
      "iaac 40.567\n",
      "iaac 41.267\n",
      "iaac 41.967\n",
      "iaac 42.667\n",
      "iaac 45.247\n",
      "iaac 45.947\n",
      "iaac 47.437\n",
      "iaac 48.137\n",
      "iaac 48.837\n",
      "iaac 50.037\n",
      "iaac 50.737\n",
      "iaac 51.275\n",
      "iaac 51.775\n",
      "iaac 52.785\n",
      "iaac 53.485\n",
      "iaac 54.185\n",
      "iaac 54.885\n",
      "iaac 55.585\n",
      "iaac 56.285\n",
      "iaac 57.395\n",
      "iaac 58.095\n",
      "iaac 59.015\n",
      "iaac 59.715\n",
      "iaac 60.415\n",
      "iaac 61.115\n",
      "iaac 61.815\n",
      "iaac 62.515\n",
      "iaac 63.215\n",
      "iaac 63.915\n",
      "iaac 64.615\n",
      "iaac 65.315\n",
      "iaac 66.015\n",
      "iaac 66.715\n",
      "iaac 67.415\n",
      "iaac 68.115\n",
      "iaac 68.815\n",
      "iaac 69.515\n",
      "iaac 70.215\n",
      "iaac 70.915\n",
      "iaah 0.0\n",
      "iaah 0.7\n",
      "iaah 1.4\n",
      "iaah 2.1\n",
      "iaah 2.8\n",
      "iaah 3.5\n",
      "iaah 4.57\n",
      "iaah 5.27\n",
      "iaah 5.97\n",
      "iaah 7.108\n",
      "iaah 7.808\n",
      "iaah 8.657\n",
      "iaah 9.517\n",
      "iaah 10.307\n",
      "iaah 11.267\n",
      "iaah 12.437\n",
      "iaah 13.067\n",
      "iaah 13.92\n",
      "iaah 14.62\n",
      "iaah 15.32\n",
      "iaah 16.02\n",
      "iaah 16.72\n",
      "iaah 17.75\n",
      "iaah 18.45\n",
      "iaah 19.15\n",
      "iaah 19.878\n",
      "iaah 20.578\n",
      "iaah 21.218\n",
      "iaah 21.918\n",
      "iaah 22.767\n",
      "iaah 23.517\n",
      "iaah 24.247\n",
      "iaah 24.947\n",
      "iaah 25.647\n",
      "iaah 26.827\n",
      "iaah 27.577\n",
      "iaah 28.43\n",
      "iaah 29.13\n",
      "iaah 29.83\n",
      "iaah 30.53\n",
      "iaah 31.23\n",
      "iaah 31.93\n",
      "iaah 32.63\n",
      "iaah 33.33\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "33.33",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1aa627613db4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdev_segments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../augmented/callhome/callhome1/augmented_0/1.0_0.3_0.5/128/segments'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdev_ivectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../augmented/callhome/callhome1/augmented_0/1.0_0.3_0.5/128/exp/make_ivectors/ivector.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdev_files_segments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_rttm_segments_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_rttm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_segments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_ivectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~notebooks/egs/dnn_tracking/v1/scripts/models.py\u001b[0m in \u001b[0;36mget_rttm_segments_features\u001b[0;34m(rttm_filepath, segments_filepath, ivectors_filepath)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msegment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msegments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_turn_onset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m       \u001b[0mivector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mivectors_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mutterances_turns_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_turn_onset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m       \u001b[0msegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ivectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mivector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0mfiles_segments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 33.33"
     ]
    }
   ],
   "source": [
    "dev_rttm     = '../augmented/callhome/callhome1/augmented_0/1.0_0.3_0.5/ref.rttm'\n",
    "dev_segments = '../augmented/callhome/callhome1/augmented_0/1.0_0.3_0.5/128/segments'\n",
    "dev_ivectors = '../augmented/callhome/callhome1/augmented_0/1.0_0.3_0.5/128/exp/make_ivectors/ivector.txt'\n",
    "dev_files_segments = get_rttm_segments_features(dev_rttm, dev_segments, dev_ivectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_rttm     = '../exp/callhome/callhome2/ref_augmented_0_1.5_0.5_0.5.rttm'\n",
    "eval_segments = '../exp/callhome/callhome2/augmented_0/segments'\n",
    "eval_ivectors = '../exp/callhome/callhome2/augmented_0/exp/make_ivectors/ivector.txt'\n",
    "eval_files_segments = get_rttm_segments_features(eval_rttm, eval_segments, eval_ivectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the two first speakers of each file\n",
    "dev_files_speakers = get_first_speakers(dev_files_segments, 2)\n",
    "eval_files_speakers = get_first_speakers(eval_files_segments, 2)\n",
    "\n",
    "# Removing single-speaker files\n",
    "delete = [file_id for file_id, speakers_names in dev_files_speakers.items() if len(speakers_names) < 2]\n",
    "for file_id in delete:\n",
    "    del dev_files_speakers[file_id]\n",
    "delete = [file_id for file_id, speakers_names in eval_files_speakers.items() if len(speakers_names) < 2]\n",
    "for file_id in delete:\n",
    "    del eval_files_speakers[file_id]\n",
    "\n",
    "# Filtering segments that only contain speakers from the list\n",
    "dev_files_segments_lim = limit_segments_speakers_names(dev_files_segments, dev_files_speakers, log = True)\n",
    "eval_files_segments_lim = limit_segments_speakers_names(eval_files_segments, eval_files_speakers, log = True)\n",
    "\n",
    "# Filtering segments thath only contain one speaker\n",
    "dev_files_segments_lim = limit_segments_speakers_length(dev_files_segments_lim, 1, log = True)\n",
    "eval_files_segments_lim = limit_segments_speakers_length(eval_files_segments_lim, 1, log = True)\n",
    "\n",
    "#dev_files_segments_lim = balance_speakers_segments_length(dev_files_segments_lim, log = True)\n",
    "#eval_files_segments_lim = balance_speakers_segments_length(eval_files_segments_lim, log = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = list(dev_files_segments_lim.keys())[5]\n",
    "segments = dev_files_segments_lim[file_id]\n",
    "\n",
    "x = [segment.get_ivectors()[0].get_value() for segment in segments if len(segment.get_speakers()) == 1]\n",
    "y = [segment.get_speakers()[0].get_name() for segment in segments if len(segment.get_speakers()) == 1]\n",
    "\n",
    "speakers_ivectors = {}\n",
    "for xi, yi in zip(x, y):\n",
    "    if yi not in speakers_ivectors:\n",
    "        speakers_ivectors[yi] = []\n",
    "    speakers_ivectors[yi].append(xi)\n",
    "    \n",
    "speakers_models = {}\n",
    "for speaker_name, ivectors in speakers_ivectors.items():\n",
    "    speakers_models[speaker_name] = []\n",
    "    for i in range(1, len(ivectors)):\n",
    "        speakers_models[speaker_name].append(np.sum(ivectors[:i], 0) / len(ivectors[:i]))\n",
    "\n",
    "x_ = []\n",
    "y_ = []\n",
    "for speaker_name, models in speakers_models.items():\n",
    "    for ivector in models:\n",
    "        x_.append(ivector)\n",
    "        y_.append(speaker_name + '_m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(x)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(data)\n",
    "scaled_data = scaler.transform(data)\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(scaled_data)\n",
    "\n",
    "data_ = pd.DataFrame(x_)\n",
    "scaled_data_ = scaler.transform(data_)\n",
    "\n",
    "pca_data = pd.DataFrame(pca.transform(np.concatenate([scaled_data, scaled_data_])))\n",
    "pca_data['label'] = y + y_\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "per_var = np.round(pca.explained_variance_ratio_ * 100)\n",
    "ax.set_title('Scree Plot')\n",
    "ax.set_ylabel('Percentage of Explained Variance')\n",
    "ax.set_xlabel('Principal Component')\n",
    "ax.bar(x = range(1, len(per_var) + 1), height = per_var)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "colors = ['r', 'g', 'b', 'c']\n",
    "labels_colors = {}\n",
    "for label in pca_data['label']:\n",
    "    if label not in labels_colors:\n",
    "        labels_colors[label] = colors.pop(0)\n",
    "colors = [labels_colors[label] for label in pca_data['label']]\n",
    "ax.set_title('Principal Component Analysis')\n",
    "ax.set_ylabel('Dimension 2')\n",
    "ax.set_xlabel('Dimension 1')\n",
    "ax.scatter(pca_data[0], pca_data[1], c = colors)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "tsne = TSNE()\n",
    "tsne_data = pd.DataFrame(tsne.fit_transform(np.concatenate([scaled_data, scaled_data_])))\n",
    "ax.set_title('t-distributed Stochastic Neighbor Embedding')\n",
    "ax.set_ylabel('Dimension 2')\n",
    "ax.set_xlabel('Dimension 1')\n",
    "ax.scatter(tsne_data[0], tsne_data[1], c = colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ims = []\n",
    "for index, (x_i, y_i) in enumerate(zip(x_, y_)):\n",
    "    data_ = pd.DataFrame([x_i])\n",
    "    scaled_data_ = scaler.transform(data_)\n",
    "    pca_data = pd.DataFrame(pca.transform(np.concatenate([scaled_data, scaled_data_])))\n",
    "    pca_data['label'] = y + [y_i]\n",
    "    im = plt.scatter(pca_data[0], pca_data[1], c = colors[:len(x)] + [colors[len(x) + index]], animated=True)\n",
    "    ims.append([im])\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=250, blit=True, repeat_delay=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy\n",
    "\n",
    "class Files_dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 files_segments,\n",
    "                 models_generation_lengths = [3],\n",
    "                 models_container_length = 2,\n",
    "                 include_zeros = True,\n",
    "                 include_overlaps = False,\n",
    "                 feature='ivectors'):\n",
    "        self.files_segments = files_segments\n",
    "        self.include_overlaps = include_overlaps\n",
    "        self.feature = feature\n",
    "        self.speakers_segments_indexes = {}\n",
    "        self.speakers_segments_lengths = {}\n",
    "        self.speakers_models = {}\n",
    "        self.speakers_permutations = {}\n",
    "        self.lookup = []\n",
    "        self.length = 0\n",
    "        for file_id, segments in self.files_segments.items():\n",
    "            self.speakers_segments_indexes[file_id] = get_speakers_segments_indexes(enumerate(segments))\n",
    "            self.speakers_segments_lengths[file_id] = {}\n",
    "            for speakers_names, indexes in self.speakers_segments_indexes[file_id].items():\n",
    "                self.speakers_segments_lengths[file_id][speakers_names] = len(indexes)\n",
    "            self.speakers_segments_lengths[file_id]['0'] = max(self.speakers_segments_lengths[file_id].values())\n",
    "            self.speakers_models[file_id] = get_speakers_models(segments,\n",
    "                                                                self.speakers_segments_indexes[file_id],\n",
    "                                                                models_generation_lengths)\n",
    "            self.speakers_permutations[file_id] = get_speakers_permutations(self.speakers_models[file_id],\n",
    "                                                                            models_container_length,\n",
    "                                                                            include_zeros,\n",
    "                                                                            include_overlaps)\n",
    "            for index, permutation in enumerate(self.speakers_permutations[file_id]):\n",
    "                models_length = numpy.prod([len(self.speakers_models[file_id][speakers_names].keys())\\\n",
    "                if speakers_names != '0' else 1 for speakers_names in permutation])\n",
    "                length = models_length * len(segments)\n",
    "                self.lookup.append({\\\n",
    "                                    'file_id': file_id,\\\n",
    "                                    'permutation_index': index,\\\n",
    "                                    'models_length': models_length,\\\n",
    "                                    'segments_length': len(segments),\\\n",
    "                                    'permutation_length': length,\\\n",
    "                                    'onset': self.length,\\\n",
    "                                    'end': self.length + length - 1 })\n",
    "                self.length += length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        lookup = [value for value in self.lookup if value['onset'] <= idx and idx <= value['end']][0]\n",
    "        index = idx - lookup['onset']\n",
    "        permutation = self.speakers_permutations[lookup['file_id']][lookup['permutation_index']]\n",
    "        remainder, segment_index = divmod(index, lookup['segments_length'])\n",
    "        models_container = []\n",
    "        for index, speakers_names in enumerate(permutation):\n",
    "            models_lengths = [len(self.speakers_models[lookup['file_id']][speakers_names].keys()) if speakers_names != '0' else 1 for speakers_names in permutation][index + 1:]\n",
    "            if index != len(permutation) - 1:\n",
    "                model_index, remainder = divmod(remainder, int(numpy.prod(models_lengths)))\n",
    "            else:\n",
    "                model_index = remainder\n",
    "            if speakers_names != '0':\n",
    "                models_container.append(self.speakers_models[lookup['file_id']][speakers_names][list(self.speakers_models[lookup['file_id']][speakers_names].keys())[model_index]])\n",
    "            else:\n",
    "                # TODO: improve\n",
    "                models_container.append({ 'ivectors': [Ivector(numpy.random.uniform(-0.1, 0.1, 128).astype(numpy.float32))] })\n",
    "        segment = self.files_segments[lookup['file_id']][segment_index]\n",
    "        segment_speakers = [speaker.get_name() for speaker in segment.get_speakers()]\n",
    "        x = [value[self.feature][0].get_value() for value\\\n",
    "             in models_container + [{ 'ivectors': segment.get_ivectors() }]]\n",
    "        if self.include_overlaps:\n",
    "            segment_speakers = ','.join(sorted(set(segment_speakers)))\n",
    "            y = numpy.asarray([speakers_names == segment_speakers for speakers_names in permutation], dtype = numpy.float32)\n",
    "        else:\n",
    "            y = numpy.asarray([speakers_names in segment_speakers for speakers_names in permutation], dtype = numpy.float32) / len(segment_speakers)\n",
    "        w = [self.speakers_segments_lengths[lookup['file_id']][speakers_names] for speakers_names in permutation]\n",
    "        w_sum = np.sum(w)\n",
    "        w = np.ones(len(w)) - w / w_sum\n",
    "        return x, y, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, b, M):\n",
    "        super(Model, self).__init__()\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv1d((M + 1), M ** 3, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(M ** 3, M ** 2, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(M ** 2, M, 3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear((b - 6) * M, M * 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(M * 32, M * 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(M * 16, M),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = torch.stack(x, 1)\n",
    "        x = self.cnn1(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "train_dataset = Files_dataset(dev_files_segments_lim)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 64, shuffle = True, num_workers = 8)\n",
    "\n",
    "net = Model(128, 2).to(device, non_blocking = True)\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.0001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    losses = []\n",
    "    for x, y, w in train_dataloader:\n",
    "        x = [tensor.to(device, non_blocking = True) for tensor in x]\n",
    "        y = y.to(device, non_blocking = True)\n",
    "        w = w.to(device, non_blocking = True)\n",
    "        \n",
    "        criterion = nn.BCELoss(w)\n",
    "        y_ = net(x)\n",
    "        loss = criterion(y_, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.data)\n",
    "    print(np.sum(losses) / len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
