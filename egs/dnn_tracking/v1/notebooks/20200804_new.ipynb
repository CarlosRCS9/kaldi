{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "spath = '../'\n",
    "sys.path.insert(0,spath)\n",
    "from scripts.models import get_rttm_segments_features, sort_segments_by_speakers, Ivector\n",
    "from scripts.notebook import \\\n",
    "get_best_speakers, \\\n",
    "limit_segments_speakers_names, \\\n",
    "limit_segments_speakers_length, \\\n",
    "balance_speakers_segments_length, \\\n",
    "get_speakers_segments_indexes, \\\n",
    "get_speakers_models, \\\n",
    "get_speakers_permutations, \\\n",
    "get_speakers_weights_2, \\\n",
    "Permutations\n",
    "\n",
    "import itertools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 128\n",
    "\n",
    "dev_a_rttm     = '../augmented/callhome/callhome1/augmented_0/1.5_0.3_0.5/' + str(dimension) + '/ref.rttm'\n",
    "dev_a_segments = '../augmented/callhome/callhome1/augmented_0/1.5_0.3_0.5/' + str(dimension) + '/segments'\n",
    "dev_a_ivectors = '../augmented/callhome/callhome1/augmented_0/1.5_0.3_0.5/' + str(dimension) + '/exp/make_ivectors/ivector.txt'\n",
    "dev_a_files_segments = get_rttm_segments_features(dev_a_rttm, dev_a_segments, dev_a_ivectors)\n",
    "\n",
    "dev_b_rttm     = '../augmented/callhome/callhome1/augmented_0/1.0_0.3_0.5/' + str(dimension) + '/ref.rttm'\n",
    "dev_b_segments = '../augmented/callhome/callhome1/augmented_0/1.0_0.3_0.5/' + str(dimension) + '/segments'\n",
    "dev_b_ivectors = '../augmented/callhome/callhome1/augmented_0/1.0_0.3_0.5/' + str(dimension) + '/exp/make_ivectors/ivector.txt'\n",
    "dev_b_files_segments = get_rttm_segments_features(dev_b_rttm, dev_b_segments, dev_b_ivectors)\n",
    "\n",
    "dev_c_rttm     = '../augmented/callhome/callhome1/augmented_0/0.5_0.3_0.5/' + str(dimension) + '/ref.rttm'\n",
    "dev_c_segments = '../augmented/callhome/callhome1/augmented_0/0.5_0.3_0.5/' + str(dimension) + '/segments'\n",
    "dev_c_ivectors = '../augmented/callhome/callhome1/augmented_0/0.5_0.3_0.5/' + str(dimension) + '/exp/make_ivectors/ivector.txt'\n",
    "dev_c_files_segments = get_rttm_segments_features(dev_c_rttm, dev_c_segments, dev_c_ivectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 25942 of 35773: 0.725183797836357\n",
      "Kept 38643 of 53526: 0.7219482120838471\n",
      "Kept 115828 of 160980: 0.7195179525406883\n",
      "Kept 17709 of 25942: 0.6826381928918356\n",
      "Kept 26371 of 38643: 0.6824263126568848\n",
      "Kept 79193 of 115828: 0.6837120558068861\n"
     ]
    }
   ],
   "source": [
    "# Getting the two first speakers of each file\n",
    "dev_a_files_speakers = get_best_speakers(dev_a_files_segments, 2)\n",
    "dev_b_files_speakers = get_best_speakers(dev_b_files_segments, 2)\n",
    "dev_c_files_speakers = get_best_speakers(dev_c_files_segments, 2)\n",
    "\n",
    "# Removing single-speaker files\n",
    "'''delete = [file_id for file_id, speakers_names in dev_a_files_speakers.items() if len(speakers_names) < 2]\n",
    "for file_id in delete:\n",
    "    del dev_a_files_speakers[file_id]\n",
    "delete = [file_id for file_id, speakers_names in dev_b_files_speakers.items() if len(speakers_names) < 2]\n",
    "for file_id in delete:\n",
    "    del dev_b_files_speakers[file_id]\n",
    "delete = [file_id for file_id, speakers_names in dev_c_files_speakers.items() if len(speakers_names) < 2]\n",
    "for file_id in delete:\n",
    "    del dev_c_files_speakers[file_id]'''\n",
    "\n",
    "# Filtering segments that only contain speakers from the list\n",
    "dev_a_files_segments_lim = limit_segments_speakers_names(dev_a_files_segments, dev_a_files_speakers, log = True)\n",
    "dev_b_files_segments_lim = limit_segments_speakers_names(dev_b_files_segments, dev_b_files_speakers, log = True)\n",
    "dev_c_files_segments_lim = limit_segments_speakers_names(dev_c_files_segments, dev_c_files_speakers, log = True)\n",
    "\n",
    "# Filtering segments thath only contain one speaker\n",
    "dev_a_files_segments_lim = limit_segments_speakers_length(dev_a_files_segments_lim, 1, log = True)\n",
    "dev_b_files_segments_lim = limit_segments_speakers_length(dev_b_files_segments_lim, 1, log = True)\n",
    "dev_c_files_segments_lim = limit_segments_speakers_length(dev_c_files_segments_lim, 1, log = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "def invert_speaker_weights(speakers_weights):\n",
    "    weight_sum = sum(speakers_weights.values())\n",
    "    weight_count = len(speakers_weights.values())\n",
    "    speakers_weights_inverse = {}\n",
    "    for speaker_name, weight in speakers_weights.items():\n",
    "        speakers_weights_inverse[speaker_name] = (weight_sum - speakers_weights[speaker_name]) / ((weight_count - 1) * weight_sum)\n",
    "    return speakers_weights_inverse\n",
    "\n",
    "class Files_dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 files_segments,\n",
    "                 models_generation_lengths = [3, 5, 7],\n",
    "                 models_container_length = 2,\n",
    "                 include_zeros = True,\n",
    "                 include_overlaps = False,\n",
    "                 feature = 'ivectors',\n",
    "                 zeros_multiplier = 1):\n",
    "        self.files_segments = files_segments\n",
    "        self.models_generation_lengths = models_generation_lengths\n",
    "        self.models_container_length = models_container_length\n",
    "        self.include_zeros = include_zeros\n",
    "        self.include_overlaps = include_overlaps\n",
    "        self.feature = feature\n",
    "        self.zeros_multiplier = zeros_multiplier\n",
    "        self.speakers_segments_indexes = {}\n",
    "        self.speakers_models = {}\n",
    "        self.speakers_models_combinations_length = {}\n",
    "        self.complete_turns = {}\n",
    "        self.speakers_permutations = {}\n",
    "        self.speakers_weights = {}\n",
    "        self.lookup = []\n",
    "        self.length = 0\n",
    "        for file_id, segments in self.files_segments.items():\n",
    "            self.speakers_segments_indexes[file_id] = get_speakers_segments_indexes(enumerate(segments))\n",
    "            self.speakers_models[file_id] = get_speakers_models(segments,\n",
    "                                                                self.speakers_segments_indexes[file_id],\n",
    "                                                                self.models_generation_lengths)\n",
    "            self.speakers_models_combinations_length[file_id] = len(self.models_generation_lengths) ** len(self.speakers_models[file_id].keys())            \n",
    "            self.complete_turns[file_id] = 2\n",
    "            \n",
    "            length = self.complete_turns[file_id] * self.speakers_models_combinations_length[file_id] * len(segments)\n",
    "            self.speakers_permutations[file_id] = Permutations(self.speakers_models[file_id].keys(),\n",
    "                                                               length,\n",
    "                                                               self.models_container_length,\n",
    "                                                               self.include_zeros)\n",
    "            speakers_weights = self.speakers_permutations[file_id].get_speakers_names_counts()\n",
    "            if self.include_zeros and '0' in speakers_weights:\n",
    "                speakers_weights['0'] *= (1 / self.zeros_multiplier)\n",
    "            self.speakers_weights[file_id] = invert_speaker_weights(speakers_weights)\n",
    "\n",
    "            self.lookup.append({ 'file_id': file_id, 'onset': self.length, 'end': self.length + length - 1 })\n",
    "            self.length += length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        lookup = [value for value in self.lookup if value['onset'] <= key and key <= value['end']][0]\n",
    "        file_id = lookup['file_id']\n",
    "        index = key - lookup['onset']\n",
    "        segments = self.files_segments[file_id]\n",
    "        permutation = self.speakers_permutations[file_id][index]\n",
    "        _, turn_index = divmod(index, self.speakers_models_combinations_length[file_id] * len(segments))\n",
    "        \n",
    "        model_index, segment_index = divmod(turn_index, len(segments))\n",
    "        \n",
    "        models = {}\n",
    "        models_speakers_names = list(self.speakers_models[file_id].keys())\n",
    "        remainder = model_index\n",
    "        for speaker_name_index, speaker_name in enumerate(models_speakers_names):\n",
    "            models_lengths = [len(self.speakers_models[file_id][speaker_name].keys()) for speaker_name in models_speakers_names[speaker_name_index + 1:]]\n",
    "            if index != len(models_speakers_names) - 1:\n",
    "                model_index, remainder = divmod(remainder, int(np.prod(models_lengths)))\n",
    "            else:\n",
    "                model_index = remainder\n",
    "            models[speaker_name] = self.speakers_models[file_id][speaker_name][list(self.speakers_models[file_id][speaker_name].keys())[model_index]]\n",
    "\n",
    "        models_container = [models[speaker_name] if speaker_name != '0' else { 'ivectors': [Ivector(np.random.uniform(-0.1, 0.1, dimension).astype(np.float32))] } for speaker_name in permutation]\n",
    "        \n",
    "        segment = segments[segment_index]\n",
    "        segment_speakers_names = [speaker.get_name() for speaker in segment.get_speakers()]\n",
    "        \n",
    "        x = [embeddings[self.feature][0].get_value() for embeddings in models_container + [{ 'ivectors': segment.get_ivectors() }]]\n",
    "        if self.include_overlaps:\n",
    "            segment_speaker_name = ','.join(sorted(set(segment_speakers_names)))\n",
    "            y = np.asarray([speaker_name == segment_speaker_name for speaker_name in permutation], dtype = np.float32)\n",
    "        else:\n",
    "            y = np.asarray([speaker_name in segment_speakers_names for speaker_name in permutation], dtype = np.float32) / len(segment_speakers_names)\n",
    "        w =  np.asarray([self.speakers_weights[file_id][speaker_name] for speaker_name in permutation], dtype = np.float32)\n",
    "        \n",
    "        return x, y, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, b, M):\n",
    "        super(Model, self).__init__()\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv1d((M + 1), M ** 3, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(M ** 3, M ** 2, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(M ** 2, M, 3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear((b - 6) * M, M * 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(M * 32, M * 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(M * 16, M),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = torch.stack(x, 1)\n",
    "        x = self.cnn1(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Train_graph:\n",
    "    def __init__(self, training_loss = 1):\n",
    "        self.step = 0\n",
    "        self.training_losses_x = [self.step - 1, self.step]\n",
    "        self.training_losses_y = [training_loss, training_loss]\n",
    "        self.validation_losses_x = None\n",
    "        self.validation_losses_y = None\n",
    "        self.fig = plt.figure()\n",
    "        self.ax = self.fig.add_subplot()\n",
    "        self.training_line, = self.ax.plot(self.training_losses_x, self.training_losses_y, '--', label = 'Training')\n",
    "        self.validation_line = None\n",
    "        self.ax.set_ylim(0, training_loss)\n",
    "        self.ax.set_xlabel('Epoch')\n",
    "        self.ax.set_ylabel('Loss')\n",
    "        self.ax.legend()\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.canvas.flush_events()\n",
    "    def draw(self, training_loss, validaton_loss = None):\n",
    "        self.step += 1\n",
    "        self.training_losses_x.append(self.step)\n",
    "        self.training_losses_y.append(training_loss)\n",
    "        self.training_line.set_xdata(self.training_losses_x)\n",
    "        self.training_line.set_ydata(self.training_losses_y)\n",
    "        if validation_loss is not None:\n",
    "            if self.validation_line is None:\n",
    "                self.validation_losses_x = [self.step - 1]\n",
    "                self.validation_losses_y = [validation_loss]\n",
    "                self.validation_line = self.ax.plot(self.validation_losses_x, self.validation_losses_y, label = 'Validation')[0]\n",
    "                self.ax.legend()\n",
    "            self.validation_losses_x.append(self.step)\n",
    "            self.validation_losses_y.append(validation_loss)\n",
    "            self.validation_line.set_xdata(self.validation_losses_x)\n",
    "            self.validation_line.set_ydata(self.validation_losses_y)\n",
    "        self.ax.set_xlim(0, self.step + 1)\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.canvas.flush_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (mpl.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: mpl.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                width = entry.contentBoxSize.inlineSize;\n",
       "                height = entry.contentBoxSize.blockSize;\n",
       "            } else {\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            canvas.setAttribute('width', width * mpl.ratio);\n",
       "            canvas.setAttribute('height', height * mpl.ratio);\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / mpl.ratio,\n",
       "        fig.canvas.height / mpl.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / mpl.ratio;\n",
       "    fig.root.removeEventListener('remove', this._remove_fig_handler);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / mpl.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function () {\n",
       "    this.close_ws(this, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "    el.addEventListener('remove', this._remove_fig_handler);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"300\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0863, device='cuda:0') tensor(0.0904, device='cuda:0')\r"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "seed = 19970917 #25005233 19970917\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "zeros_multiplier = 1.0\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "a_files_ids = list(dev_a_files_segments_lim.keys())\n",
    "a_validation_files_ids = random.sample(a_files_ids, int(len(a_files_ids) * 0.2))\n",
    "a_train_files_ids = [file_id for file_id in a_files_ids if file_id not in a_validation_files_ids]\n",
    "\n",
    "a_train_files_segments = {}\n",
    "b_train_files_segments = {}\n",
    "c_train_files_segments = {}\n",
    "for file_id in a_train_files_ids:\n",
    "    a_train_files_segments[file_id] = dev_a_files_segments_lim[file_id]\n",
    "    b_train_files_segments[file_id] = dev_b_files_segments_lim[file_id]\n",
    "    c_train_files_segments[file_id] = dev_c_files_segments_lim[file_id]\n",
    "a_validation_files_segments = {}\n",
    "b_validation_files_segments = {}\n",
    "c_validation_files_segments = {}\n",
    "for file_id in a_validation_files_ids:\n",
    "    a_validation_files_segments[file_id] = dev_a_files_segments_lim[file_id]\n",
    "    b_validation_files_segments[file_id] = dev_b_files_segments_lim[file_id]\n",
    "    c_validation_files_segments[file_id] = dev_c_files_segments_lim[file_id]\n",
    "\n",
    "a_train_dataset = Files_dataset(a_train_files_segments, [6],zeros_multiplier = zeros_multiplier)\n",
    "b_train_dataset = Files_dataset(b_train_files_segments, [11],zeros_multiplier = zeros_multiplier)\n",
    "c_train_dataset = Files_dataset(c_train_files_segments, [38],zeros_multiplier = zeros_multiplier)\n",
    "a_train_dataloader = DataLoader(a_train_dataset, batch_size = 32, shuffle = True, num_workers = 8)\n",
    "b_train_dataloader = DataLoader(b_train_dataset, batch_size = 32, shuffle = True, num_workers = 8)\n",
    "c_train_dataloader = DataLoader(c_train_dataset, batch_size = 32, shuffle = True, num_workers = 8)\n",
    "\n",
    "a_validation_dataset = Files_dataset(a_validation_files_segments, [6],zeros_multiplier = zeros_multiplier)\n",
    "b_validation_dataset = Files_dataset(b_validation_files_segments, [11],zeros_multiplier = zeros_multiplier)\n",
    "c_validation_dataset = Files_dataset(c_validation_files_segments, [38],zeros_multiplier = zeros_multiplier)\n",
    "a_validation_dataloader = DataLoader(a_validation_dataset, batch_size = 32, shuffle = True, num_workers = 8)\n",
    "b_validation_dataloader = DataLoader(b_validation_dataset, batch_size = 32, shuffle = True, num_workers = 8)\n",
    "c_validation_dataloader = DataLoader(c_validation_dataset, batch_size = 32, shuffle = True, num_workers = 8)\n",
    "\n",
    "net = Model(dimension, 2).to(device, non_blocking = True)\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.0001)\n",
    "\n",
    "losses = []\n",
    "with torch.no_grad():\n",
    "    for dataloader in [a_train_dataloader]:\n",
    "        for x, y, w in dataloader:\n",
    "            x = [tensor.to(device, non_blocking = True).float() for tensor in x]\n",
    "            y = y.to(device, non_blocking = True).float()\n",
    "            w = w.to(device, non_blocking = True).float()\n",
    "            criterion = nn.BCELoss(w)\n",
    "            y_ = net(x)\n",
    "            loss = criterion(y_, y)\n",
    "            losses.append(loss.data)\n",
    "train_loss = (np.sum(losses) / len(losses)).cpu()\n",
    "\n",
    "train_graph = Train_graph(train_loss)\n",
    "\n",
    "for train_dataloader, validation_dataloader in [(a_train_dataloader, a_validation_dataloader),\n",
    "                                                (b_train_dataloader, b_validation_dataloader),\n",
    "                                                (c_train_dataloader, c_validation_dataloader)]:\n",
    "    for epoch in range(20):\n",
    "        losses = []\n",
    "        for x, y, w in train_dataloader:\n",
    "            x = [tensor.to(device, non_blocking = True).float() for tensor in x]\n",
    "            y = y.to(device, non_blocking = True).float()\n",
    "            w = w.to(device, non_blocking = True).float()\n",
    "\n",
    "            criterion = nn.BCELoss(w)\n",
    "            net.zero_grad()\n",
    "            y_ = net(x)\n",
    "            loss = criterion(y_, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss.data)\n",
    "        train_loss = np.sum(losses) / len(losses)\n",
    "        \n",
    "        validation_losses = []\n",
    "        with torch.no_grad():\n",
    "            for x, y, w in validation_dataloader:\n",
    "                x = [tensor.to(device, non_blocking = True).float() for tensor in x]\n",
    "                y = y.to(device, non_blocking = True).float()\n",
    "                w = w.to(device, non_blocking = True).float()\n",
    "                criterion = nn.BCELoss(w)\n",
    "                y_ = net(x)\n",
    "                loss = criterion(y_, y)\n",
    "                \n",
    "                validation_losses.append(loss)\n",
    "        validation_loss = np.sum(validation_losses) / len(validation_losses)\n",
    "        \n",
    "        train_graph.draw(train_loss, validation_loss)\n",
    "        print(train_loss, validation_loss, end = '\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_eval_rttm     = '../augmented/callhome/callhome2/augmented_0/1.5_0.3_0.5/' + str(dimension) + '/ref.rttm'\n",
    "a_eval_segments = '../augmented/callhome/callhome2/augmented_0/1.5_0.3_0.5/' + str(dimension) + '/segments'\n",
    "a_eval_ivectors = '../augmented/callhome/callhome2/augmented_0/1.5_0.3_0.5/' + str(dimension) + '/exp/make_ivectors/ivector.txt'\n",
    "a_eval_files_segments = get_rttm_segments_features(a_eval_rttm, a_eval_segments, a_eval_ivectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 19828 of 33962: 0.5838289853365526\n",
      "Kept 17773 of 19828: 0.8963586846883196\n"
     ]
    }
   ],
   "source": [
    "# Filtering segments thath only contain one speaker\n",
    "a_eval_files_segments_lim = limit_segments_speakers_length(a_eval_files_segments, 1, log = True)\n",
    "\n",
    "# Getting the two first speakers of each file\n",
    "a_eval_files_speakers_names = get_best_speakers(a_eval_files_segments_lim, 2)\n",
    "\n",
    "# Filtering segments that only contain speakers from the list\n",
    "a_eval_files_segments_lim = limit_segments_speakers_names(a_eval_files_segments_lim, a_eval_files_speakers_names, log = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "der: 17.92\n"
     ]
    }
   ],
   "source": [
    "import kaldi_utils\n",
    "\n",
    "class File_dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 segments,\n",
    "                 models_generation_length,\n",
    "                 models_container_speakers_names,\n",
    "                 models_container_length = None,\n",
    "                 include_overlaps = False,\n",
    "                 feature = 'ivectors'):\n",
    "        self.segments = segments\n",
    "        self.models_generation_length = models_generation_length\n",
    "        self.models_container_speakers_names = models_container_speakers_names\n",
    "        self.models_container_length = models_container_length if isinstance(models_container_length, int) else len(models_container_speakers_names)\n",
    "        if len(self.models_container_speakers_names) < self.models_container_length:\n",
    "            self.models_container_speakers_names += ['0' for index in range(self.models_container_length - len(self.models_container_speakers_names))]\n",
    "        self.include_overlaps = include_overlaps\n",
    "        self.feature = feature\n",
    "        \n",
    "        speakers_segments_indexes = get_speakers_segments_indexes(enumerate(segments))\n",
    "        self.speakers_models = get_speakers_models(self.segments,\n",
    "                                                   speakers_segments_indexes,\n",
    "                                                   [self.models_generation_length])\n",
    "        self.models_container = [self.speakers_models[speaker_name][self.models_generation_length] if speaker_name != '0' else { 'ivectors': [Ivector(np.random.uniform(-0.1, 0.1, dimension).astype(np.float32))] } for speaker_name in self.models_container_speakers_names]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.segments)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        segment = self.segments[key]\n",
    "        x = [embeddings[self.feature][0].get_value() for embeddings in self.models_container + [{ 'ivectors': segment.get_ivectors() }]]\n",
    "        segment_speakers_names = [speaker.get_name() for speaker in segment.get_speakers()]\n",
    "        if self.include_overlaps:\n",
    "            segment_speaker_name = ','.join(sorted(set(segment_speakers_names)))\n",
    "            y = np.asarray([speaker_name == segment_speaker_name for speaker_name in self.models_container_speakers_names], dtype = np.float32)\n",
    "        else:\n",
    "            y = np.asarray([speaker_name in segment_speakers_names for speaker_name in self.models_container_speakers_names], dtype = np.float32) / len(segment_speakers_names)\n",
    "        return x, y, key\n",
    "    \n",
    "def get_custom_rttm(segment, speaker_name):\n",
    "    return segment.get_type() + ' ' + \\\n",
    "        segment.get_file_id() + ' ' + \\\n",
    "        segment.get_speakers()[0].get_channel_id() + ' ' + \\\n",
    "        str(round(segment.get_turn_onset(), 3)) + ' ' + \\\n",
    "        str(round(segment.get_turn_duration(), 3)) + ' ' + \\\n",
    "        segment.get_orthography_field() + ' ' + \\\n",
    "        segment.get_speakers()[0].get_type() + ' ' + \\\n",
    "        speaker_name + ' ' + \\\n",
    "        segment.get_confidence_score() + ' ' + \\\n",
    "        segment.get_signal_lookahead_time() + '\\n'\n",
    "    \n",
    "def net_scoring(x, net, device):\n",
    "    with torch.no_grad():\n",
    "        x = [tensor.to(device) for tensor in x]\n",
    "        y_ = net(x)\n",
    "        return y_.cpu().numpy()[0]\n",
    "\n",
    "def track(files_segments, files_speakers_names, write_folder = None):\n",
    "    groundtruth_rttm = ''\n",
    "    resuts_rttm = ''\n",
    "    for file_id, segments in files_segments.items():\n",
    "        file_dataset = File_dataset(segments, 6, files_speakers_names[file_id], 2)\n",
    "        file_dataloader = DataLoader(file_dataset)\n",
    "        for x, _, segment_index in file_dataloader:\n",
    "            segment_index = segment_index.numpy()[0]\n",
    "            segment = segments[segment_index]\n",
    "            y_ = net_scoring(x, net, device)\n",
    "            index = np.argmax(y_)\n",
    "            \n",
    "            groundtruth_rttm += segment.get_rttm()\n",
    "            resuts_rttm += get_custom_rttm(segment, str(index))\n",
    "            \n",
    "    if write_folder is not None:\n",
    "        !mkdir -p $write_folder\n",
    "        \n",
    "        file = open(write_folder + '/groundtruth.rttm', 'w')\n",
    "        file.write(groundtruth_rttm)\n",
    "        file.close()\n",
    "        \n",
    "        file = open(write_folder + '/results.rttm', 'w')\n",
    "        file.write(resuts_rttm)\n",
    "        file.close()\n",
    "        \n",
    "        der = kaldi_utils.md_eval(write_folder + '/groundtruth.rttm', write_folder + '/results.rttm', write_folder)\n",
    "        \n",
    "        print('der:', der)\n",
    "            \n",
    "track(a_eval_files_segments_lim, a_eval_files_speakers_names, 'batch/20200804')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_validation_files_speakers_names = get_best_speakers(a_validation_files_segments, 2)\n",
    "\n",
    "track(a_validation_files_segments, a_validation_files_speakers_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_train_files_speakers_names = get_best_speakers(a_train_files_segments, 2)\n",
    "\n",
    "track(a_train_files_segments, a_train_files_speakers_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
