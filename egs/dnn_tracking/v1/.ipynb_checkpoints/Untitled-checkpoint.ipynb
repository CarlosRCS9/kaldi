{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_vector = 'xvectors'\n",
    "conf_vector_length = 128\n",
    "conf_models_generation_length = 5\n",
    "conf_models_container_length = 2\n",
    "conf_permutations_include_zeros = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from functools import reduce\n",
    "\n",
    "# is_valid_segment [DONE]\n",
    "def is_valid_segment(segment):\n",
    "    return len(segment['speakers']) == 1 \\\n",
    "            and len(segment['ivectors']) == 1 \\\n",
    "            and len(segment['xvectors']) == 1 \\\n",
    "            and segment['speakers'][0]['speaker_id'] in ['A', 'B']\n",
    "\n",
    "# load_recordings_segments [DONE]\n",
    "def load_recordings_segments(directory):\n",
    "    filenames = [filename for filename in os.listdir(directory) if os.path.isfile(os.path.join(directory, filename))]\n",
    "    recordings_segments = {}\n",
    "    recordings_length = len(filenames)\n",
    "    recordings_count = 0\n",
    "    for filename in filenames:\n",
    "        recording_id = filename.split('.')[0]\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        file = open(filepath, 'r')\n",
    "        recordings_segments[recording_id] = [json.loads(line) for line in file.readlines()]\n",
    "        file.close()\n",
    "        recordings_segments[recording_id] = list(filter(is_valid_segment, recordings_segments[recording_id]))\n",
    "        recordings_count += 1\n",
    "        print('Loading ' + directory + ' ' + str(recordings_count) + '/' + str(recordings_length), end = '\\r')\n",
    "    return recordings_segments\n",
    "\n",
    "# speakers_get_indexes [DONE]\n",
    "def speakers_get_indexes(accumulator, speaker_tuple):\n",
    "    speaker_id, index = speaker_tuple\n",
    "    if speaker_id in accumulator:\n",
    "        accumulator[speaker_id].append(index)\n",
    "    else:\n",
    "        accumulator[speaker_id] = [index]\n",
    "    return accumulator\n",
    "\n",
    "# balance_segments [DONE]\n",
    "def balance_segments(recordings_segments, minimum_speakers, minimum_speaker_length):\n",
    "    new_recordings_segments = {}\n",
    "    for recording_id in recordings_segments:\n",
    "        recording_segments = recordings_segments[recording_id]\n",
    "        speakers_indexes = [(segment['speakers'][0]['speaker_id'], index) for index, segment in enumerate(recording_segments)]\n",
    "        speakers_indexes = reduce(speakers_get_indexes, speakers_indexes, {})\n",
    "        speakers_lengths = [(speaker_id, len(speakers_indexes[speaker_id])) for speaker_id in speakers_indexes]\n",
    "        speakers_lengths.sort(key = lambda x: x[1])\n",
    "        speakers_lengths_min = speakers_lengths[0][1]\n",
    "        if len(speakers_lengths) >= minimum_speakers and speakers_lengths_min >= minimum_speaker_length:\n",
    "            recording_indexes = []\n",
    "            for speaker_id in speakers_indexes:\n",
    "                speakers_indexes[speaker_id] = speakers_indexes[speaker_id][:speakers_lengths_min]\n",
    "                recording_indexes += speakers_indexes[speaker_id]\n",
    "            new_recordings_segments[recording_id] = [segment for index, segment in enumerate(recordings_segments[recording_id]) if index in recording_indexes]\n",
    "    print('Recordings left: ' + str(len(new_recordings_segments)) + '/' + str(len(recordings_segments)))\n",
    "    return new_recordings_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recordings left: 172/249on 249/249\n"
     ]
    }
   ],
   "source": [
    "callhome1_segments = load_recordings_segments('exp/callhome1/json')\n",
    "callhome1_segments_cut = balance_segments(callhome1_segments, 2, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "class Recordings_dataset(Dataset):\n",
    "    def __init__(self, recordings_segments, recordings_ids):\n",
    "        self.recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "        self.recordings_segments = {}\n",
    "        for recording_id in self.recordings_ids:\n",
    "            self.recordings_segments[recording_id] = recordings_segments[recording_id]\n",
    "        self.mode = conf_vector\n",
    "        self.models_generation_length = conf_models_generation_length\n",
    "        self.models_container_length = conf_models_container_length\n",
    "        self.permutations_include_zeros = conf_permutations_include_zeros\n",
    "        self.recordings_data = {}\n",
    "        self.recordings_map = []\n",
    "        self.recordings_length = 0\n",
    "        for recording_id in self.recordings_ids:\n",
    "            self.recordings_data[recording_id] = {}\n",
    "            recording_segments = self.recordings_segments[recording_id]\n",
    "            recording_data = self.recordings_data[recording_id]\n",
    "            recording_data['speakers_indexes'] = [(segment['speakers'][0]['speaker_id'], index) for index, segment in enumerate(recording_segments)]\n",
    "            recording_data['speakers_indexes'] = reduce(speakers_get_indexes, recording_data['speakers_indexes'], {})\n",
    "            recording_data['speakers_indexes_lengths_max'] = max([len(recording_data['speakers_indexes'][speaker_id]) for speaker_id in recording_data['speakers_indexes']])\n",
    "            recording_data['speakers_models'] = {}\n",
    "            for speaker_id in recording_data['speakers_indexes']:\n",
    "                speaker_indexes = recording_data['speakers_indexes'][speaker_id]\n",
    "                speaker_vectors = [np.asarray(recording_segments[index][self.mode][0]['value']) for index in speaker_indexes[:self.models_generation_length]]\n",
    "                recording_data['speakers_models'][speaker_id] = [np.sum(speaker_vectors, 0) / len(speaker_vectors)]\n",
    "            if self.permutations_include_zeros:\n",
    "                recording_data['permutations'] = list(itertools.permutations(list(recording_data['speakers_models'].keys()) \\\n",
    "                + ['0' for i in range(self.models_container_length)], self.models_container_length))\n",
    "            else:\n",
    "                recording_data['permutations'] = list(itertools.permutations(list(recording_data['speakers_models'].keys()), self.models_container_length))\n",
    "            recording_data['permutations'] = list(set(recording_data['permutations']))\n",
    "            recording_data['permutations'].sort()\n",
    "            recording_data['permutations_map'] = []\n",
    "            recording_data['permutations_length'] = 0\n",
    "            for index, permutation in enumerate(recording_data['permutations']):\n",
    "                speakers_models_length = int(np.prod([len(recording_data['speakers_models'][speaker_id]) for speaker_id in permutation if speaker_id != '0']))\n",
    "                recording_data['permutations_map'].append((recording_data['permutations_length'], recording_data['permutations_length'] + speakers_models_length - 1, index))\n",
    "                recording_data['permutations_length'] += speakers_models_length\n",
    "            recording_data['length'] = len(recording_segments) * recording_data['permutations_length']\n",
    "            self.recordings_map.append((self.recordings_length, self.recordings_length + recording_data['length'] - 1, recording_id))\n",
    "            self.recordings_length += recording_data['length']\n",
    "    def __len__(self):\n",
    "        return self.recordings_length\n",
    "    def __getitem__(self, idx):\n",
    "        recording_tuple = list(filter(lambda recording_tuple: recording_tuple[0] <= idx and idx <= recording_tuple[1], self.recordings_map))[0]\n",
    "        recording_idx = idx - recording_tuple[0]\n",
    "        recording_id = recording_tuple[2]\n",
    "        recording_data = self.recordings_data[recording_id]\n",
    "        \n",
    "        segment_id, segment_idx = divmod(recording_idx, recording_data['permutations_length'])\n",
    "        segment = self.recordings_segments[recording_id][segment_id]\n",
    "        target_id = segment['speakers'][0]['speaker_id']\n",
    "        vector = np.asarray(segment[self.mode][0]['value'])\n",
    "        \n",
    "        permutation_tuple = list(filter(lambda permutation_tuple: permutation_tuple[0] <= segment_idx and segment_idx <= permutation_tuple[1], recording_data['permutations_map']))[0]\n",
    "        permutation_id = permutation_tuple[2]\n",
    "        permutation = recording_data['permutations'][permutation_id]\n",
    "        \n",
    "        models_container = [np.asarray(recording_data['speakers_models'][speaker_id][0]) if speaker_id != '0' else np.random.uniform(-0.1, 0.1, len(vector)) for speaker_id in permutation]\n",
    "        models_weigths = np.asarray([len(recording_data['speakers_indexes'][speaker_id]) if speaker_id != '0' else recording_data['speakers_indexes_lengths_max'] for speaker_id in permutation])\n",
    "        models_weigths_sum = np.sum(models_weigths)\n",
    "        models_weigths = np.ones(len(models_weigths)) - models_weigths / models_weigths_sum\n",
    "        \n",
    "        x = [vector] + models_container\n",
    "        y = np.asarray([speaker_id == target_id for speaker_id in permutation], dtype = float)\n",
    "        z = models_weigths\n",
    "        \n",
    "        return x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings_dataset = Recordings_dataset(callhome1_segments_cut, [recording_id for recording_id in callhome1_segments_cut])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def plda_score(ref_vector, test_vector):\n",
    "    ref_string = str(list(ref_vector)).replace(',', '').replace('[', '[ ').replace(']', ' ]')\n",
    "    test_string = str(list(test_vector)).replace(',', '').replace('[', '[ ').replace(']', ' ]')\n",
    "    bin = './plda_score.sh'\n",
    "    p = subprocess.Popen([bin, ref_string, test_string], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output, err = p.communicate()\n",
    "    rc = p.returncode\n",
    "    if rc == 0:\n",
    "        #lines =  output.decode(\"utf-8\").split('\\n')\n",
    "        #derLine = [line for line in lines if 'OVERALL SPEAKER DIARIZATION ERROR' in line][0]\n",
    "        #return float(re.findall('\\d+\\.\\d+', derLine)[0])\n",
    "        print(output)\n",
    "    else:\n",
    "        print(err)\n",
    "        exit('plda_socre.sh fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'ivector-plda-scoring: error while loading shared libraries: libkaldi-ivector.so: cannot open shared object file: No such file or directory\\n'\n"
     ]
    }
   ],
   "source": [
    "input, target, weigth = recordings_dataset[0]\n",
    "plda_score(input[0], input[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
