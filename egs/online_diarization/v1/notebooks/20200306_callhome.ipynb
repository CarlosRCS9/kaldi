{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# is_valid_segment [DONE]\n",
    "def is_valid_segment(segment, valid_speakers_length = 2, valid_speakers_ids = ['A', 'B']):\n",
    "    speakers_ids = [speaker['speaker_id'] for speaker in segment['speakers']]\n",
    "    speakers_ids = list(set(speakers_ids))\n",
    "    return len(speakers_ids) <= valid_speakers_length and \\\n",
    "        all(speaker_id in valid_speakers_ids for speaker_id in speakers_ids)\n",
    "\n",
    "# load_recordings_segments [DONE]\n",
    "def load_recordings_segments(directory):\n",
    "    filenames = [filename for filename in os.listdir(directory) if os.path.isfile(os.path.join(directory, filename))]\n",
    "    filenames.sort()\n",
    "    recordings_segments = {}\n",
    "    recordings_length = len(filenames)\n",
    "    recordings_count = 0\n",
    "    segments_original = 0\n",
    "    segments_filtered = 0\n",
    "    for filename in filenames:\n",
    "        recording_id = filename.split('.')[0]\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        file = open(filepath, 'r')\n",
    "        recordings_segments[recording_id] = [json.loads(line) for line in file.readlines()]\n",
    "        file.close()\n",
    "        segments_original += len(recordings_segments[recording_id])\n",
    "        recordings_segments[recording_id] = list(filter(is_valid_segment, recordings_segments[recording_id]))\n",
    "        segments_filtered += len(recordings_segments[recording_id])\n",
    "        recordings_count += 1\n",
    "        print(directory + ' loading ' + str(recordings_count) + '/' + str(recordings_length), end = '\\r')\n",
    "    print(directory, 'loaded', str(recordings_count) + '/' + str(recordings_length) + ',', round(segments_filtered / segments_original, 2), 'segments left.')\n",
    "    return recordings_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../exp/pre_norm/callhome1/json loaded 249/249, 0.74 segments left.\n"
     ]
    }
   ],
   "source": [
    "callhome1_recordings_segments = load_recordings_segments('../exp/pre_norm/callhome1/json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../exp/pre_norm/callhome2/json loaded 250/250, 0.77 segments left.\n"
     ]
    }
   ],
   "source": [
    "callhome2_recordings_segments = load_recordings_segments('../exp/pre_norm/callhome2/json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from functools import reduce\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# speakers_get_indexes [DONE]\n",
    "def speakers_get_indexes(accumulator, speakers_tuple):\n",
    "    speaker_ids, index = speakers_tuple\n",
    "    speaker_ids = ','.join(speaker_ids)\n",
    "    if speaker_ids in accumulator:\n",
    "        accumulator[speaker_ids].append(index)\n",
    "    else:\n",
    "        accumulator[speaker_ids] = [index]\n",
    "    return accumulator\n",
    "\n",
    "def generate_speaker_model(recording_segments,\n",
    "                           speaker_indexes,\n",
    "                           segments_length,\n",
    "                           vector = 'ivectors',\n",
    "                           selection = 'first',\n",
    "                           indexes = []):\n",
    "    if segments_length > len(speaker_indexes):\n",
    "        print('WARNING: there are less speaker indexes than segments.')\n",
    "    if selection == 'first':\n",
    "        selected_segments = [segment for index, segment in enumerate(recording_segments) if index in speaker_indexes[:segments_length]]\n",
    "    elif selection == 'random':\n",
    "        selected_segments = [recording_segments[index] for index in random.sample(speaker_indexes, segments_length if segments_length < len(speaker_indexes) else len(speaker_indexes))]\n",
    "    elif selection == 'indexes':\n",
    "        selected_segments = [recording_segments[index] for index in indexes]\n",
    "    else:\n",
    "        print('ERROR: unknown speaker model segments selection strategy.')\n",
    "    selected_vectors = [np.asarray(segment[vector][0]['value']) for segment in selected_segments]\n",
    "    return np.sum(selected_vectors, 0) / len(selected_vectors)\n",
    "    \n",
    "\n",
    "class Recordings_dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 recordings_segments,\n",
    "                 recordings_ids = None,\n",
    "                 vector = 'ivectors',\n",
    "                 models_container_length = 2,\n",
    "                 models_container_include_zeros = True,\n",
    "                 models_container_include_overlaps = False,\n",
    "                 models_generation_lengths = [3, 4],\n",
    "                 models_generation_selection = 'first',\n",
    "                 balance_segments = True,\n",
    "                 balance_segments_selection = 'copy'):\n",
    "        # -----------------------------------------------------Saving input data----- #\n",
    "        if recordings_ids is None:\n",
    "            recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "        self.recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "        self.recordings_segments = {}\n",
    "        for recording_id in self.recordings_ids:\n",
    "            self.recordings_segments[recording_id] = recordings_segments[recording_id]\n",
    "        self.vector = vector\n",
    "        self.models_container_length = models_container_length\n",
    "        self.models_container_include_zeros = models_container_include_zeros\n",
    "        self.models_container_include_overlaps = models_container_include_overlaps\n",
    "        self.models_generation_lengths = models_generation_lengths\n",
    "        self.models_generation_selection = models_generation_selection\n",
    "        self.balance_segments = balance_segments\n",
    "        self.balance_segments_selection = balance_segments_selection\n",
    "        # --------------------------------------------------------------------------- #\n",
    "        self.recordings_data = {}\n",
    "        # -------------------------------------------------- #\n",
    "        self.recordings_map = []\n",
    "        self.recordings_length = 0\n",
    "        for recording_id in self.recordings_ids:\n",
    "            self.recordings_data[recording_id] = {}\n",
    "            recording_segments = self.recordings_segments[recording_id]\n",
    "            recording_data = self.recordings_data[recording_id]\n",
    "            # ----- Obtaining speakers indexes ----- #\n",
    "            recording_data['speakers_indexes'] = [(sorted(list(set([speaker['speaker_id'] for speaker in segment['speakers']]))), index) for index, segment in enumerate(recording_segments)]\n",
    "            recording_data['speakers_indexes'] = reduce(speakers_get_indexes, recording_data['speakers_indexes'], {})\n",
    "            # ----- Balancing speakers segments ----- #\n",
    "            recording_data['speakers_indexes_lengths_max'] = max([len(recording_data['speakers_indexes'][speakers_ids]) for speakers_ids in recording_data['speakers_indexes']])\n",
    "            if self.balance_segments:\n",
    "                if self.balance_segments_selection == 'copy':\n",
    "                    for speakers_ids in recording_data['speakers_indexes']:\n",
    "                        for i in range(recording_data['speakers_indexes_lengths_max'] - len(recording_data['speakers_indexes'][speakers_ids])):\n",
    "                            index = random.choice(recording_data['speakers_indexes'][speakers_ids])\n",
    "                            recording_segments.append(recording_segments[index])\n",
    "                            recording_data['speakers_indexes'][speakers_ids].append(len(recording_segments) - 1)\n",
    "                else:\n",
    "                    print('ERROR: unknown balancing segments selection strategy.')\n",
    "            # ----- Generating speakers models ----- #\n",
    "            recording_data['speakers_models'] = {}\n",
    "            for speakers_ids in recording_data['speakers_indexes']:\n",
    "                recording_data['speakers_models'][speakers_ids] = {}\n",
    "                for models_generation_length in models_generation_lengths:\n",
    "                    speakers_model = generate_speaker_model(recording_segments, recording_data['speakers_indexes'][speakers_ids], models_generation_length, self.vector, self.models_generation_selection)\n",
    "                    recording_data['speakers_models'][speakers_ids][models_generation_length] = [speakers_model]\n",
    "            # ----- Generating permutations ----- #\n",
    "            if self.models_container_include_zeros:\n",
    "                recording_data['permutations'] = list(itertools.permutations(list(recording_data['speakers_models'].keys()) \\\n",
    "                + ['0' for i in range(self.models_container_length)], self.models_container_length))\n",
    "            else:\n",
    "                recording_data['permutations'] = list(itertools.permutations(list(recording_data['speakers_models'].keys()), self.models_container_length))\n",
    "            recording_data['permutations'] = list(set(recording_data['permutations']))\n",
    "            recording_data['permutations'].sort()\n",
    "            if not self.models_container_include_overlaps:\n",
    "                recording_data['permutations'] = [permutation for permutation in recording_data['permutations'] if all(len(speakers_ids.split(',')) == 1 for speakers_ids in permutation)]\n",
    "            # -------------------------------------------------- #\n",
    "            recording_data['permutations_map'] = []\n",
    "            recording_data['permutations_length'] = 0\n",
    "            for index, permutation in enumerate(recording_data['permutations']):\n",
    "                speakers_models_length = int(np.prod([np.sum([len(recording_data['speakers_models'][speakers_ids][models_generation_length]) for models_generation_length in recording_data['speakers_models'][speakers_ids]]) for speakers_ids in permutation if speakers_ids != '0']))\n",
    "                recording_data['permutations_map'].append((recording_data['permutations_length'], recording_data['permutations_length'] + speakers_models_length - 1, index))\n",
    "                recording_data['permutations_length'] += speakers_models_length\n",
    "            recording_data['length'] = len(recording_segments) * recording_data['permutations_length']\n",
    "            self.recordings_map.append((self.recordings_length, self.recordings_length + recording_data['length'] - 1, recording_id))\n",
    "            self.recordings_length += recording_data['length']\n",
    "    def __len__(self):\n",
    "        return self.recordings_length\n",
    "    def __getitem__(self, idx):\n",
    "        recording_limits = list(filter(lambda recording_limits: recording_limits[0] <= idx and idx <= recording_limits[1], self.recordings_map))[0]\n",
    "        recording_idx = idx - recording_limits[0]\n",
    "        recording_id = recording_limits[2]\n",
    "        recording_data = self.recordings_data[recording_id]\n",
    "        \n",
    "        segment_index, segment_idx = divmod(recording_idx, recording_data['permutations_length'])\n",
    "        segment = self.recordings_segments[recording_id][segment_index]\n",
    "        vector = np.asarray(segment[self.vector][0]['value'])\n",
    "        \n",
    "        permutation_limits = list(filter(lambda permutation_limits: permutation_limits[0] <= segment_idx and segment_idx <= permutation_limits[1], recording_data['permutations_map']))[0]\n",
    "        permutation_idx = segment_idx - permutation_limits[0]\n",
    "        permutation_index = permutation_limits[2]\n",
    "        permutation = recording_data['permutations'][permutation_index]\n",
    "        \n",
    "        speakers_models_lengths = [np.sum([len(recording_data['speakers_models'][speakers_ids][models_generation_length]) for models_generation_length in recording_data['speakers_models'][speakers_ids]])  if speakers_ids != '0' else 1 for speakers_ids in permutation]\n",
    "        models_container = []\n",
    "        model_index = permutation_idx\n",
    "        for i, length_i in enumerate(speakers_models_lengths):\n",
    "            if i != len(speakers_models_lengths) - 1:\n",
    "                model_index, remainder = divmod(model_index, np.sum(speakers_models_lengths[i + 1:]))\n",
    "            else:\n",
    "                model_index = remainder\n",
    "            models_container.append(recording_data['speakers_models'][permutation[i]][self.models_generation_lengths[model_index]][0] if permutation[i] != '0' else np.random.uniform(-0.1, 0.1, len(vector)))\n",
    "        \n",
    "        models_weigths = np.asarray([len(recording_data['speakers_indexes'][speakers_ids]) if speakers_ids != '0' else recording_data['speakers_indexes_lengths_max'] for speakers_ids in permutation])\n",
    "        models_weigths_sum = np.sum(models_weigths)\n",
    "        models_weigths = np.ones(len(models_weigths)) - models_weigths / models_weigths_sum\n",
    "        \n",
    "        targets_ids = [speaker['speaker_id'] for speaker in segment['speakers']]\n",
    "        \n",
    "        x = [vector] + models_container\n",
    "        if self.models_container_include_overlaps:\n",
    "            targets_ids = ','.join(sorted(list(set(targets_ids))))\n",
    "            y = np.asarray([speakers_ids == targets_ids for speakers_ids in permutation], dtype = float)\n",
    "        else:\n",
    "            y = np.asarray([speaker_id in targets_ids for speaker_id in permutation], dtype = float) / len(targets_ids)\n",
    "        z = models_weigths\n",
    "        \n",
    "        return x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1150356\n",
      "([array([ 0.3519602 ,  4.005612  , -0.9051194 ,  0.427141  , -0.5701674 ,\n",
      "        1.003131  ,  2.235364  ,  1.921338  , -3.015491  , -1.534834  ,\n",
      "        1.217496  ,  0.710883  , -0.4937762 , -1.104113  , -0.9110618 ,\n",
      "       -0.167288  ,  1.414095  , -0.1112232 , -0.6965439 ,  0.6867012 ,\n",
      "       -0.7766348 , -0.04425273,  0.4530951 , -1.876562  , -0.04310996,\n",
      "       -0.7285927 , -2.392449  , -1.250621  , -0.370301  , -0.9466311 ,\n",
      "       -1.463477  , -0.7710519 ,  1.655105  , -0.7872185 ,  0.2859635 ,\n",
      "        0.8824552 ,  0.1180109 , -0.1328261 ,  0.6444096 , -1.067963  ,\n",
      "        0.4666332 ,  0.680375  ,  0.00625678,  1.387998  , -1.354118  ,\n",
      "        0.4809265 ,  0.5807109 , -0.762727  , -0.3915525 ,  1.229105  ,\n",
      "       -1.247902  , -0.3112767 , -0.1510374 ,  1.076944  , -1.710107  ,\n",
      "       -0.2918752 , -0.5748917 ,  1.470002  ,  0.5160106 , -0.925755  ,\n",
      "       -1.05996   , -0.7791965 ,  0.4565023 , -0.0949901 ,  0.04555997,\n",
      "       -1.829623  ,  1.14681   , -0.4794345 , -1.455163  , -0.7890527 ,\n",
      "        0.3561657 , -0.5559001 ,  1.426413  ,  0.6440983 , -0.7897372 ,\n",
      "        0.6832949 ,  0.6340429 , -0.5566473 , -1.719079  ,  1.63533   ,\n",
      "       -0.03703713, -0.6556488 , -0.8365966 ,  0.3240997 ,  0.5598972 ,\n",
      "       -0.965958  , -0.2414842 , -0.1996214 ,  0.2655578 ,  0.06657741,\n",
      "       -0.3409776 , -0.9333175 , -0.3609016 , -1.128814  , -1.018725  ,\n",
      "        0.09407683,  0.8852803 , -0.813305  , -0.2700548 , -0.06571241,\n",
      "       -0.6560531 ,  0.2729629 , -1.110421  , -0.2958674 , -0.6157938 ,\n",
      "        0.1812155 ,  1.161196  ,  1.097816  , -0.6307182 , -0.3168221 ,\n",
      "        0.2325246 ,  0.2632913 , -0.4164332 , -0.04552158, -0.2218413 ,\n",
      "       -0.1623497 , -0.7682337 , -0.2304497 , -1.10449   ,  0.4418797 ,\n",
      "        0.4156742 ,  0.03982199,  0.6050134 , -0.6068442 ,  1.550861  ,\n",
      "        0.07800397, -0.4374412 , -0.3903607 ]), array([-0.09666753,  0.0155578 ,  0.08204204,  0.05878777,  0.00566624,\n",
      "       -0.09401739, -0.04817826,  0.03869969,  0.00682775,  0.01246033,\n",
      "        0.03947884,  0.01535037,  0.01597027,  0.03737188, -0.03826645,\n",
      "       -0.05215591,  0.09814976, -0.01214601, -0.06258405,  0.06550329,\n",
      "        0.06248454,  0.04135746,  0.01836911,  0.01648039, -0.09197176,\n",
      "       -0.00236424, -0.06153618,  0.00633273, -0.06742503,  0.01267128,\n",
      "       -0.0975071 ,  0.01937564, -0.01304634,  0.0643986 ,  0.04955129,\n",
      "       -0.08599744, -0.02599848,  0.01678658,  0.09680723, -0.0861981 ,\n",
      "        0.05092183,  0.05755798, -0.04841107, -0.01995579, -0.0964462 ,\n",
      "        0.03020501,  0.0957275 , -0.04557058, -0.0359943 ,  0.02023985,\n",
      "        0.01473513,  0.04091587,  0.0608083 ,  0.05283183,  0.01627414,\n",
      "       -0.07803589,  0.07260626, -0.00397542, -0.0869987 ,  0.0046919 ,\n",
      "       -0.02576201, -0.02385544, -0.02814653,  0.08805636, -0.03417429,\n",
      "        0.04702963,  0.0485925 , -0.02824067,  0.01691704,  0.05542966,\n",
      "        0.054383  , -0.07933067,  0.07349638, -0.05074364, -0.05520565,\n",
      "       -0.01423804, -0.00681603, -0.03432447, -0.08109605,  0.04656063,\n",
      "        0.09713105,  0.07270551,  0.01146924, -0.04763946, -0.00621212,\n",
      "       -0.03735942, -0.00599039, -0.02187068,  0.09081401, -0.08432897,\n",
      "        0.09316329, -0.02317569,  0.09970332,  0.09354044, -0.07642623,\n",
      "        0.01264856,  0.02864654, -0.07692247,  0.02635833,  0.04847873,\n",
      "       -0.03810525, -0.05498879, -0.05122414,  0.05229485,  0.07719492,\n",
      "        0.00589432, -0.01171448,  0.00212291,  0.05552152, -0.07833769,\n",
      "       -0.02311258,  0.02897052, -0.01252513, -0.01105307,  0.02194468,\n",
      "        0.04868845, -0.09665291,  0.09661825, -0.07256214,  0.00648104,\n",
      "       -0.0937911 , -0.07931023,  0.07325745, -0.04101578, -0.07618117,\n",
      "        0.068757  , -0.09600018,  0.03887053]), array([ 0.29846913,  3.063003  , -0.37082603,  0.57728687,  0.64751833,\n",
      "        0.46410915,  1.34926833,  0.33313998, -1.97571367,  0.02509833,\n",
      "        2.980881  ,  1.861203  ,  0.2857427 ,  0.74158559,  1.364907  ,\n",
      "        0.87035898, -0.02006915,  1.06369303, -0.21197387,  1.92430433,\n",
      "        1.30765383,  1.04431763,  0.89404657, -0.38902133,  0.29314867,\n",
      "       -0.98607867, -1.13756   ,  1.01325893, -1.34045787, -1.3521596 ,\n",
      "        1.23316433,  0.5404597 ,  2.436267  , -0.76092327, -0.89952827,\n",
      "        1.46343693, -1.00463647, -1.79113467,  1.51084013, -0.10718378,\n",
      "        1.19149047,  0.8344826 , -1.11200433, -0.16927753,  2.20775933,\n",
      "        0.40948067,  0.2811952 , -1.09196433,  0.7945484 ,  0.34918997,\n",
      "        0.02484753, -0.2002304 ,  2.2217075 ,  1.0069744 , -0.3290944 ,\n",
      "       -0.25984313,  0.06166137, -0.11007067,  1.00310727, -0.71038797,\n",
      "        0.26963605, -0.49681083,  0.5140767 ,  1.0975456 , -0.93573887,\n",
      "        0.63920649,  0.32470286,  1.462492  , -0.86323483,  0.30983137,\n",
      "        1.511255  , -0.2730307 , -0.22264477,  1.95349567,  0.12741233,\n",
      "        0.78308323,  0.64192016,  0.52748368,  0.33215391,  1.02512167,\n",
      "       -0.70009027, -0.25885487, -0.99121963,  0.06173732, -0.619783  ,\n",
      "        0.9034707 ,  1.15632853,  0.40132169,  0.63784147, -0.7912033 ,\n",
      "        0.00780767, -0.7205496 ,  0.0899211 , -0.30738285, -0.21612053,\n",
      "        0.36688858, -0.32532972, -0.57063447, -0.40833223, -0.63180473,\n",
      "       -0.91173193, -0.230694  ,  0.2628623 ,  0.22721533, -0.36625283,\n",
      "       -0.0520476 , -0.05932117,  0.20554883,  0.17886011,  0.5756048 ,\n",
      "       -0.0412461 , -0.7170248 , -0.4741516 ,  0.99184202,  0.05862453,\n",
      "       -0.1499907 , -0.75441837,  0.76404687, -0.5809736 ,  0.14138853,\n",
      "       -0.22126047, -0.34661717, -0.13763684,  0.19361581,  0.6412348 ,\n",
      "        0.48547856, -0.04817461, -0.35283097])], array([0. , 0.5]), array([0.5, 0.5]))\n"
     ]
    }
   ],
   "source": [
    "callhome1_dataset = Recordings_dataset(callhome1_recordings_segments)\n",
    "print(len(callhome1_dataset))\n",
    "print(callhome1_dataset[37])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
