{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recordings segments loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from functools import reduce\n",
    "\n",
    "# is_single_speaker_segment [VALIDATED]\n",
    "# validates if a segment has a single speaker who belongs to the speakers list. \n",
    "def is_single_speaker_segment(segment, valid_speakers_ids = ['A', 'B']):\n",
    "    return len(segment['speakers']) == 1 and segment['speakers'][0]['speaker_id'] in valid_speakers_ids\n",
    "\n",
    "# is_valid_segment [VALIDATED]\n",
    "# validates if a segment meets a maximum number of speakers,\n",
    "# and that all the speakers in the segment belong to a list.\n",
    "def is_valid_segment(segment, maximum_speakers_length = 2, valid_speakers_ids = ['A', 'B']):\n",
    "    speakers_ids = [speaker['speaker_id'] for speaker in segment['speakers']]\n",
    "    speakers_ids = list(set(speakers_ids))\n",
    "    return len(speakers_ids) <= maximum_speakers_length and \\\n",
    "        all(speaker_id in valid_speakers_ids for speaker_id in speakers_ids)\n",
    "\n",
    "# load_recordings_segments [VALIDATED]\n",
    "# loads the recordings segments data from the .json files located in a directory \n",
    "def load_recordings_segments(directory, validation_function):\n",
    "    filenames = [filename for filename in os.listdir(directory) if os.path.isfile(os.path.join(directory, filename))]\n",
    "    filenames.sort()\n",
    "    recordings_segments = {}\n",
    "    recordings_length = len(filenames)\n",
    "    recordings_count = 0\n",
    "    segments_original = 0\n",
    "    segments_filtered = 0\n",
    "    for filename in filenames:\n",
    "        recording_id = filename.split('.')[0]\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        file = open(filepath, 'r')\n",
    "        recordings_segments[recording_id] = [json.loads(line) for line in file.readlines()]\n",
    "        file.close()\n",
    "        segments_original += len(recordings_segments[recording_id])\n",
    "        recordings_segments[recording_id] = list(filter(validation_function, recordings_segments[recording_id]))\n",
    "        segments_filtered += len(recordings_segments[recording_id])\n",
    "        recordings_count += 1\n",
    "        print(directory + ' loading ' + str(recordings_count) + '/' + str(recordings_length), end = '\\r')\n",
    "    print(directory, 'loaded', str(recordings_count) + '/' + str(recordings_length) + ',', round(segments_filtered / segments_original, 2), 'segments left.')\n",
    "    return recordings_segments\n",
    "\n",
    "# speakers_get_indexes [VALIDATED]\n",
    "# used to convert a (speakers_ids, index) list to a speakers_ids => [indexes] dictionary\n",
    "def speakers_get_indexes(accumulator, speakers_tuple):\n",
    "    speaker_ids, index = speakers_tuple\n",
    "    speaker_ids = ','.join(speaker_ids)\n",
    "    if speaker_ids in accumulator:\n",
    "        accumulator[speaker_ids].append(index)\n",
    "    else:\n",
    "        accumulator[speaker_ids] = [index]\n",
    "    return accumulator\n",
    "\n",
    "# balance_segments [VALIDATED]\n",
    "# balances the recording segments data to meet a minimum of speakers per recording,\n",
    "# and a minimum of segments per speaker.\n",
    "def balance_segments(recordings_segments,\n",
    "                     minimum_speakers_length = 2,\n",
    "                     minimum_speaker_segments = 3,\n",
    "                     include_overlaps = False):\n",
    "    new_recordings_segments = {}\n",
    "    for recording_id in recordings_segments:\n",
    "        recording_segments = recordings_segments[recording_id]\n",
    "        # ----- Obtaining speakers indexes ----- #\n",
    "        speakers_indexes = [(sorted(list(set([speaker['speaker_id'] for speaker in segment['speakers']]))), index) for index, segment in enumerate(recording_segments)]\n",
    "        speakers_indexes = reduce(speakers_get_indexes, speakers_indexes, {})\n",
    "        # ----- Removing overlaps ----- #\n",
    "        if not include_overlaps:\n",
    "            for speakers_ids in list(speakers_indexes.keys()):\n",
    "                if len(speakers_ids.split(',')) > 1:\n",
    "                    del speakers_indexes[speakers_ids]\n",
    "        speakers_lengths = [(speakers_ids, len(speakers_indexes[speakers_ids])) for speakers_ids in speakers_indexes]\n",
    "        speakers_lengths.sort(key = lambda x: x[1])\n",
    "        speakers_lengths_min = speakers_lengths[0][1]\n",
    "        if len(speakers_lengths) >= minimum_speakers_length and speakers_lengths_min >= minimum_speaker_segments:\n",
    "            recording_indexes = []\n",
    "            for speakers_ids in speakers_indexes:\n",
    "                speakers_indexes[speakers_ids] = speakers_indexes[speakers_ids][:speakers_lengths_min]\n",
    "                recording_indexes += speakers_indexes[speakers_ids]\n",
    "            new_recordings_segments[recording_id] = [segment for index, segment in enumerate(recordings_segments[recording_id]) if index in recording_indexes]\n",
    "    print('Recordings left: ' + str(len(new_recordings_segments)) + '/' + str(len(recordings_segments)))\n",
    "    return new_recordings_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recordings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def generate_speaker_model(recording_segments,\n",
    "                           speaker_indexes,\n",
    "                           segments_length,\n",
    "                           vector = 'ivectors',\n",
    "                           selection = 'first',\n",
    "                           indexes = []):\n",
    "    #if segments_length > len(speaker_indexes):\n",
    "    #    print('WARNING: there are less speaker indexes than segments.')\n",
    "    if selection == 'first':\n",
    "        selected_segments = [segment for index, segment in enumerate(recording_segments) if index in speaker_indexes[:segments_length]]\n",
    "    elif selection == 'random':\n",
    "        selected_segments = [recording_segments[index] for index in random.sample(speaker_indexes, segments_length if segments_length < len(speaker_indexes) else len(speaker_indexes))]\n",
    "    elif selection == 'indexes':\n",
    "        selected_segments = [recording_segments[index] for index in indexes]\n",
    "    else:\n",
    "        print('ERROR: unknown speaker model segments selection strategy.')\n",
    "    selected_vectors = [np.asarray(segment[vector][0]['value']) for segment in selected_segments]\n",
    "    return np.sum(selected_vectors, 0) / len(selected_vectors)\n",
    "    \n",
    "\n",
    "class Recordings_dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 recordings_segments,\n",
    "                 recordings_ids = None,\n",
    "                 vector = 'ivectors',\n",
    "                 models_container_length = 2,\n",
    "                 models_container_include_zeros = True,\n",
    "                 models_container_include_overlaps = False,\n",
    "                 models_generation_lengths = [3],\n",
    "                 models_generation_selection = 'first',\n",
    "                 balance_segments = True,\n",
    "                 balance_segments_selection = 'copy'):\n",
    "        # -----------------------------------------------------Saving input data----- #\n",
    "        if recordings_ids is None:\n",
    "            recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "        self.recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "        self.recordings_segments = {}\n",
    "        for recording_id in self.recordings_ids:\n",
    "            self.recordings_segments[recording_id] = recordings_segments[recording_id]\n",
    "        self.vector = vector\n",
    "        self.models_container_length = models_container_length\n",
    "        self.models_container_include_zeros = models_container_include_zeros\n",
    "        self.models_container_include_overlaps = models_container_include_overlaps\n",
    "        self.models_generation_lengths = models_generation_lengths\n",
    "        self.models_generation_selection = models_generation_selection\n",
    "        self.balance_segments = balance_segments\n",
    "        self.balance_segments_selection = balance_segments_selection\n",
    "        # --------------------------------------------------------------------------- #\n",
    "        self.recordings_data = {}\n",
    "        # -------------------------------------------------- #\n",
    "        self.recordings_map = []\n",
    "        self.recordings_length = 0\n",
    "        for recording_id in self.recordings_ids:\n",
    "            self.recordings_data[recording_id] = {}\n",
    "            recording_segments = self.recordings_segments[recording_id]\n",
    "            recording_data = self.recordings_data[recording_id]\n",
    "            # ----- Obtaining speakers indexes ----- #\n",
    "            recording_data['speakers_indexes'] = [(sorted(list(set([speaker['speaker_id'] for speaker in segment['speakers']]))), index) for index, segment in enumerate(recording_segments)]\n",
    "            recording_data['speakers_indexes'] = reduce(speakers_get_indexes, recording_data['speakers_indexes'], {})\n",
    "            # ----- Balancing speakers segments ----- #\n",
    "            recording_data['speakers_indexes_lengths_max'] = max([len(recording_data['speakers_indexes'][speakers_ids]) for speakers_ids in recording_data['speakers_indexes']])\n",
    "            if self.balance_segments:\n",
    "                if self.balance_segments_selection == 'copy':\n",
    "                    for speakers_ids in recording_data['speakers_indexes']:\n",
    "                        for i in range(recording_data['speakers_indexes_lengths_max'] - len(recording_data['speakers_indexes'][speakers_ids])):\n",
    "                            index = random.choice(recording_data['speakers_indexes'][speakers_ids])\n",
    "                            recording_segments.append(recording_segments[index])\n",
    "                            recording_data['speakers_indexes'][speakers_ids].append(len(recording_segments) - 1)\n",
    "                else:\n",
    "                    print('ERROR: unknown balancing segments selection strategy.')\n",
    "            # ----- Generating speakers models ----- #\n",
    "            recording_data['speakers_models'] = {}\n",
    "            for speakers_ids in recording_data['speakers_indexes']:\n",
    "                recording_data['speakers_models'][speakers_ids] = {}\n",
    "                for models_generation_length in models_generation_lengths:\n",
    "                    speakers_model = generate_speaker_model(recording_segments, recording_data['speakers_indexes'][speakers_ids], models_generation_length, self.vector, self.models_generation_selection)\n",
    "                    recording_data['speakers_models'][speakers_ids][models_generation_length] = [speakers_model]\n",
    "            # ----- Generating permutations ----- #\n",
    "            if self.models_container_include_zeros:\n",
    "                recording_data['permutations'] = list(itertools.permutations(list(recording_data['speakers_models'].keys()) \\\n",
    "                + ['0' for i in range(self.models_container_length)], self.models_container_length))\n",
    "            else:\n",
    "                recording_data['permutations'] = list(itertools.permutations(list(recording_data['speakers_models'].keys()), self.models_container_length))\n",
    "            recording_data['permutations'] = list(set(recording_data['permutations']))\n",
    "            recording_data['permutations'].sort()\n",
    "            if not self.models_container_include_overlaps:\n",
    "                recording_data['permutations'] = [permutation for permutation in recording_data['permutations'] if all(len(speakers_ids.split(',')) == 1 for speakers_ids in permutation)]\n",
    "            # -------------------------------------------------- #\n",
    "            recording_data['permutations_map'] = []\n",
    "            recording_data['permutations_length'] = 0\n",
    "            for index, permutation in enumerate(recording_data['permutations']):\n",
    "                speakers_models_length = int(np.prod([np.sum([len(recording_data['speakers_models'][speakers_ids][models_generation_length]) for models_generation_length in recording_data['speakers_models'][speakers_ids]]) for speakers_ids in permutation if speakers_ids != '0']))\n",
    "                recording_data['permutations_map'].append((recording_data['permutations_length'], recording_data['permutations_length'] + speakers_models_length - 1, index))\n",
    "                recording_data['permutations_length'] += speakers_models_length\n",
    "            recording_data['length'] = len(recording_segments) * recording_data['permutations_length']\n",
    "            self.recordings_map.append((self.recordings_length, self.recordings_length + recording_data['length'] - 1, recording_id))\n",
    "            self.recordings_length += recording_data['length']\n",
    "    def __len__(self):\n",
    "        return self.recordings_length\n",
    "    def __getitem__(self, idx):\n",
    "        recording_limits = list(filter(lambda recording_limits: recording_limits[0] <= idx and idx <= recording_limits[1], self.recordings_map))[0]\n",
    "        recording_idx = idx - recording_limits[0]\n",
    "        recording_id = recording_limits[2]\n",
    "        recording_data = self.recordings_data[recording_id]\n",
    "        \n",
    "        segment_index, segment_idx = divmod(recording_idx, recording_data['permutations_length'])\n",
    "        segment = self.recordings_segments[recording_id][segment_index]\n",
    "        vector = np.asarray(segment[self.vector][0]['value'])\n",
    "        \n",
    "        permutation_limits = list(filter(lambda permutation_limits: permutation_limits[0] <= segment_idx and segment_idx <= permutation_limits[1], recording_data['permutations_map']))[0]\n",
    "        permutation_idx = segment_idx - permutation_limits[0]\n",
    "        permutation_index = permutation_limits[2]\n",
    "        permutation = recording_data['permutations'][permutation_index]\n",
    "        \n",
    "        speakers_models_lengths = [np.sum([len(recording_data['speakers_models'][speakers_ids][models_generation_length]) for models_generation_length in recording_data['speakers_models'][speakers_ids]])  if speakers_ids != '0' else 1 for speakers_ids in permutation]\n",
    "        models_container = []\n",
    "        model_index = permutation_idx\n",
    "        for i, length_i in enumerate(speakers_models_lengths):\n",
    "            if i != len(speakers_models_lengths) - 1:\n",
    "                model_index, remainder = divmod(model_index, np.sum(speakers_models_lengths[i + 1:]))\n",
    "            else:\n",
    "                model_index = remainder\n",
    "            models_container.append(recording_data['speakers_models'][permutation[i]][self.models_generation_lengths[model_index]][0] if permutation[i] != '0' else np.random.uniform(-0.1, 0.1, len(vector)))\n",
    "        \n",
    "        models_weigths = np.asarray([len(recording_data['speakers_indexes'][speakers_ids]) if speakers_ids != '0' else recording_data['speakers_indexes_lengths_max'] for speakers_ids in permutation])\n",
    "        models_weigths_sum = np.sum(models_weigths)\n",
    "        models_weigths = np.ones(len(models_weigths)) - models_weigths / models_weigths_sum\n",
    "        \n",
    "        targets_ids = [speaker['speaker_id'] for speaker in segment['speakers']]\n",
    "        \n",
    "        x = [vector] + models_container\n",
    "        if self.models_container_include_overlaps:\n",
    "            targets_ids = ','.join(sorted(list(set(targets_ids))))\n",
    "            y = np.asarray([speakers_ids == targets_ids for speakers_ids in permutation], dtype = float)\n",
    "        else:\n",
    "            y = np.asarray([speaker_id in targets_ids for speaker_id in permutation], dtype = float) / len(targets_ids)\n",
    "        z = models_weigths\n",
    "        \n",
    "        return x, y, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load live_graph.py\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Live_graph:\n",
    "    def __init__(self, validation_threshold):\n",
    "        self.plt_count = -1\n",
    "        self.validation_threshold = validation_threshold\n",
    "        self.plt_thr = ([self.plt_count], [self.validation_threshold])\n",
    "        self.plt_loss = ([self.plt_count], [1])\n",
    "        self.plt_valid = ([self.plt_count], [1])\n",
    "        self.plt_test = ([self.plt_count], [1])\n",
    "        self.fig = plt.figure()\n",
    "        self.ax = self.fig.add_subplot()\n",
    "        self.line0, = self.ax.plot(self.plt_thr[0], self.plt_thr[1], 'k--', label = 'Threshold') # Threshold line\n",
    "        self.line1, = self.ax.plot(self.plt_loss[0], self.plt_loss[1], '--', label = 'Training') # Training loss\n",
    "        self.line2, = self.ax.plot(self.plt_valid[0], self.plt_valid[1], label = 'Validation')   # Validation loss\n",
    "        self.line3, = self.ax.plot(self.plt_test[0], self.plt_test[1], label = 'Test')           # Test loss\n",
    "        self.ax.set_xlabel('Epoch')\n",
    "        self.ax.set_ylabel('Loss')\n",
    "        self.ax.legend()\n",
    "        self.ax.set_xlim(-1, 0)\n",
    "        self.ax.set_ylim(0, 0.5)\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.canvas.flush_events()\n",
    "    def step(self, training, validation, test = -1):\n",
    "        self.plt_count += 1\n",
    "        self.plt_thr[0].append(self.plt_count)\n",
    "        self.plt_thr[1].append(self.validation_threshold)\n",
    "        self.plt_loss[0].append(self.plt_count)\n",
    "        self.plt_loss[1].append(training)\n",
    "        self.plt_valid[0].append(self.plt_count)\n",
    "        self.plt_valid[1].append(validation)\n",
    "        self.plt_test[0].append(self.plt_count)\n",
    "        self.plt_test[1].append(test)\n",
    "        self.line0.set_xdata(self.plt_thr[0])\n",
    "        self.line0.set_ydata(self.plt_thr[1])\n",
    "        self.line1.set_xdata(self.plt_loss[0])\n",
    "        self.line1.set_ydata(self.plt_loss[1])\n",
    "        self.line2.set_xdata(self.plt_valid[0])\n",
    "        self.line2.set_ydata(self.plt_valid[1])\n",
    "        self.line3.set_xdata(self.plt_test[0])\n",
    "        self.line3.set_ydata(self.plt_test[1])\n",
    "        self.ax.set_xlim(0, self.plt_count + 1)\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.canvas.flush_events()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, models_container_length, vector_length):\n",
    "        super().__init__()\n",
    "        n = models_container_length\n",
    "        m = vector_length\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv1d((n + 1), n ** 3, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(n ** 3, n ** 2, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(n ** 2, n, 3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(n * (m - 6), n * 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n * 16, n * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n * 4, n),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = torch.stack(input, 1)\n",
    "        x = self.cnn1(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self):\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device('cuda:0')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "    def get_net(self,\n",
    "                recordings_segments,\n",
    "                recordings_ids = None,\n",
    "                vector = 'ivectors',\n",
    "                vector_length = 128,\n",
    "                models_container_length = 2,\n",
    "                models_container_include_zeros = True,\n",
    "                models_container_include_overlaps = False,\n",
    "                models_generation_lengths = [3],\n",
    "                models_generation_selection = 'first',\n",
    "                balance_segments = True,\n",
    "                balance_segments_selection = 'copy',\n",
    "                batch_size = 16,\n",
    "                num_workers = 8,\n",
    "                test_recordings_segments = None):\n",
    "        \n",
    "        if recordings_ids is None:\n",
    "            recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "        self.recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "\n",
    "        train_dataset = Recordings_dataset(recordings_segments,\n",
    "                                           recordings_ids, \n",
    "                                           vector,\n",
    "                                           models_container_length,\n",
    "                                           models_container_include_zeros,\n",
    "                                           models_container_include_overlaps,\n",
    "                                           models_generation_lengths,\n",
    "                                           models_generation_selection,\n",
    "                                           balance_segments,\n",
    "                                           balance_segments_selection)\n",
    "\n",
    "        train_length = int(len(train_dataset) * 0.7)\n",
    "        valid_length = len(train_dataset) - train_length\n",
    "\n",
    "        train_dataset, valid_dataset = random_split(train_dataset, [train_length, valid_length])\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers = num_workers)\n",
    "        valid_dataloader = DataLoader(valid_dataset, batch_size = batch_size, num_workers = num_workers)\n",
    "        \n",
    "        if test_recordings_segments is not None:\n",
    "            test_recordings_ids = [recording_id for recording_id in test_recordings_segments]\n",
    "            test_dataset = Recordings_dataset(test_recordings_segments,\n",
    "                                              test_recordings_ids,\n",
    "                                              vector,\n",
    "                                              models_container_length,\n",
    "                                              models_container_include_zeros,\n",
    "                                              models_container_include_overlaps,\n",
    "                                              models_generation_lengths,\n",
    "                                              models_generation_selection,\n",
    "                                              balance_segments,\n",
    "                                              balance_segments_selection)\n",
    "            test_dataloader = DataLoader(test_dataset, batch_size = batch_size, num_workers = num_workers)\n",
    "\n",
    "        net = Net(models_container_length, vector_length).to(self.device)\n",
    "        optimizer = optim.Adam(net.parameters(), lr = 0.0001)\n",
    "\n",
    "        epochs = 30\n",
    "        validation_threshold = 0.07\n",
    "\n",
    "        live_graph = Live_graph(validation_threshold)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_losses = []\n",
    "            for input, target, weigth in train_dataloader:\n",
    "                input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                target = target.to(self.device, non_blocking = True).float()\n",
    "                weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                criterion = nn.BCELoss(weigth)\n",
    "                net.zero_grad()\n",
    "                output = net(input)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_losses.append(loss.data)\n",
    "                print('train: ' + str(len(train_losses)) + '/' + str(len(train_dataloader)) + '          ', end = '\\r')\n",
    "            train_loss = np.sum(train_losses) / len(train_losses)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                validation_losses = []\n",
    "                for input, target, weigth in valid_dataloader:\n",
    "                    input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                    target = target.to(self.device, non_blocking = True).float()\n",
    "                    weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                    criterion = nn.BCELoss(weigth)\n",
    "                    output = net(input)\n",
    "                    loss = criterion(output, target)\n",
    "                    validation_losses.append(loss.data)\n",
    "                    print('validation: ' + str(len(validation_losses)) + '/' + str(len(valid_dataloader)) + '          ', end = '\\r')\n",
    "                validation_loss = np.sum(validation_losses) / len(validation_losses)\n",
    "                \n",
    "                test_loss = -1\n",
    "                if test_recordings_segments is not None:\n",
    "                    test_losses = []\n",
    "                    for input, target, weigth in test_dataloader:\n",
    "                        input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                        target = target.to(self.device, non_blocking = True).float()\n",
    "                        weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                        criterion = nn.BCELoss(weigth)\n",
    "                        output = net(input)\n",
    "                        loss = criterion(output, target)\n",
    "                        test_losses.append(loss.data)\n",
    "                        print('test: ' + str(len(test_losses)) + '/' + str(len(test_dataloader)) + '          ', end = '\\r')\n",
    "                    test_loss = np.sum(test_losses) / len(test_losses)\n",
    "\n",
    "            live_graph.step(train_loss, validation_loss, test_loss)\n",
    "\n",
    "            if validation_loss <= validation_threshold:\n",
    "                print('Done training.')\n",
    "                break\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load md_eval.py\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "def md_eval(ref_filepath, res_filepath, save_filepath = None):\n",
    "    bin = '../../../../tools/sctk-2.4.10/src/md-eval/md-eval.pl'\n",
    "    p = subprocess.Popen([bin, '-r', ref_filepath, '-s', res_filepath], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output, err = p.communicate()\n",
    "    rc = p.returncode\n",
    "    if rc == 0:\n",
    "        output = output.decode(\"utf-8\")\n",
    "        if save_filepath is not None:\n",
    "            file = open(save_filepath, 'w')\n",
    "            file.write(output)\n",
    "            file.close()\n",
    "        lines =  output.split('\\n')\n",
    "        derLine = [line for line in lines if 'OVERALL SPEAKER DIARIZATION ERROR' in line][0]\n",
    "        return float(re.findall('\\d+\\.\\d+', derLine)[0])\n",
    "    else:\n",
    "        exit('md-eval.pl fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eer(res_filepath):\n",
    "    bin = '../eer_score.sh'\n",
    "    p = subprocess.Popen([bin, res_filepath], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output, err = p.communicate()\n",
    "    rc = p.returncode\n",
    "    if rc == 0:\n",
    "        output = output.decode(\"utf-8\")\n",
    "        return float(output)\n",
    "    else:\n",
    "        exit('eer_score.sh fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plda_score(ref_vector, test_vector, plda_filepath):\n",
    "    ref_string = str(list(ref_vector)).replace(',', '').replace('[', '[ ').replace(']', ' ]')\n",
    "    test_string = str(list(test_vector)).replace(',', '').replace('[', '[ ').replace(']', ' ]')\n",
    "\n",
    "    bin = '../plda_score.sh'\n",
    "    p = subprocess.Popen([bin, plda_filepath, ref_string, test_string], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output, err = p.communicate()\n",
    "    rc = p.returncode\n",
    "    if rc == 0:\n",
    "        lines =  output.decode(\"utf-8\").split('\\n')\n",
    "        pldaLine = [line for line in lines if 'reference test' in line][0]\n",
    "        return float(re.findall('\\d+\\.\\d+', pldaLine)[0])\n",
    "    else:\n",
    "        print(err)\n",
    "        exit('plda_socre.sh fail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracking_tester(recordings_segments,\n",
    "                    recordings_ids = None,\n",
    "                    scoring_function = None,\n",
    "                    groundtruth_filepath = '',\n",
    "                    groundtruth_valid_speakers_ids = ['A', 'B'],\n",
    "                    vector = 'ivectors',\n",
    "                    models_container_length = 2,\n",
    "                    models_container_include_overlaps = False,\n",
    "                    models_generation_length = 3,\n",
    "                    models_generation_selection = 'first'):\n",
    "\n",
    "    if recordings_ids is None:\n",
    "        recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "    recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "    recordings_ids.sort()\n",
    "    \n",
    "    results = {}\n",
    "    results_reduced = {}\n",
    "    results_rttm = ''\n",
    "    results_scores = {}\n",
    "    results_eer = ''\n",
    "    for recording_id in recordings_ids:\n",
    "        recording_dataset = Recordings_dataset(recordings_segments,\n",
    "                                               recording_id,\n",
    "                                               vector = vector,\n",
    "                                               models_container_length = models_container_length,\n",
    "                                               models_container_include_zeros = False,\n",
    "                                               models_container_include_overlaps = models_container_include_overlaps,\n",
    "                                               models_generation_lengths = [models_generation_length],\n",
    "                                               models_generation_selection = models_generation_selection,\n",
    "                                               balance_segments = False,\n",
    "                                               balance_segments_selection = 'copy')\n",
    "        speakers_models = recording_dataset.recordings_data[recording_id]['speakers_models']\n",
    "        speakers_ids = [speakers_ids for speakers_ids in speakers_models]\n",
    "        models_container = [speakers_models[speakers_ids][models_generation_length][0] for speakers_ids in speakers_models if models_container_include_overlaps or len(speakers_ids.split(',')) == 1]\n",
    "        for i in range(models_container_length - len(models_container)):\n",
    "            models_container.append(np.random.uniform(-0.1, 0.1, len(models_container[0])))\n",
    "        # At this point there is no information about the speaker identity, only the model\n",
    "        results[recording_id] = []\n",
    "        results_scores[recording_id] = []\n",
    "        for segment in recordings_segments[recording_id]:\n",
    "            segment_vector = np.asarray(segment[vector][0]['value'])\n",
    "            scores = scoring_function(segment_vector, models_container)\n",
    "            targets_ids = [speaker['speaker_id'] for speaker in segment['speakers']]\n",
    "            targets_ids.sort()\n",
    "            labels = ['target' if targets_ids == sorted(speaker_id.split(',')) else 'nontarget' for speaker_id in speakers_ids]\n",
    "            scores_labels = list(zip(scores, labels))\n",
    "            results_scores[recording_id].append(scores_labels)\n",
    "            index = np.argmax(scores)\n",
    "            results[recording_id].append({ 'begining': segment['begining'], 'ending': segment['ending'], 'speaker_id': index })\n",
    "            if len(results[recording_id]) > 2:\n",
    "                if results[recording_id][len(results[recording_id]) - 1]['speaker_id'] == results[recording_id][len(results[recording_id]) - 3]['speaker_id']:\n",
    "                    if results[recording_id][len(results[recording_id]) - 1]['speaker_id'] != results[recording_id][len(results[recording_id]) - 2]['speaker_id']:\n",
    "                        results[recording_id][len(results[recording_id]) - 2]['speaker_id'] = results[recording_id][len(results[recording_id]) - 1]['speaker_id']\n",
    "                        results[recording_id][len(results[recording_id]) - 1]['modified'] = True\n",
    "        results_reduced[recording_id] = []\n",
    "        last_speaker_id = -1\n",
    "        last_speaker = { 'begining': 0, 'ending': 0, 'speaker_id': -1 }\n",
    "        for segment in results[recording_id] + [{ 'begining': 0, 'ending': 0, 'speaker_id': -1 }]:\n",
    "            begining = segment['begining']\n",
    "            ending = segment['ending']\n",
    "            speaker_id = segment['speaker_id']\n",
    "            if last_speaker_id != speaker_id:\n",
    "                if last_speaker_id != -1:\n",
    "                    results_reduced[recording_id].append(last_speaker)\n",
    "                last_speaker_id = speaker_id\n",
    "                last_speaker = { 'begining': begining, 'ending': ending, 'speaker_id': speaker_id }\n",
    "            else:\n",
    "                if begining <= last_speaker['ending']:\n",
    "                    last_speaker['ending'] = ending\n",
    "                else:\n",
    "                    if last_speaker_id != -1:\n",
    "                        results_reduced[recording_id].append(last_speaker)\n",
    "                    last_speaker_id = speaker_id\n",
    "                    last_speaker = { 'begining': begining, 'ending': ending, 'speaker_id': speaker_id }\n",
    "        for scores_labels in results_scores[recording_id]:\n",
    "            for score_label in scores_labels:\n",
    "                result_eer = '{:f}'.format(score_label[0]) + ' ' + score_label[1]\n",
    "                results_eer += result_eer + '\\n'\n",
    "        for segment in results_reduced[recording_id]:\n",
    "            result_rttm = 'SPEAKER ' + recording_id + ' 0 ' + str(segment['begining']) + ' ' + str(round(segment['ending'] - segment['begining'], 2)) + ' <NA> <NA> ' + str(segment['speaker_id']) + ' <NA> <NA>'\n",
    "            results_rttm += result_rttm + '\\n'\n",
    "\n",
    "    file = open(groundtruth_filepath, 'r')\n",
    "    groundtruth_rttm = ''.join([line for line in file.readlines() if (line.split(' ')[1] in recordings_ids) and \\\n",
    "                    (line.split(' ')[7] in ['A', 'B'])])\n",
    "    file.close()\n",
    "    \n",
    "    !mkdir -p tmp\n",
    "    \n",
    "    file = open('tmp/results.eer', 'w')\n",
    "    file.write(results_eer)\n",
    "    file.close()\n",
    "    \n",
    "    file = open('tmp/groundtruth.rttm', 'w')\n",
    "    file.write(groundtruth_rttm)\n",
    "    file.close()\n",
    "    \n",
    "    file = open('tmp/results.rttm', 'w')\n",
    "    file.write(results_rttm)\n",
    "    file.close()\n",
    "\n",
    "    print(eer('notebooks/tmp/results.eer'))\n",
    "    return md_eval('tmp/groundtruth.rttm', 'tmp/results.rttm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading recordings segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_directory = '../exp/pre_norm/callhome1/json'\n",
    "b_directory = '../exp/pre_norm/callhome2/json'\n",
    "maximum_speakers_length = 2\n",
    "valid_speakers_ids = ['A', 'B']\n",
    "include_overlaps = False\n",
    "vector = 'ivectors'\n",
    "vector_length = 128\n",
    "models_container_length = 2\n",
    "models_container_include_zeros = True\n",
    "models_container_include_overlaps = False\n",
    "models_generation_length = 3\n",
    "models_generation_selection = 'first'\n",
    "balance_segments_selection = 'copy'\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../exp/pre_norm/callhome1/json loaded 249/249, 0.74 segments left.\n",
      "../exp/pre_norm/callhome2/json loaded 250/250, 0.77 segments left.\n"
     ]
    }
   ],
   "source": [
    "a_recordings_segments = load_recordings_segments(a_directory,\n",
    "                                                 lambda segment: is_valid_segment(segment, maximum_speakers_length, valid_speakers_ids))\n",
    "b_recordings_segments = load_recordings_segments(b_directory,\n",
    "                                                 lambda segment: is_valid_segment(segment, maximum_speakers_length, valid_speakers_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recordings left: 246/249\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training.29/1029          \n"
     ]
    }
   ],
   "source": [
    "a_trainer = Trainer()\n",
    "a_net = a_trainer.get_net(balance_segments(a_recordings_segments, \n",
    "                                           maximum_speakers_length,\n",
    "                                           models_generation_length,\n",
    "                                           include_overlaps),\n",
    "                          vector = vector,\n",
    "                          vector_length = vector_length,\n",
    "                          models_container_length = models_container_length,\n",
    "                          models_container_include_zeros = models_container_include_zeros,\n",
    "                          models_container_include_overlaps = models_container_include_overlaps,\n",
    "                          models_generation_lengths = [models_generation_length],\n",
    "                          models_generation_selection = models_generation_selection,\n",
    "                          balance_segments_selection = balance_segments_selection,\n",
    "                          batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_selector(vector, models_container, net):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    with torch.no_grad():\n",
    "        input = [torch.Tensor([nparray]).to(device, non_blocking = True).float() for nparray in [vector] + models_container]\n",
    "        output = net(input)\n",
    "        return output.cpu().data.numpy()[0]\n",
    "    \n",
    "def plda_selector(vector, models_container, plda_filepath):\n",
    "    return [plda_score(ref_vector, vector, plda_filepath) for ref_vector in models_container]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../exp/pre_norm/callhome2/json loaded 250/250, 0.7 segments left.\n"
     ]
    }
   ],
   "source": [
    "b_recordings_segments = load_recordings_segments(b_directory,\n",
    "                                                 lambda segment: is_single_speaker_segment(segment, ['A', 'B']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.31"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_tester(b_recordings_segments,\n",
    "                scoring_function = lambda vector, models_container: net_selector(vector, models_container, a_net),\n",
    "                groundtruth_filepath = '../data/callhome2_1.0_0.5.rttm',\n",
    "                groundtruth_valid_speakers_ids = ['A', 'B'],\n",
    "                vector = vector,\n",
    "                models_container_length = models_container_length,\n",
    "                models_container_include_overlaps = models_container_include_overlaps,\n",
    "                models_generation_length = models_generation_length,\n",
    "                models_generation_selection = models_generation_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.84"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_tester(b_recordings_segments,\n",
    "                scoring_function = lambda vector, models_container: plda_selector(vector,\n",
    "                                                                                  models_container,\n",
    "                                                                                  'exp/plda/callhome1/ivectors.plda'),\n",
    "                groundtruth_filepath = '../data/callhome2_1.0_0.5.rttm',\n",
    "                groundtruth_valid_speakers_ids = ['A', 'B'],\n",
    "                vector = vector,\n",
    "                models_container_length = models_container_length,\n",
    "                models_container_include_overlaps = models_container_include_overlaps,\n",
    "                models_generation_length = models_generation_length,\n",
    "                models_generation_selection = models_generation_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
