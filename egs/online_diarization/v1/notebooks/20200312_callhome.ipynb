{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recordings segments loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from functools import reduce\n",
    "\n",
    "# is_valid_segment [VALIDATED]\n",
    "# validates that a segment meets a maximum number of speakers,\n",
    "# and that all the speakers in the segment belong to a list.\n",
    "def is_valid_segment(segment, maximum_speakers_length = 2, valid_speakers_ids = ['A', 'B']):\n",
    "    speakers_ids = [speaker['speaker_id'] for speaker in segment['speakers']]\n",
    "    speakers_ids = list(set(speakers_ids))\n",
    "    return len(speakers_ids) <= maximum_speakers_length and \\\n",
    "        all(speaker_id in valid_speakers_ids for speaker_id in speakers_ids)\n",
    "\n",
    "# load_recordings_segments [VALIDATED]\n",
    "# loads the recordings segments data from the .json files located in a directory \n",
    "def load_recordings_segments(directory, maximum_speakers_length = 2, valid_speakers_ids = ['A', 'B']):\n",
    "    filenames = [filename for filename in os.listdir(directory) if os.path.isfile(os.path.join(directory, filename))]\n",
    "    filenames.sort()\n",
    "    recordings_segments = {}\n",
    "    recordings_length = len(filenames)\n",
    "    recordings_count = 0\n",
    "    segments_original = 0\n",
    "    segments_filtered = 0\n",
    "    for filename in filenames:\n",
    "        recording_id = filename.split('.')[0]\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        file = open(filepath, 'r')\n",
    "        recordings_segments[recording_id] = [json.loads(line) for line in file.readlines()]\n",
    "        file.close()\n",
    "        segments_original += len(recordings_segments[recording_id])\n",
    "        recordings_segments[recording_id] = list(filter(lambda segment: is_valid_segment(segment, maximum_speakers_length, valid_speakers_ids), recordings_segments[recording_id]))\n",
    "        segments_filtered += len(recordings_segments[recording_id])\n",
    "        recordings_count += 1\n",
    "        print(directory + ' loading ' + str(recordings_count) + '/' + str(recordings_length), end = '\\r')\n",
    "    print(directory, 'loaded', str(recordings_count) + '/' + str(recordings_length) + ',', round(segments_filtered / segments_original, 2), 'segments left.')\n",
    "    return recordings_segments\n",
    "\n",
    "# speakers_get_indexes [VALIDATED]\n",
    "# used to convert a (speakers_ids, index) list to a speakers_ids => [indexes] dictionary\n",
    "def speakers_get_indexes(accumulator, speakers_tuple):\n",
    "    speaker_ids, index = speakers_tuple\n",
    "    speaker_ids = ','.join(speaker_ids)\n",
    "    if speaker_ids in accumulator:\n",
    "        accumulator[speaker_ids].append(index)\n",
    "    else:\n",
    "        accumulator[speaker_ids] = [index]\n",
    "    return accumulator\n",
    "\n",
    "# balance_segments [VALIDATED]\n",
    "# balances the recording segments data to meet a minimum of speakers per recording,\n",
    "# and a minimum of segments per speaker.\n",
    "def balance_segments(recordings_segments,\n",
    "                     minimum_speakers_length = 2,\n",
    "                     minimum_speaker_segments = 3,\n",
    "                     include_overlaps = False):\n",
    "    new_recordings_segments = {}\n",
    "    for recording_id in recordings_segments:\n",
    "        recording_segments = recordings_segments[recording_id]\n",
    "        # ----- Obtaining speakers indexes ----- #\n",
    "        speakers_indexes = [(sorted(list(set([speaker['speaker_id'] for speaker in segment['speakers']]))), index) for index, segment in enumerate(recording_segments)]\n",
    "        speakers_indexes = reduce(speakers_get_indexes, speakers_indexes, {})\n",
    "        # ----- Removing overlaps ----- #\n",
    "        if not include_overlaps:\n",
    "            for speakers_ids in list(speakers_indexes.keys()):\n",
    "                if len(speakers_ids.split(',')) > 1:\n",
    "                    del speakers_indexes[speakers_ids]\n",
    "        speakers_lengths = [(speakers_ids, len(speakers_indexes[speakers_ids])) for speakers_ids in speakers_indexes]\n",
    "        speakers_lengths.sort(key = lambda x: x[1])\n",
    "        speakers_lengths_min = speakers_lengths[0][1]\n",
    "        if len(speakers_lengths) >= minimum_speakers_length and speakers_lengths_min >= minimum_speaker_segments:\n",
    "            recording_indexes = []\n",
    "            for speakers_ids in speakers_indexes:\n",
    "                speakers_indexes[speakers_ids] = speakers_indexes[speakers_ids][:speakers_lengths_min]\n",
    "                recording_indexes += speakers_indexes[speakers_ids]\n",
    "            new_recordings_segments[recording_id] = [segment for index, segment in enumerate(recordings_segments[recording_id]) if index in recording_indexes]\n",
    "    print('Recordings left: ' + str(len(new_recordings_segments)) + '/' + str(len(recordings_segments)))\n",
    "    return new_recordings_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recordings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def generate_speaker_model(recording_segments,\n",
    "                           speaker_indexes,\n",
    "                           segments_length,\n",
    "                           vector = 'ivectors',\n",
    "                           selection = 'first',\n",
    "                           indexes = []):\n",
    "    #if segments_length > len(speaker_indexes):\n",
    "    #    print('WARNING: there are less speaker indexes than segments.')\n",
    "    if selection == 'first':\n",
    "        selected_segments = [segment for index, segment in enumerate(recording_segments) if index in speaker_indexes[:segments_length]]\n",
    "    elif selection == 'random':\n",
    "        selected_segments = [recording_segments[index] for index in random.sample(speaker_indexes, segments_length if segments_length < len(speaker_indexes) else len(speaker_indexes))]\n",
    "    elif selection == 'indexes':\n",
    "        selected_segments = [recording_segments[index] for index in indexes]\n",
    "    else:\n",
    "        print('ERROR: unknown speaker model segments selection strategy.')\n",
    "    selected_vectors = [np.asarray(segment[vector][0]['value']) for segment in selected_segments]\n",
    "    return np.sum(selected_vectors, 0) / len(selected_vectors)\n",
    "    \n",
    "\n",
    "class Recordings_dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 recordings_segments,\n",
    "                 recordings_ids = None,\n",
    "                 vector = 'ivectors',\n",
    "                 models_container_length = 2,\n",
    "                 models_container_include_zeros = True,\n",
    "                 models_container_include_overlaps = False,\n",
    "                 models_generation_lengths = [3],\n",
    "                 models_generation_selection = 'first',\n",
    "                 balance_segments = True,\n",
    "                 balance_segments_selection = 'copy'):\n",
    "        # -----------------------------------------------------Saving input data----- #\n",
    "        if recordings_ids is None:\n",
    "            recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "        self.recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "        self.recordings_segments = {}\n",
    "        for recording_id in self.recordings_ids:\n",
    "            self.recordings_segments[recording_id] = recordings_segments[recording_id]\n",
    "        self.vector = vector\n",
    "        self.models_container_length = models_container_length\n",
    "        self.models_container_include_zeros = models_container_include_zeros\n",
    "        self.models_container_include_overlaps = models_container_include_overlaps\n",
    "        self.models_generation_lengths = models_generation_lengths\n",
    "        self.models_generation_selection = models_generation_selection\n",
    "        self.balance_segments = balance_segments\n",
    "        self.balance_segments_selection = balance_segments_selection\n",
    "        # --------------------------------------------------------------------------- #\n",
    "        self.recordings_data = {}\n",
    "        # -------------------------------------------------- #\n",
    "        self.recordings_map = []\n",
    "        self.recordings_length = 0\n",
    "        for recording_id in self.recordings_ids:\n",
    "            self.recordings_data[recording_id] = {}\n",
    "            recording_segments = self.recordings_segments[recording_id]\n",
    "            recording_data = self.recordings_data[recording_id]\n",
    "            # ----- Obtaining speakers indexes ----- #\n",
    "            recording_data['speakers_indexes'] = [(sorted(list(set([speaker['speaker_id'] for speaker in segment['speakers']]))), index) for index, segment in enumerate(recording_segments)]\n",
    "            recording_data['speakers_indexes'] = reduce(speakers_get_indexes, recording_data['speakers_indexes'], {})\n",
    "            # ----- Balancing speakers segments ----- #\n",
    "            recording_data['speakers_indexes_lengths_max'] = max([len(recording_data['speakers_indexes'][speakers_ids]) for speakers_ids in recording_data['speakers_indexes']])\n",
    "            if self.balance_segments:\n",
    "                if self.balance_segments_selection == 'copy':\n",
    "                    for speakers_ids in recording_data['speakers_indexes']:\n",
    "                        for i in range(recording_data['speakers_indexes_lengths_max'] - len(recording_data['speakers_indexes'][speakers_ids])):\n",
    "                            index = random.choice(recording_data['speakers_indexes'][speakers_ids])\n",
    "                            recording_segments.append(recording_segments[index])\n",
    "                            recording_data['speakers_indexes'][speakers_ids].append(len(recording_segments) - 1)\n",
    "                else:\n",
    "                    print('ERROR: unknown balancing segments selection strategy.')\n",
    "            # ----- Generating speakers models ----- #\n",
    "            recording_data['speakers_models'] = {}\n",
    "            for speakers_ids in recording_data['speakers_indexes']:\n",
    "                recording_data['speakers_models'][speakers_ids] = {}\n",
    "                for models_generation_length in models_generation_lengths:\n",
    "                    speakers_model = generate_speaker_model(recording_segments, recording_data['speakers_indexes'][speakers_ids], models_generation_length, self.vector, self.models_generation_selection)\n",
    "                    recording_data['speakers_models'][speakers_ids][models_generation_length] = [speakers_model]\n",
    "            # ----- Generating permutations ----- #\n",
    "            if self.models_container_include_zeros:\n",
    "                recording_data['permutations'] = list(itertools.permutations(list(recording_data['speakers_models'].keys()) \\\n",
    "                + ['0' for i in range(self.models_container_length)], self.models_container_length))\n",
    "            else:\n",
    "                recording_data['permutations'] = list(itertools.permutations(list(recording_data['speakers_models'].keys()), self.models_container_length))\n",
    "            recording_data['permutations'] = list(set(recording_data['permutations']))\n",
    "            recording_data['permutations'].sort()\n",
    "            if not self.models_container_include_overlaps:\n",
    "                recording_data['permutations'] = [permutation for permutation in recording_data['permutations'] if all(len(speakers_ids.split(',')) == 1 for speakers_ids in permutation)]\n",
    "            # -------------------------------------------------- #\n",
    "            recording_data['permutations_map'] = []\n",
    "            recording_data['permutations_length'] = 0\n",
    "            for index, permutation in enumerate(recording_data['permutations']):\n",
    "                speakers_models_length = int(np.prod([np.sum([len(recording_data['speakers_models'][speakers_ids][models_generation_length]) for models_generation_length in recording_data['speakers_models'][speakers_ids]]) for speakers_ids in permutation if speakers_ids != '0']))\n",
    "                recording_data['permutations_map'].append((recording_data['permutations_length'], recording_data['permutations_length'] + speakers_models_length - 1, index))\n",
    "                recording_data['permutations_length'] += speakers_models_length\n",
    "            recording_data['length'] = len(recording_segments) * recording_data['permutations_length']\n",
    "            self.recordings_map.append((self.recordings_length, self.recordings_length + recording_data['length'] - 1, recording_id))\n",
    "            self.recordings_length += recording_data['length']\n",
    "    def __len__(self):\n",
    "        return self.recordings_length\n",
    "    def __getitem__(self, idx):\n",
    "        recording_limits = list(filter(lambda recording_limits: recording_limits[0] <= idx and idx <= recording_limits[1], self.recordings_map))[0]\n",
    "        recording_idx = idx - recording_limits[0]\n",
    "        recording_id = recording_limits[2]\n",
    "        recording_data = self.recordings_data[recording_id]\n",
    "        \n",
    "        segment_index, segment_idx = divmod(recording_idx, recording_data['permutations_length'])\n",
    "        segment = self.recordings_segments[recording_id][segment_index]\n",
    "        vector = np.asarray(segment[self.vector][0]['value'])\n",
    "        \n",
    "        permutation_limits = list(filter(lambda permutation_limits: permutation_limits[0] <= segment_idx and segment_idx <= permutation_limits[1], recording_data['permutations_map']))[0]\n",
    "        permutation_idx = segment_idx - permutation_limits[0]\n",
    "        permutation_index = permutation_limits[2]\n",
    "        permutation = recording_data['permutations'][permutation_index]\n",
    "        \n",
    "        speakers_models_lengths = [np.sum([len(recording_data['speakers_models'][speakers_ids][models_generation_length]) for models_generation_length in recording_data['speakers_models'][speakers_ids]])  if speakers_ids != '0' else 1 for speakers_ids in permutation]\n",
    "        models_container = []\n",
    "        model_index = permutation_idx\n",
    "        for i, length_i in enumerate(speakers_models_lengths):\n",
    "            if i != len(speakers_models_lengths) - 1:\n",
    "                model_index, remainder = divmod(model_index, np.sum(speakers_models_lengths[i + 1:]))\n",
    "            else:\n",
    "                model_index = remainder\n",
    "            models_container.append(recording_data['speakers_models'][permutation[i]][self.models_generation_lengths[model_index]][0] if permutation[i] != '0' else np.random.uniform(-0.1, 0.1, len(vector)))\n",
    "        \n",
    "        models_weigths = np.asarray([len(recording_data['speakers_indexes'][speakers_ids]) if speakers_ids != '0' else recording_data['speakers_indexes_lengths_max'] for speakers_ids in permutation])\n",
    "        models_weigths_sum = np.sum(models_weigths)\n",
    "        models_weigths = np.ones(len(models_weigths)) - models_weigths / models_weigths_sum\n",
    "        \n",
    "        targets_ids = [speaker['speaker_id'] for speaker in segment['speakers']]\n",
    "        \n",
    "        x = [vector] + models_container\n",
    "        if self.models_container_include_overlaps:\n",
    "            targets_ids = ','.join(sorted(list(set(targets_ids))))\n",
    "            y = np.asarray([speakers_ids == targets_ids for speakers_ids in permutation], dtype = float)\n",
    "        else:\n",
    "            y = np.asarray([speaker_id in targets_ids for speaker_id in permutation], dtype = float) / len(targets_ids)\n",
    "        z = models_weigths\n",
    "        \n",
    "        return x, y, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load live_graph.py\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Live_graph:\n",
    "    def __init__(self, validation_threshold):\n",
    "        self.plt_count = -1\n",
    "        self.validation_threshold = validation_threshold\n",
    "        self.plt_thr = ([self.plt_count], [self.validation_threshold])\n",
    "        self.plt_loss = ([self.plt_count], [1])\n",
    "        self.plt_valid = ([self.plt_count], [1])\n",
    "        self.plt_test = ([self.plt_count], [1])\n",
    "        self.fig = plt.figure()\n",
    "        self.ax = self.fig.add_subplot()\n",
    "        self.line0, = self.ax.plot(self.plt_thr[0], self.plt_thr[1], 'k--', label = 'Threshold') # Threshold line\n",
    "        self.line1, = self.ax.plot(self.plt_loss[0], self.plt_loss[1], '--', label = 'Training') # Training loss\n",
    "        self.line2, = self.ax.plot(self.plt_valid[0], self.plt_valid[1], label = 'Validation')   # Validation loss\n",
    "        self.line3, = self.ax.plot(self.plt_test[0], self.plt_test[1], label = 'Test')           # Test loss\n",
    "        self.ax.set_xlabel('Epoch')\n",
    "        self.ax.set_ylabel('Loss')\n",
    "        self.ax.legend()\n",
    "        self.ax.set_xlim(-1, 0)\n",
    "        self.ax.set_ylim(0, 0.5)\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.canvas.flush_events()\n",
    "    def step(self, training, validation, test = -1):\n",
    "        self.plt_count += 1\n",
    "        self.plt_thr[0].append(self.plt_count)\n",
    "        self.plt_thr[1].append(self.validation_threshold)\n",
    "        self.plt_loss[0].append(self.plt_count)\n",
    "        self.plt_loss[1].append(training)\n",
    "        self.plt_valid[0].append(self.plt_count)\n",
    "        self.plt_valid[1].append(validation)\n",
    "        self.plt_test[0].append(self.plt_count)\n",
    "        self.plt_test[1].append(test)\n",
    "        self.line0.set_xdata(self.plt_thr[0])\n",
    "        self.line0.set_ydata(self.plt_thr[1])\n",
    "        self.line1.set_xdata(self.plt_loss[0])\n",
    "        self.line1.set_ydata(self.plt_loss[1])\n",
    "        self.line2.set_xdata(self.plt_valid[0])\n",
    "        self.line2.set_ydata(self.plt_valid[1])\n",
    "        self.line3.set_xdata(self.plt_test[0])\n",
    "        self.line3.set_ydata(self.plt_test[1])\n",
    "        self.ax.set_xlim(0, self.plt_count + 1)\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.canvas.flush_events()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, models_container_length, vector_length):\n",
    "        super().__init__()\n",
    "        n = models_container_length\n",
    "        m = vector_length\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv1d((n + 1), n ** 3, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(n ** 3, n ** 2, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(n ** 2, n, 3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(n * (m - 6), n * 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n * 16, n * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n * 4, n),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = torch.stack(input, 1)\n",
    "        x = self.cnn1(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self):\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device('cuda:0')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "    def get_net(self,\n",
    "                recordings_segments,\n",
    "                recordings_ids = None,\n",
    "                vector = 'ivectors',\n",
    "                vector_length = 128,\n",
    "                models_container_length = 2,\n",
    "                models_container_include_zeros = True,\n",
    "                models_container_include_overlaps = False,\n",
    "                models_generation_lengths = [3],\n",
    "                models_generation_selection = 'first',\n",
    "                balance_segments = True,\n",
    "                balance_segments_selection = 'copy',\n",
    "                batch_size = 16,\n",
    "                num_workers = 8,\n",
    "                test_recordings_segments = None):\n",
    "        \n",
    "        if recordings_ids is None:\n",
    "            recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "        self.recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "\n",
    "        train_dataset = Recordings_dataset(recordings_segments,\n",
    "                                           recordings_ids, \n",
    "                                           vector,\n",
    "                                           models_container_length,\n",
    "                                           models_container_include_zeros,\n",
    "                                           models_container_include_overlaps,\n",
    "                                           models_generation_lengths,\n",
    "                                           models_generation_selection,\n",
    "                                           balance_segments,\n",
    "                                           balance_segments_selection)\n",
    "\n",
    "        train_length = int(len(train_dataset) * 0.7)\n",
    "        valid_length = len(train_dataset) - train_length\n",
    "\n",
    "        train_dataset, valid_dataset = random_split(train_dataset, [train_length, valid_length])\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers = num_workers)\n",
    "        valid_dataloader = DataLoader(valid_dataset, batch_size = batch_size, num_workers = num_workers)\n",
    "        \n",
    "        if test_recordings_segments is not None:\n",
    "            test_recordings_ids = [recording_id for recording_id in test_recordings_segments]\n",
    "            test_dataset = Recordings_dataset(test_recordings_segments,\n",
    "                                              test_recordings_ids,\n",
    "                                              vector,\n",
    "                                              models_container_length,\n",
    "                                              models_container_include_zeros,\n",
    "                                              models_container_include_overlaps,\n",
    "                                              models_generation_lengths,\n",
    "                                              models_generation_selection,\n",
    "                                              balance_segments,\n",
    "                                              balance_segments_selection)\n",
    "            test_dataloader = DataLoader(test_dataset, batch_size = batch_size, num_workers = num_workers)\n",
    "\n",
    "        net = Net(models_container_length, vector_length).to(self.device)\n",
    "        optimizer = optim.Adam(net.parameters(), lr = 0.0001)\n",
    "\n",
    "        epochs = 50\n",
    "        validation_threshold = 0.08\n",
    "\n",
    "        live_graph = Live_graph(validation_threshold)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_losses = []\n",
    "            for input, target, weigth in train_dataloader:\n",
    "                input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                target = target.to(self.device, non_blocking = True).float()\n",
    "                weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                criterion = nn.BCELoss(weigth)\n",
    "                net.zero_grad()\n",
    "                output = net(input)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_losses.append(loss.data)\n",
    "                print('train: ' + str(len(train_losses)) + '/' + str(len(train_dataloader)) + '          ', end = '\\r')\n",
    "            train_loss = np.sum(train_losses) / len(train_losses)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                validation_losses = []\n",
    "                for input, target, weigth in valid_dataloader:\n",
    "                    input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                    target = target.to(self.device, non_blocking = True).float()\n",
    "                    weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                    criterion = nn.BCELoss(weigth)\n",
    "                    output = net(input)\n",
    "                    loss = criterion(output, target)\n",
    "                    validation_losses.append(loss.data)\n",
    "                    print('validation: ' + str(len(validation_losses)) + '/' + str(len(valid_dataloader)) + '          ', end = '\\r')\n",
    "                validation_loss = np.sum(validation_losses) / len(validation_losses)\n",
    "                \n",
    "                test_loss = -1\n",
    "                if test_recordings_segments is not None:\n",
    "                    test_losses = []\n",
    "                    for input, target, weigth in test_dataloader:\n",
    "                        input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                        target = target.to(self.device, non_blocking = True).float()\n",
    "                        weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                        criterion = nn.BCELoss(weigth)\n",
    "                        output = net(input)\n",
    "                        loss = criterion(output, target)\n",
    "                        test_losses.append(loss.data)\n",
    "                        print('test: ' + str(len(test_losses)) + '/' + str(len(test_dataloader)) + '          ', end = '\\r')\n",
    "                    test_loss = np.sum(test_losses) / len(test_losses)\n",
    "\n",
    "            live_graph.step(train_loss, validation_loss, test_loss)\n",
    "\n",
    "            if validation_loss <= validation_threshold:\n",
    "                print('Done training.')\n",
    "                break\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load md_eval.py\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "def md_eval(ref_filepath, res_filepath, save_filepath = None):\n",
    "    bin = '../../../../tools/sctk-2.4.10/src/md-eval/md-eval.pl'\n",
    "    p = subprocess.Popen([bin, '-r', ref_filepath, '-s', res_filepath], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output, err = p.communicate()\n",
    "    rc = p.returncode\n",
    "    if rc == 0:\n",
    "        output = output.decode(\"utf-8\")\n",
    "        if save_filepath is not None:\n",
    "            file = open(save_filepath, 'w')\n",
    "            file.write(output)\n",
    "            file.close()\n",
    "        lines =  output.split('\\n')\n",
    "        derLine = [line for line in lines if 'OVERALL SPEAKER DIARIZATION ERROR' in line][0]\n",
    "        return float(re.findall('\\d+\\.\\d+', derLine)[0])\n",
    "    else:\n",
    "        exit('md-eval.pl fail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracking_tester(recordings_segments,\n",
    "                    recordings_ids = None,\n",
    "                    selection_function = None,\n",
    "                    groundtruth_filepath = '',\n",
    "                    groundtruth_valid_speakers_ids = ['A', 'B'],\n",
    "                    vector = 'ivectors',\n",
    "                    models_container_length = 2,\n",
    "                    models_container_include_overlaps = False,\n",
    "                    models_generation_length = 3,\n",
    "                    models_generation_selection = 'first'):\n",
    "\n",
    "    if recordings_ids is None:\n",
    "        recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "    recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "    recordings_ids.sort()\n",
    "    \n",
    "    results = {}\n",
    "    results_reduced = {}\n",
    "    results_rttm = ''\n",
    "    for recording_id in recordings_ids:\n",
    "        recording_dataset = Recordings_dataset(recordings_segments,\n",
    "                                               recording_id,\n",
    "                                               vector = vector,\n",
    "                                               models_container_length = models_container_length,\n",
    "                                               models_container_include_zeros = False,\n",
    "                                               models_container_include_overlaps = models_container_include_overlaps,\n",
    "                                               models_generation_lengths = [models_generation_length],\n",
    "                                               models_generation_selection = models_generation_selection,\n",
    "                                               balance_segments = False,\n",
    "                                               balance_segments_selection = 'copy')\n",
    "        speakers_models = recording_dataset.recordings_data[recording_id]['speakers_models']\n",
    "        models_container = [speakers_models[speakers_ids][models_generation_length][0] for speakers_ids in speakers_models if models_container_include_overlaps or len(speakers_ids.split(',')) == 1]\n",
    "        for i in range(models_container_length - len(models_container)):\n",
    "            models_container.append(np.random.uniform(-0.1, 0.1, len(models_container[0])))\n",
    "        # At this point there is no information about the speaker identity, only the model\n",
    "        results[recording_id] = []\n",
    "        for segment in recordings_segments[recording_id]:\n",
    "            segment_vector = np.asarray(segment[vector][0]['value'])\n",
    "            selection = selection_function(segment_vector, models_container)\n",
    "            index = np.argmax(selection)\n",
    "            results[recording_id].append({ 'begining': segment['begining'], 'ending': segment['ending'], 'speaker_id': index })\n",
    "            if len(results[recording_id]) > 2:\n",
    "                if results[recording_id][len(results[recording_id]) - 1]['speaker_id'] == results[recording_id][len(results[recording_id]) - 3]['speaker_id']:\n",
    "                    if results[recording_id][len(results[recording_id]) - 1]['speaker_id'] != results[recording_id][len(results[recording_id]) - 2]['speaker_id']:\n",
    "                        results[recording_id][len(results[recording_id]) - 2]['speaker_id'] = results[recording_id][len(results[recording_id]) - 1]['speaker_id']\n",
    "                        results[recording_id][len(results[recording_id]) - 1]['modified'] = True\n",
    "        results_reduced[recording_id] = []\n",
    "        last_speaker_id = -1\n",
    "        last_speaker = { 'begining': 0, 'ending': 0, 'speaker_id': -1 }\n",
    "        for segment in results[recording_id] + [{ 'begining': 0, 'ending': 0, 'speaker_id': -1 }]:\n",
    "            begining = segment['begining']\n",
    "            ending = segment['ending']\n",
    "            speaker_id = segment['speaker_id']\n",
    "            if last_speaker_id != speaker_id:\n",
    "                if last_speaker_id != -1:\n",
    "                    results_reduced[recording_id].append(last_speaker)\n",
    "                last_speaker_id = speaker_id\n",
    "                last_speaker = { 'begining': begining, 'ending': ending, 'speaker_id': speaker_id }\n",
    "            else:\n",
    "                if begining <= last_speaker['ending']:\n",
    "                    last_speaker['ending'] = ending\n",
    "                else:\n",
    "                    if last_speaker_id != -1:\n",
    "                        results_reduced[recording_id].append(last_speaker)\n",
    "                    last_speaker_id = speaker_id\n",
    "                    last_speaker = { 'begining': begining, 'ending': ending, 'speaker_id': speaker_id }\n",
    "        for segment in results_reduced[recording_id]:\n",
    "            result_rttm = 'SPEAKER ' + recording_id + ' 0 ' + str(segment['begining']) + ' ' + str(round(segment['ending'] - segment['begining'], 2)) + ' <NA> <NA> ' + str(segment['speaker_id']) + ' <NA> <NA>'\n",
    "            results_rttm += result_rttm + '\\n'\n",
    "\n",
    "    file = open(groundtruth_filepath, 'r')\n",
    "    groundtruth_rttm = ''.join([line for line in file.readlines() if (line.split(' ')[1] in recordings_ids) and \\\n",
    "                    (line.split(' ')[7] in ['A', 'B'])])\n",
    "    file.close()\n",
    "    \n",
    "    file = open('jupyter_groundtruth.rttm', 'w')\n",
    "    file.write(groundtruth_rttm)\n",
    "    file.close()\n",
    "    \n",
    "    file = open('jupyter_results.rttm', 'w')\n",
    "    file.write(results_rttm)\n",
    "    file.close()\n",
    "\n",
    "    return md_eval('jupyter_groundtruth.rttm', 'jupyter_results.rttm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading recordings segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_directory = '../exp/pre_norm/callhome1/json'\n",
    "b_directory = '../exp/pre_norm/callhome2/json'\n",
    "valid_speakers_length = 2\n",
    "valid_speakers_ids = ['A', 'B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../exp/pre_norm/callhome1/json loaded 249/249, 0.74 segments left.\n"
     ]
    }
   ],
   "source": [
    "a_recordings_segments = load_recordings_segments(a_directory, valid_speakers_length, valid_speakers_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../exp/pre_norm/callhome2/json loaded 250/250, 0.77 segments left.\n"
     ]
    }
   ],
   "source": [
    "b_recordings_segments = load_recordings_segments(b_directory, valid_speakers_length, valid_speakers_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recordings left: 221/249\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training.09/1009          \n"
     ]
    }
   ],
   "source": [
    "a_trainer = Trainer()\n",
    "a_net = a_trainer.get_net(balance_segments(a_recordings_segments, 2, 10, False),\n",
    "                          vector = 'ivectors',\n",
    "                          vector_length = 128,\n",
    "                          models_container_length = 2,\n",
    "                          models_container_include_zeros = True,\n",
    "                          models_container_include_overlaps = False,\n",
    "                          models_generation_lengths = [5],\n",
    "                          models_generation_selection = 'first',\n",
    "                          balance_segments = False,\n",
    "                          balance_segments_selection = 'copy',\n",
    "                          batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_valid_segment [DONE]\n",
    "def is_valid_segment(segment):\n",
    "    return len(segment['speakers']) == 1 \\\n",
    "            and len(segment['ivectors']) == 1 \\\n",
    "            and len(segment['xvectors']) == 1 \\\n",
    "            and segment['speakers'][0]['speaker_id'] in ['A', 'B']\n",
    "\n",
    "# load_recordings_segments [DONE]\n",
    "def load_recordings_segments(directory):\n",
    "    filenames = [filename for filename in os.listdir(directory) if os.path.isfile(os.path.join(directory, filename))]\n",
    "    recordings_segments = {}\n",
    "    recordings_length = len(filenames)\n",
    "    recordings_count = 0\n",
    "    for filename in filenames:\n",
    "        recording_id = filename.split('.')[0]\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        file = open(filepath, 'r')\n",
    "        recordings_segments[recording_id] = [json.loads(line) for line in file.readlines()]\n",
    "        file.close()\n",
    "        recordings_segments[recording_id] = list(filter(is_valid_segment, recordings_segments[recording_id]))\n",
    "        recordings_count += 1\n",
    "        print('Loading ' + directory + ' ' + str(recordings_count) + '/' + str(recordings_length), end = '\\r')\n",
    "    return recordings_segments\n",
    "\n",
    "def foo(vector, models_container, net):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    with torch.no_grad():\n",
    "        input = [torch.Tensor([nparray]).to(device, non_blocking = True).float() for nparray in [vector] + models_container]\n",
    "        output = net(input)\n",
    "        return output.cpu().data.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../exp/pre_norm/callhome2/json 250/250\r"
     ]
    }
   ],
   "source": [
    "b_recordings_segments = load_recordings_segments(b_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_tester(b_recordings_segments, None,\n",
    "                lambda vector, models_container: foo(vector, models_container, a_net),\n",
    "                '../data/callhome2_1.0_0.5.rttm',\n",
    "                ['A', 'B'],\n",
    "                models_generation_length = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
