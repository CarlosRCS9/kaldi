{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recordings segments loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from functools import reduce\n",
    "\n",
    "# is_single_speaker_segment [VALIDATED]\n",
    "# validates if a segment has a single speaker who belongs to the speakers list. \n",
    "def is_single_speaker_segment(segment, valid_speakers_ids = ['A', 'B']):\n",
    "    return len(segment['speakers']) == 1 and segment['speakers'][0]['speaker_id'] in valid_speakers_ids\n",
    "\n",
    "# is_valid_segment [VALIDATED]\n",
    "# validates if a segment meets a maximum number of speakers,\n",
    "# and that all the speakers in the segment belong to a list.\n",
    "def is_valid_segment(segment, maximum_speakers_length = 2, valid_speakers_ids = ['A', 'B']):\n",
    "    speakers_ids = [speaker['speaker_id'] for speaker in segment['speakers']]\n",
    "    speakers_ids = list(set(speakers_ids))\n",
    "    return len(speakers_ids) <= maximum_speakers_length and \\\n",
    "        all(speaker_id in valid_speakers_ids for speaker_id in speakers_ids)\n",
    "\n",
    "# load_recordings_segments [VALIDATED]\n",
    "# loads the recordings segments data from the .json files located in a directory \n",
    "def load_recordings_segments(directory, validation_function):\n",
    "    filenames = [filename for filename in os.listdir(directory) if os.path.isfile(os.path.join(directory, filename))]\n",
    "    filenames.sort()\n",
    "    recordings_segments = {}\n",
    "    recordings_length = len(filenames)\n",
    "    recordings_count = 0\n",
    "    segments_original = 0\n",
    "    segments_filtered = 0\n",
    "    for filename in filenames:\n",
    "        recording_id = filename.split('.')[0]\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        file = open(filepath, 'r')\n",
    "        recordings_segments[recording_id] = [json.loads(line) for line in file.readlines()]\n",
    "        file.close()\n",
    "        segments_original += len(recordings_segments[recording_id])\n",
    "        recordings_segments[recording_id] = list(filter(validation_function, recordings_segments[recording_id]))\n",
    "        segments_filtered += len(recordings_segments[recording_id])\n",
    "        recordings_count += 1\n",
    "        print(directory + ' loading ' + str(recordings_count) + '/' + str(recordings_length), end = '\\r')\n",
    "    print(directory, 'loaded', str(recordings_count) + '/' + str(recordings_length) + ',', round(segments_filtered / segments_original, 2), 'segments left.')\n",
    "    return recordings_segments\n",
    "\n",
    "# speakers_get_indexes [VALIDATED]\n",
    "# used to convert a (speakers_ids, index) list to a speakers_ids => [indexes] dictionary\n",
    "def speakers_get_indexes(accumulator, speakers_tuple):\n",
    "    speaker_ids, index = speakers_tuple\n",
    "    speaker_ids = ','.join(speaker_ids)\n",
    "    if speaker_ids in accumulator:\n",
    "        accumulator[speaker_ids].append(index)\n",
    "    else:\n",
    "        accumulator[speaker_ids] = [index]\n",
    "    return accumulator\n",
    "\n",
    "# balance_segments [VALIDATED]\n",
    "# balances the recording segments data to meet a minimum of speakers per recording,\n",
    "# and a minimum of segments per speaker.\n",
    "def balance_segments(recordings_segments,\n",
    "                     minimum_speakers_length = 2,\n",
    "                     minimum_speaker_segments = 3,\n",
    "                     include_overlaps = False):\n",
    "    new_recordings_segments = {}\n",
    "    for recording_id in recordings_segments:\n",
    "        recording_segments = recordings_segments[recording_id]\n",
    "        # ----- Obtaining speakers indexes ----- #\n",
    "        speakers_indexes = [(sorted(list(set([speaker['speaker_id'] for speaker in segment['speakers']]))), index) for index, segment in enumerate(recording_segments)]\n",
    "        speakers_indexes = reduce(speakers_get_indexes, speakers_indexes, {})\n",
    "        # ----- Removing overlaps ----- #\n",
    "        if not include_overlaps:\n",
    "            for speakers_ids in list(speakers_indexes.keys()):\n",
    "                if len(speakers_ids.split(',')) > 1:\n",
    "                    del speakers_indexes[speakers_ids]\n",
    "        speakers_lengths = [(speakers_ids, len(speakers_indexes[speakers_ids])) for speakers_ids in speakers_indexes]\n",
    "        speakers_lengths.sort(key = lambda x: x[1])\n",
    "        speakers_lengths_min = speakers_lengths[0][1]\n",
    "        if len(speakers_lengths) >= minimum_speakers_length and speakers_lengths_min >= minimum_speaker_segments:\n",
    "            recording_indexes = []\n",
    "            for speakers_ids in speakers_indexes:\n",
    "                speakers_indexes[speakers_ids] = speakers_indexes[speakers_ids][:speakers_lengths_min]\n",
    "                recording_indexes += speakers_indexes[speakers_ids]\n",
    "            new_recordings_segments[recording_id] = [segment for index, segment in enumerate(recordings_segments[recording_id]) if index in recording_indexes]\n",
    "    print('Recordings left: ' + str(len(new_recordings_segments)) + '/' + str(len(recordings_segments)))\n",
    "    return new_recordings_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recordings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def generate_speaker_model(recording_segments,\n",
    "                           speaker_indexes,\n",
    "                           segments_length,\n",
    "                           vector = 'ivectors',\n",
    "                           selection = 'first',\n",
    "                           indexes = []):\n",
    "    #if segments_length > len(speaker_indexes):\n",
    "    #    print('WARNING: there are less speaker indexes than segments.')\n",
    "    if selection == 'first':\n",
    "        selected_segments = [segment for index, segment in enumerate(recording_segments) if index in speaker_indexes[:segments_length]]\n",
    "    elif selection == 'random':\n",
    "        selected_segments = [recording_segments[index] for index in random.sample(speaker_indexes, segments_length if segments_length < len(speaker_indexes) else len(speaker_indexes))]\n",
    "    elif selection == 'indexes':\n",
    "        selected_segments = [recording_segments[index] for index in indexes]\n",
    "    else:\n",
    "        print('ERROR: unknown speaker model segments selection strategy.')\n",
    "    selected_vectors = [np.asarray(segment[vector][0]['value']) for segment in selected_segments]\n",
    "    return np.sum(selected_vectors, 0) / len(selected_vectors)\n",
    "    \n",
    "\n",
    "class Recordings_dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 recordings_segments,\n",
    "                 recordings_ids = None,\n",
    "                 vector = 'ivectors',\n",
    "                 models_container_length = 2,\n",
    "                 models_container_include_zeros = True,\n",
    "                 models_container_include_overlaps = False,\n",
    "                 models_generation_lengths = [3],\n",
    "                 models_generation_selection = 'first',\n",
    "                 balance_segments = True,\n",
    "                 balance_segments_selection = 'copy'):\n",
    "        # -----------------------------------------------------Saving input data----- #\n",
    "        if recordings_ids is None:\n",
    "            recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "        self.recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "        self.recordings_segments = {}\n",
    "        for recording_id in self.recordings_ids:\n",
    "            self.recordings_segments[recording_id] = recordings_segments[recording_id]\n",
    "        self.vector = vector\n",
    "        self.models_container_length = models_container_length\n",
    "        self.models_container_include_zeros = models_container_include_zeros\n",
    "        self.models_container_include_overlaps = models_container_include_overlaps\n",
    "        self.models_generation_lengths = models_generation_lengths\n",
    "        self.models_generation_selection = models_generation_selection\n",
    "        self.balance_segments = balance_segments\n",
    "        self.balance_segments_selection = balance_segments_selection\n",
    "        # --------------------------------------------------------------------------- #\n",
    "        self.recordings_data = {}\n",
    "        # -------------------------------------------------- #\n",
    "        self.recordings_map = []\n",
    "        self.recordings_length = 0\n",
    "        for recording_id in self.recordings_ids:\n",
    "            self.recordings_data[recording_id] = {}\n",
    "            recording_segments = self.recordings_segments[recording_id]\n",
    "            recording_data = self.recordings_data[recording_id]\n",
    "            # ----- Obtaining speakers indexes ----- #\n",
    "            recording_data['speakers_indexes'] = [(sorted(list(set([speaker['speaker_id'] for speaker in segment['speakers']]))), index) for index, segment in enumerate(recording_segments)]\n",
    "            recording_data['speakers_indexes'] = reduce(speakers_get_indexes, recording_data['speakers_indexes'], {})\n",
    "            # ----- Balancing speakers segments ----- #\n",
    "            recording_data['speakers_indexes_lengths_max'] = max([len(recording_data['speakers_indexes'][speakers_ids]) for speakers_ids in recording_data['speakers_indexes']])\n",
    "            if self.balance_segments:\n",
    "                if self.balance_segments_selection == 'copy':\n",
    "                    for speakers_ids in recording_data['speakers_indexes']:\n",
    "                        for i in range(recording_data['speakers_indexes_lengths_max'] - len(recording_data['speakers_indexes'][speakers_ids])):\n",
    "                            index = random.choice(recording_data['speakers_indexes'][speakers_ids])\n",
    "                            recording_segments.append(recording_segments[index])\n",
    "                            recording_data['speakers_indexes'][speakers_ids].append(len(recording_segments) - 1)\n",
    "                else:\n",
    "                    print('ERROR: unknown balancing segments selection strategy.')\n",
    "            # ----- Generating speakers models ----- #\n",
    "            recording_data['speakers_models'] = {}\n",
    "            for speakers_ids in recording_data['speakers_indexes']:\n",
    "                recording_data['speakers_models'][speakers_ids] = {}\n",
    "                for models_generation_length in models_generation_lengths:\n",
    "                    speakers_model = generate_speaker_model(recording_segments, recording_data['speakers_indexes'][speakers_ids], models_generation_length, self.vector, self.models_generation_selection)\n",
    "                    recording_data['speakers_models'][speakers_ids][models_generation_length] = [speakers_model]\n",
    "            # ----- Generating permutations ----- #\n",
    "            if self.models_container_include_zeros:\n",
    "                recording_data['permutations'] = list(itertools.permutations(list(recording_data['speakers_models'].keys()) \\\n",
    "                + ['0' for i in range(self.models_container_length)], self.models_container_length))\n",
    "            else:\n",
    "                recording_data['permutations'] = list(itertools.permutations(list(recording_data['speakers_models'].keys()), self.models_container_length))\n",
    "            recording_data['permutations'] = list(set(recording_data['permutations']))\n",
    "            recording_data['permutations'].sort()\n",
    "            if not self.models_container_include_overlaps:\n",
    "                recording_data['permutations'] = [permutation for permutation in recording_data['permutations'] if all(len(speakers_ids.split(',')) == 1 for speakers_ids in permutation)]\n",
    "            # -------------------------------------------------- #\n",
    "            recording_data['permutations_map'] = []\n",
    "            recording_data['permutations_length'] = 0\n",
    "            for index, permutation in enumerate(recording_data['permutations']):\n",
    "                speakers_models_length = int(np.prod([np.sum([len(recording_data['speakers_models'][speakers_ids][models_generation_length]) for models_generation_length in recording_data['speakers_models'][speakers_ids]]) for speakers_ids in permutation if speakers_ids != '0']))\n",
    "                recording_data['permutations_map'].append((recording_data['permutations_length'], recording_data['permutations_length'] + speakers_models_length - 1, index))\n",
    "                recording_data['permutations_length'] += speakers_models_length\n",
    "            recording_data['length'] = len(recording_segments) * recording_data['permutations_length']\n",
    "            self.recordings_map.append((self.recordings_length, self.recordings_length + recording_data['length'] - 1, recording_id))\n",
    "            self.recordings_length += recording_data['length']\n",
    "    def __len__(self):\n",
    "        return self.recordings_length\n",
    "    def __getitem__(self, idx):\n",
    "        recording_limits = list(filter(lambda recording_limits: recording_limits[0] <= idx and idx <= recording_limits[1], self.recordings_map))[0]\n",
    "        recording_idx = idx - recording_limits[0]\n",
    "        recording_id = recording_limits[2]\n",
    "        recording_data = self.recordings_data[recording_id]\n",
    "        \n",
    "        segment_index, segment_idx = divmod(recording_idx, recording_data['permutations_length'])\n",
    "        segment = self.recordings_segments[recording_id][segment_index]\n",
    "        vector = np.asarray(segment[self.vector][0]['value'])\n",
    "        \n",
    "        permutation_limits = list(filter(lambda permutation_limits: permutation_limits[0] <= segment_idx and segment_idx <= permutation_limits[1], recording_data['permutations_map']))[0]\n",
    "        permutation_idx = segment_idx - permutation_limits[0]\n",
    "        permutation_index = permutation_limits[2]\n",
    "        permutation = recording_data['permutations'][permutation_index]\n",
    "        \n",
    "        speakers_models_lengths = [np.sum([len(recording_data['speakers_models'][speakers_ids][models_generation_length]) for models_generation_length in recording_data['speakers_models'][speakers_ids]])  if speakers_ids != '0' else 1 for speakers_ids in permutation]\n",
    "        models_container = []\n",
    "        model_index = permutation_idx\n",
    "        for i, length_i in enumerate(speakers_models_lengths):\n",
    "            if i != len(speakers_models_lengths) - 1:\n",
    "                model_index, remainder = divmod(model_index, np.sum(speakers_models_lengths[i + 1:]))\n",
    "            else:\n",
    "                model_index = remainder\n",
    "            models_container.append(recording_data['speakers_models'][permutation[i]][self.models_generation_lengths[model_index]][0] if permutation[i] != '0' else np.random.uniform(-0.1, 0.1, len(vector)))\n",
    "        \n",
    "        models_weigths = np.asarray([len(recording_data['speakers_indexes'][speakers_ids]) if speakers_ids != '0' else recording_data['speakers_indexes_lengths_max'] for speakers_ids in permutation])\n",
    "        models_weigths_sum = np.sum(models_weigths)\n",
    "        models_weigths = np.ones(len(models_weigths)) - models_weigths / models_weigths_sum\n",
    "        \n",
    "        targets_ids = [speaker['speaker_id'] for speaker in segment['speakers']]\n",
    "        \n",
    "        x = [vector] + models_container\n",
    "        if self.models_container_include_overlaps:\n",
    "            targets_ids = ','.join(sorted(list(set(targets_ids))))\n",
    "            y = np.asarray([speakers_ids == targets_ids for speakers_ids in permutation], dtype = float)\n",
    "        else:\n",
    "            y = np.asarray([speaker_id in targets_ids for speaker_id in permutation], dtype = float) / len(targets_ids)\n",
    "        z = models_weigths\n",
    "        \n",
    "        return x, y, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load live_graph.py\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Live_graph:\n",
    "    def __init__(self, validation_threshold):\n",
    "        self.plt_count = -1\n",
    "        self.validation_threshold = validation_threshold\n",
    "        self.plt_thr = ([self.plt_count], [self.validation_threshold])\n",
    "        self.plt_loss = ([self.plt_count], [1])\n",
    "        self.plt_valid = ([self.plt_count], [1])\n",
    "        self.plt_test = ([self.plt_count], [1])\n",
    "        self.fig = plt.figure()\n",
    "        self.ax = self.fig.add_subplot()\n",
    "        self.line0, = self.ax.plot(self.plt_thr[0], self.plt_thr[1], 'k--', label = 'Threshold') # Threshold line\n",
    "        self.line1, = self.ax.plot(self.plt_loss[0], self.plt_loss[1], '--', label = 'Training') # Training loss\n",
    "        self.line2, = self.ax.plot(self.plt_valid[0], self.plt_valid[1], label = 'Validation')   # Validation loss\n",
    "        self.line3, = self.ax.plot(self.plt_test[0], self.plt_test[1], label = 'Test')           # Test loss\n",
    "        self.ax.set_xlabel('Epoch')\n",
    "        self.ax.set_ylabel('Loss')\n",
    "        self.ax.legend()\n",
    "        self.ax.set_xlim(-1, 0)\n",
    "        self.ax.set_ylim(0, 0.5)\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.canvas.flush_events()\n",
    "    def step(self, training, validation, test = -1):\n",
    "        self.plt_count += 1\n",
    "        self.plt_thr[0].append(self.plt_count)\n",
    "        self.plt_thr[1].append(self.validation_threshold)\n",
    "        self.plt_loss[0].append(self.plt_count)\n",
    "        self.plt_loss[1].append(training)\n",
    "        self.plt_valid[0].append(self.plt_count)\n",
    "        self.plt_valid[1].append(validation)\n",
    "        self.plt_test[0].append(self.plt_count)\n",
    "        self.plt_test[1].append(test)\n",
    "        self.line0.set_xdata(self.plt_thr[0])\n",
    "        self.line0.set_ydata(self.plt_thr[1])\n",
    "        self.line1.set_xdata(self.plt_loss[0])\n",
    "        self.line1.set_ydata(self.plt_loss[1])\n",
    "        self.line2.set_xdata(self.plt_valid[0])\n",
    "        self.line2.set_ydata(self.plt_valid[1])\n",
    "        self.line3.set_xdata(self.plt_test[0])\n",
    "        self.line3.set_ydata(self.plt_test[1])\n",
    "        self.ax.set_xlim(0, self.plt_count + 1)\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.canvas.flush_events()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, models_container_length, vector_length):\n",
    "        super().__init__()\n",
    "        n = models_container_length\n",
    "        m = vector_length\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv1d((n + 1), n ** 3, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(n ** 3, n ** 2, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(n ** 2, n, 3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(n * (m - 6), n * 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n * 16, n * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n * 4, n),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = torch.stack(input, 1)\n",
    "        x = self.cnn1(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self):\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device('cuda:0')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "    def get_net(self,\n",
    "                recordings_segments,\n",
    "                recordings_ids = None,\n",
    "                vector = 'ivectors',\n",
    "                vector_length = 128,\n",
    "                models_container_length = 2,\n",
    "                models_container_include_zeros = True,\n",
    "                models_container_include_overlaps = False,\n",
    "                models_generation_lengths = [3],\n",
    "                models_generation_selection = 'first',\n",
    "                balance_segments = True,\n",
    "                balance_segments_selection = 'copy',\n",
    "                batch_size = 16,\n",
    "                num_workers = 8,\n",
    "                test_recordings_segments = None):\n",
    "        \n",
    "        if recordings_ids is None:\n",
    "            recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "        self.recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "\n",
    "        train_dataset = Recordings_dataset(recordings_segments,\n",
    "                                           recordings_ids, \n",
    "                                           vector,\n",
    "                                           models_container_length,\n",
    "                                           models_container_include_zeros,\n",
    "                                           models_container_include_overlaps,\n",
    "                                           models_generation_lengths,\n",
    "                                           models_generation_selection,\n",
    "                                           balance_segments,\n",
    "                                           balance_segments_selection)\n",
    "\n",
    "        train_length = int(len(train_dataset) * 0.7)\n",
    "        valid_length = len(train_dataset) - train_length\n",
    "\n",
    "        train_dataset, valid_dataset = random_split(train_dataset, [train_length, valid_length])\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers = num_workers)\n",
    "        valid_dataloader = DataLoader(valid_dataset, batch_size = batch_size, num_workers = num_workers)\n",
    "        \n",
    "        if test_recordings_segments is not None:\n",
    "            test_recordings_ids = [recording_id for recording_id in test_recordings_segments]\n",
    "            test_dataset = Recordings_dataset(test_recordings_segments,\n",
    "                                              test_recordings_ids,\n",
    "                                              vector,\n",
    "                                              models_container_length,\n",
    "                                              models_container_include_zeros,\n",
    "                                              models_container_include_overlaps,\n",
    "                                              models_generation_lengths,\n",
    "                                              models_generation_selection,\n",
    "                                              balance_segments,\n",
    "                                              balance_segments_selection)\n",
    "            test_dataloader = DataLoader(test_dataset, batch_size = batch_size, num_workers = num_workers)\n",
    "\n",
    "        net = Net(models_container_length, vector_length).to(self.device)\n",
    "        optimizer = optim.Adam(net.parameters(), lr = 0.0001)\n",
    "\n",
    "        epochs = 50\n",
    "        validation_threshold = 0.1\n",
    "\n",
    "        live_graph = Live_graph(validation_threshold)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_losses = []\n",
    "            for input, target, weigth in train_dataloader:\n",
    "                input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                target = target.to(self.device, non_blocking = True).float()\n",
    "                weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                criterion = nn.BCELoss(weigth)\n",
    "                net.zero_grad()\n",
    "                output = net(input)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_losses.append(loss.data)\n",
    "                print('train: ' + str(len(train_losses)) + '/' + str(len(train_dataloader)) + '          ', end = '\\r')\n",
    "            train_loss = np.sum(train_losses) / len(train_losses)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                validation_losses = []\n",
    "                for input, target, weigth in valid_dataloader:\n",
    "                    input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                    target = target.to(self.device, non_blocking = True).float()\n",
    "                    weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                    criterion = nn.BCELoss(weigth)\n",
    "                    output = net(input)\n",
    "                    loss = criterion(output, target)\n",
    "                    validation_losses.append(loss.data)\n",
    "                    print('validation: ' + str(len(validation_losses)) + '/' + str(len(valid_dataloader)) + '          ', end = '\\r')\n",
    "                validation_loss = np.sum(validation_losses) / len(validation_losses)\n",
    "                \n",
    "                test_loss = -1\n",
    "                if test_recordings_segments is not None:\n",
    "                    test_losses = []\n",
    "                    for input, target, weigth in test_dataloader:\n",
    "                        input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                        target = target.to(self.device, non_blocking = True).float()\n",
    "                        weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                        criterion = nn.BCELoss(weigth)\n",
    "                        output = net(input)\n",
    "                        loss = criterion(output, target)\n",
    "                        test_losses.append(loss.data)\n",
    "                        print('test: ' + str(len(test_losses)) + '/' + str(len(test_dataloader)) + '          ', end = '\\r')\n",
    "                    test_loss = np.sum(test_losses) / len(test_losses)\n",
    "\n",
    "            live_graph.step(train_loss, validation_loss, test_loss)\n",
    "\n",
    "            if validation_loss <= validation_threshold:\n",
    "                print('Done training.')\n",
    "                break\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load md_eval.py\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "def md_eval(ref_filepath, res_filepath, save_filepath = None):\n",
    "    bin = '../../../../tools/sctk-2.4.10/src/md-eval/md-eval.pl'\n",
    "    p = subprocess.Popen([bin, '-r', ref_filepath, '-s', res_filepath], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output, err = p.communicate()\n",
    "    rc = p.returncode\n",
    "    if rc == 0:\n",
    "        output = output.decode(\"utf-8\")\n",
    "        if save_filepath is not None:\n",
    "            file = open(save_filepath, 'w')\n",
    "            file.write(output)\n",
    "            file.close()\n",
    "        lines =  output.split('\\n')\n",
    "        derLine = [line for line in lines if 'OVERALL SPEAKER DIARIZATION ERROR' in line][0]\n",
    "        return float(re.findall('\\d+\\.\\d+', derLine)[0])\n",
    "    else:\n",
    "        exit('md-eval.pl fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eer(res_filepath):\n",
    "    bin = '../eer_score.sh'\n",
    "    p = subprocess.Popen([bin, res_filepath], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output, err = p.communicate()\n",
    "    rc = p.returncode\n",
    "    if rc == 0:\n",
    "        output = output.decode(\"utf-8\")\n",
    "        return float(output)\n",
    "    else:\n",
    "        exit('eer_score.sh fail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracking_tester(recordings_segments,\n",
    "                    recordings_ids = None,\n",
    "                    scoring_function = None,\n",
    "                    groundtruth_filepath = '',\n",
    "                    groundtruth_valid_speakers_ids = ['A', 'B'],\n",
    "                    vector = 'ivectors',\n",
    "                    models_container_length = 2,\n",
    "                    models_container_include_overlaps = False,\n",
    "                    models_generation_length = 3,\n",
    "                    models_generation_selection = 'first'):\n",
    "\n",
    "    if recordings_ids is None:\n",
    "        recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "    recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "    recordings_ids.sort()\n",
    "    \n",
    "    results = {}\n",
    "    results_reduced = {}\n",
    "    results_rttm = ''\n",
    "    results_scores = {}\n",
    "    results_eer = ''\n",
    "    for recording_id in recordings_ids:\n",
    "        recording_dataset = Recordings_dataset(recordings_segments,\n",
    "                                               recording_id,\n",
    "                                               vector = vector,\n",
    "                                               models_container_length = models_container_length,\n",
    "                                               models_container_include_zeros = False,\n",
    "                                               models_container_include_overlaps = models_container_include_overlaps,\n",
    "                                               models_generation_lengths = [models_generation_length],\n",
    "                                               models_generation_selection = models_generation_selection,\n",
    "                                               balance_segments = False,\n",
    "                                               balance_segments_selection = 'copy')\n",
    "        speakers_models = recording_dataset.recordings_data[recording_id]['speakers_models']\n",
    "        speakers_ids = [speakers_ids for speakers_ids in speakers_models]\n",
    "        models_container = [speakers_models[speakers_ids][models_generation_length][0] for speakers_ids in speakers_models if models_container_include_overlaps or len(speakers_ids.split(',')) == 1]\n",
    "        for i in range(models_container_length - len(models_container)):\n",
    "            models_container.append(np.random.uniform(-0.1, 0.1, len(models_container[0])))\n",
    "        # At this point there is no information about the speaker identity, only the model\n",
    "        results[recording_id] = []\n",
    "        results_scores[recording_id] = []\n",
    "        for segment in recordings_segments[recording_id]:\n",
    "            segment_vector = np.asarray(segment[vector][0]['value'])\n",
    "            scores = scoring_function(segment_vector, models_container)\n",
    "            targets_ids = [speaker['speaker_id'] for speaker in segment['speakers']]\n",
    "            targets_ids.sort()\n",
    "            labels = ['target' if targets_ids == sorted(speaker_id.split(',')) else 'nontarget' for speaker_id in speakers_ids]\n",
    "            scores_labels = list(zip(scores, labels))\n",
    "            results_scores[recording_id].append(scores_labels)\n",
    "            index = np.argmax(scores)\n",
    "            results[recording_id].append({ 'begining': segment['begining'], 'ending': segment['ending'], 'speaker_id': index })\n",
    "            if len(results[recording_id]) > 2:\n",
    "                if results[recording_id][len(results[recording_id]) - 1]['speaker_id'] == results[recording_id][len(results[recording_id]) - 3]['speaker_id']:\n",
    "                    if results[recording_id][len(results[recording_id]) - 1]['speaker_id'] != results[recording_id][len(results[recording_id]) - 2]['speaker_id']:\n",
    "                        results[recording_id][len(results[recording_id]) - 2]['speaker_id'] = results[recording_id][len(results[recording_id]) - 1]['speaker_id']\n",
    "                        results[recording_id][len(results[recording_id]) - 1]['modified'] = True\n",
    "        results_reduced[recording_id] = []\n",
    "        last_speaker_id = -1\n",
    "        last_speaker = { 'begining': 0, 'ending': 0, 'speaker_id': -1 }\n",
    "        for segment in results[recording_id] + [{ 'begining': 0, 'ending': 0, 'speaker_id': -1 }]:\n",
    "            begining = segment['begining']\n",
    "            ending = segment['ending']\n",
    "            speaker_id = segment['speaker_id']\n",
    "            if last_speaker_id != speaker_id:\n",
    "                if last_speaker_id != -1:\n",
    "                    results_reduced[recording_id].append(last_speaker)\n",
    "                last_speaker_id = speaker_id\n",
    "                last_speaker = { 'begining': begining, 'ending': ending, 'speaker_id': speaker_id }\n",
    "            else:\n",
    "                if begining <= last_speaker['ending']:\n",
    "                    last_speaker['ending'] = ending\n",
    "                else:\n",
    "                    if last_speaker_id != -1:\n",
    "                        results_reduced[recording_id].append(last_speaker)\n",
    "                    last_speaker_id = speaker_id\n",
    "                    last_speaker = { 'begining': begining, 'ending': ending, 'speaker_id': speaker_id }\n",
    "        for scores_labels in results_scores[recording_id]:\n",
    "            for score_label in scores_labels:\n",
    "                result_eer = '{:f}'.format(score_label[0]) + ' ' + score_label[1]\n",
    "                results_eer += result_eer + '\\n'\n",
    "        for segment in results_reduced[recording_id]:\n",
    "            result_rttm = 'SPEAKER ' + recording_id + ' 0 ' + str(segment['begining']) + ' ' + str(round(segment['ending'] - segment['begining'], 2)) + ' <NA> <NA> ' + str(segment['speaker_id']) + ' <NA> <NA>'\n",
    "            results_rttm += result_rttm + '\\n'\n",
    "\n",
    "    file = open(groundtruth_filepath, 'r')\n",
    "    groundtruth_rttm = ''.join([line for line in file.readlines() if (line.split(' ')[1] in recordings_ids) and \\\n",
    "                    (line.split(' ')[7] in ['A', 'B'])])\n",
    "    file.close()\n",
    "    \n",
    "    !mkdir -p tmp\n",
    "    \n",
    "    file = open('tmp/results.eer', 'w')\n",
    "    file.write(results_eer)\n",
    "    file.close()\n",
    "    \n",
    "    file = open('tmp/groundtruth.rttm', 'w')\n",
    "    file.write(groundtruth_rttm)\n",
    "    file.close()\n",
    "    \n",
    "    file = open('tmp/results.rttm', 'w')\n",
    "    file.write(results_rttm)\n",
    "    file.close()\n",
    "\n",
    "    print(eer('notebooks/tmp/results.eer'))\n",
    "    return md_eval('tmp/groundtruth.rttm', 'tmp/results.rttm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading recordings segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_directory = '../exp/pre_norm/callhome1/json'\n",
    "b_directory = '../exp/pre_norm/callhome2/json'\n",
    "maximum_speakers_length = 2\n",
    "valid_speakers_ids = ['A', 'B']\n",
    "include_overlaps = False\n",
    "vector = 'ivectors'\n",
    "vector_length = 128\n",
    "models_container_length = 2\n",
    "models_container_include_zeros = True\n",
    "models_container_include_overlaps = False\n",
    "models_generation_length = 20\n",
    "models_generation_selection = 'first'\n",
    "balance_segments_selection = 'copy'\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../exp/pre_norm/callhome1/json loaded 249/249, 0.74 segments left.\n",
      "../exp/pre_norm/callhome2/json loaded 250/250, 0.77 segments left.\n"
     ]
    }
   ],
   "source": [
    "a_recordings_segments = load_recordings_segments(a_directory,\n",
    "                                                 lambda segment: is_valid_segment(segment, maximum_speakers_length, valid_speakers_ids))\n",
    "b_recordings_segments = load_recordings_segments(b_directory,\n",
    "                                                 lambda segment: is_valid_segment(segment, maximum_speakers_length, valid_speakers_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recordings left: 172/249\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training.7/917          \n"
     ]
    }
   ],
   "source": [
    "a_trainer = Trainer()\n",
    "a_net = a_trainer.get_net(balance_segments(a_recordings_segments, \n",
    "                                           maximum_speakers_length,\n",
    "                                           models_generation_length,\n",
    "                                           include_overlaps),\n",
    "                          vector = vector,\n",
    "                          vector_length = vector_length,\n",
    "                          models_container_length = models_container_length,\n",
    "                          models_container_include_zeros = models_container_include_zeros,\n",
    "                          models_container_include_overlaps = models_container_include_overlaps,\n",
    "                          models_generation_lengths = [models_generation_length],\n",
    "                          models_generation_selection = models_generation_selection,\n",
    "                          balance_segments_selection = balance_segments_selection,\n",
    "                          batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_selector(vector, models_container, net):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    with torch.no_grad():\n",
    "        input = [torch.Tensor([nparray]).to(device, non_blocking = True).float() for nparray in [vector] + models_container]\n",
    "        output = net(input)\n",
    "        return output.cpu().data.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../exp/pre_norm/callhome2/json loaded 250/250, 0.7 segments left.\n"
     ]
    }
   ],
   "source": [
    "b_recordings_segments = load_recordings_segments(b_directory,\n",
    "                                                 lambda segment: is_single_speaker_segment(segment, ['A', 'B']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.69"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_tester(b_recordings_segments,\n",
    "                scoring_function = lambda vector, models_container: net_selector(vector, models_container, a_net),\n",
    "                groundtruth_filepath = '../data/callhome2_1.0_0.5.rttm',\n",
    "                groundtruth_valid_speakers_ids = ['A', 'B'],\n",
    "                vector = vector,\n",
    "                models_container_length = models_container_length,\n",
    "                models_container_include_overlaps = models_container_include_overlaps,\n",
    "                models_generation_length = models_generation_length,\n",
    "                models_generation_selection = models_generation_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
