{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recordings segments loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from functools import reduce\n",
    "\n",
    "# is_single_speaker_segment [VALIDATED]\n",
    "# validates if a segment has a single speaker who belongs to the speakers list. \n",
    "def is_single_speaker_segment(segment, valid_speakers_ids = ['A', 'B']):\n",
    "    return len(segment['speakers']) == 1 and segment['speakers'][0]['speaker_id'] in valid_speakers_ids\n",
    "\n",
    "# is_valid_segment [VALIDATED]\n",
    "# validates if a segment meets a maximum number of speakers,\n",
    "# and that all the speakers in the segment belong to a list.\n",
    "def is_valid_segment(segment, maximum_speakers_length = 2, valid_speakers_ids = ['A', 'B']):\n",
    "    speakers_ids = [speaker['speaker_id'] for speaker in segment['speakers']]\n",
    "    speakers_ids = list(set(speakers_ids))\n",
    "    return len(speakers_ids) <= maximum_speakers_length and \\\n",
    "        all(speaker_id in valid_speakers_ids for speaker_id in speakers_ids)\n",
    "\n",
    "# load_recordings_segments [VALIDATED]\n",
    "# loads the recordings segments data from the .json files located in a directory \n",
    "def load_recordings_segments(directory, validation_function):\n",
    "    filenames = [filename for filename in os.listdir(directory) if os.path.isfile(os.path.join(directory, filename))]\n",
    "    filenames.sort()\n",
    "    recordings_segments = {}\n",
    "    recordings_length = len(filenames)\n",
    "    recordings_count = 0\n",
    "    segments_original = 0\n",
    "    segments_filtered = 0\n",
    "    for filename in filenames:\n",
    "        recording_id = filename.split('.')[0]\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        file = open(filepath, 'r')\n",
    "        recordings_segments[recording_id] = [json.loads(line) for line in file.readlines()]\n",
    "        file.close()\n",
    "        segments_original += len(recordings_segments[recording_id])\n",
    "        recordings_segments[recording_id] = list(filter(validation_function, recordings_segments[recording_id]))\n",
    "        segments_filtered += len(recordings_segments[recording_id])\n",
    "        recordings_count += 1\n",
    "        print(directory + ' loading ' + str(recordings_count) + '/' + str(recordings_length), end = '\\r')\n",
    "    print(directory, 'loaded', str(recordings_count) + '/' + str(recordings_length) + ',', round(segments_filtered / segments_original, 2), 'segments left.')\n",
    "    return recordings_segments\n",
    "\n",
    "# speakers_get_indexes [VALIDATED]\n",
    "# used to convert a (speakers_ids, index) list to a speakers_ids => [indexes] dictionary\n",
    "def speakers_get_indexes(accumulator, speakers_tuple):\n",
    "    speaker_ids, index = speakers_tuple\n",
    "    speaker_ids = ','.join(speaker_ids)\n",
    "    if speaker_ids in accumulator:\n",
    "        accumulator[speaker_ids].append(index)\n",
    "    else:\n",
    "        accumulator[speaker_ids] = [index]\n",
    "    return accumulator\n",
    "\n",
    "# balance_segments [VALIDATED]\n",
    "# balances the recording segments data to meet a minimum of speakers per recording,\n",
    "# and a minimum of segments per speaker.\n",
    "def balance_segments(recordings_segments,\n",
    "                     minimum_speakers_length = 2,\n",
    "                     minimum_speaker_segments = 3,\n",
    "                     include_overlaps = False):\n",
    "    new_recordings_segments = {}\n",
    "    for recording_id in recordings_segments:\n",
    "        recording_segments = recordings_segments[recording_id]\n",
    "        # ----- Obtaining speakers indexes ----- #\n",
    "        speakers_indexes = [(sorted(list(set([speaker['speaker_id'] for speaker in segment['speakers']]))), index) for index, segment in enumerate(recording_segments)]\n",
    "        speakers_indexes = reduce(speakers_get_indexes, speakers_indexes, {})\n",
    "        # ----- Removing overlaps ----- #\n",
    "        if not include_overlaps:\n",
    "            for speakers_ids in list(speakers_indexes.keys()):\n",
    "                if len(speakers_ids.split(',')) > 1:\n",
    "                    del speakers_indexes[speakers_ids]\n",
    "        speakers_lengths = [(speakers_ids, len(speakers_indexes[speakers_ids])) for speakers_ids in speakers_indexes]\n",
    "        speakers_lengths.sort(key = lambda x: x[1])\n",
    "        speakers_lengths_min = speakers_lengths[0][1]\n",
    "        if len(speakers_lengths) >= minimum_speakers_length and speakers_lengths_min >= minimum_speaker_segments:\n",
    "            recording_indexes = []\n",
    "            for speakers_ids in speakers_indexes:\n",
    "                speakers_indexes[speakers_ids] = speakers_indexes[speakers_ids][:speakers_lengths_min]\n",
    "                recording_indexes += speakers_indexes[speakers_ids]\n",
    "            new_recordings_segments[recording_id] = [segment for index, segment in enumerate(recordings_segments[recording_id]) if index in recording_indexes]\n",
    "    print('Recordings left: ' + str(len(new_recordings_segments)) + '/' + str(len(recordings_segments)))\n",
    "    return new_recordings_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recordings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def generate_speaker_model(recording_segments,\n",
    "                           speaker_indexes,\n",
    "                           segments_length,\n",
    "                           vector = 'ivectors',\n",
    "                           selection = 'first',\n",
    "                           indexes = []):\n",
    "    #if segments_length > len(speaker_indexes):\n",
    "    #    print('WARNING: there are less speaker indexes than segments.')\n",
    "    if selection == 'first':\n",
    "        selected_segments = [segment for index, segment in enumerate(recording_segments) if index in speaker_indexes[:segments_length]]\n",
    "    elif selection == 'random':\n",
    "        selected_segments = [recording_segments[index] for index in random.sample(speaker_indexes, segments_length if segments_length < len(speaker_indexes) else len(speaker_indexes))]\n",
    "    elif selection == 'indexes':\n",
    "        selected_segments = [recording_segments[index] for index in indexes]\n",
    "    else:\n",
    "        print('ERROR: unknown speaker model segments selection strategy.')\n",
    "    selected_vectors = [np.asarray(segment[vector][0]['value']) for segment in selected_segments]\n",
    "    return np.sum(selected_vectors, 0) / len(selected_vectors)\n",
    "    \n",
    "\n",
    "class Recordings_dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 recordings_segments,\n",
    "                 recordings_ids = None,\n",
    "                 vector = 'ivectors',\n",
    "                 models_container_length = 2,\n",
    "                 models_container_include_zeros = True,\n",
    "                 models_container_include_overlaps = False,\n",
    "                 models_generation_lengths = [3],\n",
    "                 models_generation_selection = 'first',\n",
    "                 balance_segments = True,\n",
    "                 balance_segments_selection = 'copy'):\n",
    "        # -----------------------------------------------------Saving input data----- #\n",
    "        if recordings_ids is None:\n",
    "            recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "        self.recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "        self.recordings_segments = {}\n",
    "        for recording_id in self.recordings_ids:\n",
    "            self.recordings_segments[recording_id] = recordings_segments[recording_id]\n",
    "        self.vector = vector\n",
    "        self.models_container_length = models_container_length\n",
    "        self.models_container_include_zeros = models_container_include_zeros\n",
    "        self.models_container_include_overlaps = models_container_include_overlaps\n",
    "        self.models_generation_lengths = models_generation_lengths\n",
    "        self.models_generation_selection = models_generation_selection\n",
    "        self.balance_segments = balance_segments\n",
    "        self.balance_segments_selection = balance_segments_selection\n",
    "        # --------------------------------------------------------------------------- #\n",
    "        self.recordings_data = {}\n",
    "        # -------------------------------------------------- #\n",
    "        self.recordings_map = []\n",
    "        self.recordings_length = 0\n",
    "        for recording_id in self.recordings_ids:\n",
    "            self.recordings_data[recording_id] = {}\n",
    "            recording_segments = self.recordings_segments[recording_id]\n",
    "            recording_data = self.recordings_data[recording_id]\n",
    "            # ----- Obtaining speakers indexes ----- #\n",
    "            recording_data['speakers_indexes'] = [(sorted(list(set([speaker['speaker_id'] for speaker in segment['speakers']]))), index) for index, segment in enumerate(recording_segments)]\n",
    "            recording_data['speakers_indexes'] = reduce(speakers_get_indexes, recording_data['speakers_indexes'], {})\n",
    "            # ----- Balancing speakers segments ----- #\n",
    "            recording_data['speakers_indexes_lengths_max'] = max([len(recording_data['speakers_indexes'][speakers_ids]) for speakers_ids in recording_data['speakers_indexes']])\n",
    "            if self.balance_segments:\n",
    "                if self.balance_segments_selection == 'copy':\n",
    "                    for speakers_ids in recording_data['speakers_indexes']:\n",
    "                        for i in range(recording_data['speakers_indexes_lengths_max'] - len(recording_data['speakers_indexes'][speakers_ids])):\n",
    "                            index = random.choice(recording_data['speakers_indexes'][speakers_ids])\n",
    "                            recording_segments.append(recording_segments[index])\n",
    "                            recording_data['speakers_indexes'][speakers_ids].append(len(recording_segments) - 1)\n",
    "                else:\n",
    "                    print('ERROR: unknown balancing segments selection strategy.')\n",
    "            # ----- Generating speakers models ----- #\n",
    "            recording_data['speakers_models'] = {}\n",
    "            for speakers_ids in recording_data['speakers_indexes']:\n",
    "                recording_data['speakers_models'][speakers_ids] = {}\n",
    "                for models_generation_length in models_generation_lengths:\n",
    "                    speakers_model = generate_speaker_model(recording_segments, recording_data['speakers_indexes'][speakers_ids], models_generation_length, self.vector, self.models_generation_selection)\n",
    "                    recording_data['speakers_models'][speakers_ids][models_generation_length] = [speakers_model]\n",
    "            # ----- Generating permutations ----- #\n",
    "            if self.models_container_include_zeros:\n",
    "                recording_data['permutations'] = list(itertools.permutations(list(recording_data['speakers_models'].keys()) \\\n",
    "                + ['0' for i in range(self.models_container_length)], self.models_container_length))\n",
    "            else:\n",
    "                recording_data['permutations'] = list(itertools.permutations(list(recording_data['speakers_models'].keys()), self.models_container_length))\n",
    "            recording_data['permutations'] = list(set(recording_data['permutations']))\n",
    "            recording_data['permutations'].sort()\n",
    "            if not self.models_container_include_overlaps:\n",
    "                recording_data['permutations'] = [permutation for permutation in recording_data['permutations'] if all(len(speakers_ids.split(',')) == 1 for speakers_ids in permutation)]\n",
    "            # -------------------------------------------------- #\n",
    "            recording_data['permutations_map'] = []\n",
    "            recording_data['permutations_length'] = 0\n",
    "            for index, permutation in enumerate(recording_data['permutations']):\n",
    "                speakers_models_length = int(np.prod([np.sum([len(recording_data['speakers_models'][speakers_ids][models_generation_length]) for models_generation_length in recording_data['speakers_models'][speakers_ids]]) for speakers_ids in permutation if speakers_ids != '0']))\n",
    "                recording_data['permutations_map'].append((recording_data['permutations_length'], recording_data['permutations_length'] + speakers_models_length - 1, index))\n",
    "                recording_data['permutations_length'] += speakers_models_length\n",
    "            recording_data['length'] = len(recording_segments) * recording_data['permutations_length']\n",
    "            self.recordings_map.append((self.recordings_length, self.recordings_length + recording_data['length'] - 1, recording_id))\n",
    "            self.recordings_length += recording_data['length']\n",
    "    def __len__(self):\n",
    "        return self.recordings_length\n",
    "    def __getitem__(self, idx):\n",
    "        recording_limits = list(filter(lambda recording_limits: recording_limits[0] <= idx and idx <= recording_limits[1], self.recordings_map))[0]\n",
    "        recording_idx = idx - recording_limits[0]\n",
    "        recording_id = recording_limits[2]\n",
    "        recording_data = self.recordings_data[recording_id]\n",
    "        \n",
    "        segment_index, segment_idx = divmod(recording_idx, recording_data['permutations_length'])\n",
    "        segment = self.recordings_segments[recording_id][segment_index]\n",
    "        vector = np.asarray(segment[self.vector][0]['value'])\n",
    "        \n",
    "        permutation_limits = list(filter(lambda permutation_limits: permutation_limits[0] <= segment_idx and segment_idx <= permutation_limits[1], recording_data['permutations_map']))[0]\n",
    "        permutation_idx = segment_idx - permutation_limits[0]\n",
    "        permutation_index = permutation_limits[2]\n",
    "        permutation = recording_data['permutations'][permutation_index]\n",
    "        \n",
    "        speakers_models_lengths = [np.sum([len(recording_data['speakers_models'][speakers_ids][models_generation_length]) for models_generation_length in recording_data['speakers_models'][speakers_ids]])  if speakers_ids != '0' else 1 for speakers_ids in permutation]\n",
    "        models_container = []\n",
    "        model_index = permutation_idx\n",
    "        for i, length_i in enumerate(speakers_models_lengths):\n",
    "            if i != len(speakers_models_lengths) - 1:\n",
    "                model_index, remainder = divmod(model_index, np.sum(speakers_models_lengths[i + 1:]))\n",
    "            else:\n",
    "                model_index = remainder\n",
    "            models_container.append(recording_data['speakers_models'][permutation[i]][self.models_generation_lengths[model_index]][0] if permutation[i] != '0' else np.random.uniform(-0.1, 0.1, len(vector)))\n",
    "        \n",
    "        models_weigths = np.asarray([len(recording_data['speakers_indexes'][speakers_ids]) if speakers_ids != '0' else recording_data['speakers_indexes_lengths_max'] for speakers_ids in permutation])\n",
    "        models_weigths_sum = np.sum(models_weigths)\n",
    "        models_weigths = np.ones(len(models_weigths)) - models_weigths / models_weigths_sum\n",
    "        \n",
    "        targets_ids = [speaker['speaker_id'] for speaker in segment['speakers']]\n",
    "        \n",
    "        x = [vector] + models_container\n",
    "        if self.models_container_include_overlaps:\n",
    "            targets_ids = ','.join(sorted(list(set(targets_ids))))\n",
    "            y = np.asarray([speakers_ids == targets_ids for speakers_ids in permutation], dtype = float)\n",
    "        else:\n",
    "            y = np.asarray([speaker_id in targets_ids for speaker_id in permutation], dtype = float) / len(targets_ids)\n",
    "        z = models_weigths\n",
    "        \n",
    "        return x, y, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load live_graph.py\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Live_graph:\n",
    "    def __init__(self, validation_threshold):\n",
    "        self.plt_count = -1\n",
    "        self.validation_threshold = validation_threshold\n",
    "        self.plt_thr = ([self.plt_count], [self.validation_threshold])\n",
    "        self.plt_loss = ([self.plt_count], [1])\n",
    "        self.plt_valid = ([self.plt_count], [1])\n",
    "        self.plt_test = ([self.plt_count], [1])\n",
    "        self.fig = plt.figure()\n",
    "        self.ax = self.fig.add_subplot()\n",
    "        self.line0, = self.ax.plot(self.plt_thr[0], self.plt_thr[1], 'k--', label = 'Threshold') # Threshold line\n",
    "        self.line1, = self.ax.plot(self.plt_loss[0], self.plt_loss[1], '--', label = 'Training') # Training loss\n",
    "        self.line2, = self.ax.plot(self.plt_valid[0], self.plt_valid[1], label = 'Validation')   # Validation loss\n",
    "        self.line3, = self.ax.plot(self.plt_test[0], self.plt_test[1], label = 'Test')           # Test loss\n",
    "        self.ax.set_xlabel('Epoch')\n",
    "        self.ax.set_ylabel('Loss')\n",
    "        self.ax.legend()\n",
    "        self.ax.set_xlim(-1, 0)\n",
    "        self.ax.set_ylim(0, 0.5)\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.canvas.flush_events()\n",
    "    def step(self, training, validation, test = -1):\n",
    "        self.plt_count += 1\n",
    "        self.plt_thr[0].append(self.plt_count)\n",
    "        self.plt_thr[1].append(self.validation_threshold)\n",
    "        self.plt_loss[0].append(self.plt_count)\n",
    "        self.plt_loss[1].append(training)\n",
    "        self.plt_valid[0].append(self.plt_count)\n",
    "        self.plt_valid[1].append(validation)\n",
    "        self.plt_test[0].append(self.plt_count)\n",
    "        self.plt_test[1].append(test)\n",
    "        self.line0.set_xdata(self.plt_thr[0])\n",
    "        self.line0.set_ydata(self.plt_thr[1])\n",
    "        self.line1.set_xdata(self.plt_loss[0])\n",
    "        self.line1.set_ydata(self.plt_loss[1])\n",
    "        self.line2.set_xdata(self.plt_valid[0])\n",
    "        self.line2.set_ydata(self.plt_valid[1])\n",
    "        self.line3.set_xdata(self.plt_test[0])\n",
    "        self.line3.set_ydata(self.plt_test[1])\n",
    "        self.ax.set_xlim(0, self.plt_count + 1)\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.canvas.flush_events()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, models_container_length, vector_length):\n",
    "        super().__init__()\n",
    "        n = models_container_length\n",
    "        m = vector_length\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv1d((n + 1), n ** 3, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(n ** 3, n ** 2, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(n ** 2, n, 3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(n * (m - 6), n * 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n * 16, n * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n * 4, n),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = torch.stack(input, 1)\n",
    "        x = self.cnn1(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self):\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device('cuda:0')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "    def get_net(self,\n",
    "                recordings_segments,\n",
    "                recordings_ids = None,\n",
    "                vector = 'ivectors',\n",
    "                vector_length = 128,\n",
    "                models_container_length = 2,\n",
    "                models_container_include_zeros = True,\n",
    "                models_container_include_overlaps = False,\n",
    "                models_generation_lengths = [3],\n",
    "                models_generation_selection = 'first',\n",
    "                balance_segments = True,\n",
    "                balance_segments_selection = 'copy',\n",
    "                batch_size = 16,\n",
    "                num_workers = 8,\n",
    "                test_recordings_segments = None):\n",
    "        \n",
    "        if recordings_ids is None:\n",
    "            recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "        self.recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "\n",
    "        train_dataset = Recordings_dataset(recordings_segments,\n",
    "                                           recordings_ids, \n",
    "                                           vector,\n",
    "                                           models_container_length,\n",
    "                                           models_container_include_zeros,\n",
    "                                           models_container_include_overlaps,\n",
    "                                           models_generation_lengths,\n",
    "                                           models_generation_selection,\n",
    "                                           balance_segments,\n",
    "                                           balance_segments_selection)\n",
    "\n",
    "        train_length = int(len(train_dataset) * 0.7)\n",
    "        valid_length = len(train_dataset) - train_length\n",
    "\n",
    "        train_dataset, valid_dataset = random_split(train_dataset, [train_length, valid_length])\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers = num_workers)\n",
    "        valid_dataloader = DataLoader(valid_dataset, batch_size = batch_size, num_workers = num_workers)\n",
    "        \n",
    "        if test_recordings_segments is not None:\n",
    "            test_recordings_ids = [recording_id for recording_id in test_recordings_segments]\n",
    "            test_dataset = Recordings_dataset(test_recordings_segments,\n",
    "                                              test_recordings_ids,\n",
    "                                              vector,\n",
    "                                              models_container_length,\n",
    "                                              models_container_include_zeros,\n",
    "                                              models_container_include_overlaps,\n",
    "                                              models_generation_lengths,\n",
    "                                              models_generation_selection,\n",
    "                                              balance_segments,\n",
    "                                              balance_segments_selection)\n",
    "            test_dataloader = DataLoader(test_dataset, batch_size = batch_size, num_workers = num_workers)\n",
    "\n",
    "        net = Net(models_container_length, vector_length).to(self.device)\n",
    "        optimizer = optim.Adam(net.parameters(), lr = 0.0001)\n",
    "\n",
    "        epochs = 30\n",
    "        validation_threshold = 0.07\n",
    "\n",
    "        live_graph = Live_graph(validation_threshold)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_losses = []\n",
    "            for input, target, weigth in train_dataloader:\n",
    "                input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                target = target.to(self.device, non_blocking = True).float()\n",
    "                weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                criterion = nn.BCELoss(weigth)\n",
    "                net.zero_grad()\n",
    "                output = net(input)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_losses.append(loss.data)\n",
    "                print('train: ' + str(len(train_losses)) + '/' + str(len(train_dataloader)) + '          ', end = '\\r')\n",
    "            train_loss = np.sum(train_losses) / len(train_losses)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                validation_losses = []\n",
    "                for input, target, weigth in valid_dataloader:\n",
    "                    input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                    target = target.to(self.device, non_blocking = True).float()\n",
    "                    weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                    criterion = nn.BCELoss(weigth)\n",
    "                    output = net(input)\n",
    "                    loss = criterion(output, target)\n",
    "                    validation_losses.append(loss.data)\n",
    "                    print('validation: ' + str(len(validation_losses)) + '/' + str(len(valid_dataloader)) + '          ', end = '\\r')\n",
    "                validation_loss = np.sum(validation_losses) / len(validation_losses)\n",
    "                \n",
    "                test_loss = -1\n",
    "                if test_recordings_segments is not None:\n",
    "                    test_losses = []\n",
    "                    for input, target, weigth in test_dataloader:\n",
    "                        input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                        target = target.to(self.device, non_blocking = True).float()\n",
    "                        weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                        criterion = nn.BCELoss(weigth)\n",
    "                        output = net(input)\n",
    "                        loss = criterion(output, target)\n",
    "                        test_losses.append(loss.data)\n",
    "                        print('test: ' + str(len(test_losses)) + '/' + str(len(test_dataloader)) + '          ', end = '\\r')\n",
    "                    test_loss = np.sum(test_losses) / len(test_losses)\n",
    "\n",
    "            live_graph.step(train_loss, validation_loss, test_loss)\n",
    "\n",
    "            if validation_loss <= validation_threshold:\n",
    "                print('Done training.')\n",
    "                break\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load md_eval.py\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "def md_eval(ref_filepath, res_filepath, save_filepath = None):\n",
    "    bin = '../../../../tools/sctk-2.4.10/src/md-eval/md-eval.pl'\n",
    "    p = subprocess.Popen([bin, '-r', ref_filepath, '-s', res_filepath], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output, err = p.communicate()\n",
    "    rc = p.returncode\n",
    "    if rc == 0:\n",
    "        output = output.decode(\"utf-8\")\n",
    "        if save_filepath is not None:\n",
    "            file = open(save_filepath, 'w')\n",
    "            file.write(output)\n",
    "            file.close()\n",
    "        lines =  output.split('\\n')\n",
    "        derLine = [line for line in lines if 'OVERALL SPEAKER DIARIZATION ERROR' in line][0]\n",
    "        return float(re.findall('\\d+\\.\\d+', derLine)[0])\n",
    "    else:\n",
    "        exit('md-eval.pl fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eer(res_filepath):\n",
    "    bin = '../eer_score.sh'\n",
    "    p = subprocess.Popen([bin, res_filepath], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output, err = p.communicate()\n",
    "    rc = p.returncode\n",
    "    if rc == 0:\n",
    "        output = output.decode(\"utf-8\")\n",
    "        return float(output)\n",
    "    else:\n",
    "        exit('eer_score.sh fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcf(scores_filepath, trials_filepath):\n",
    "    bin = '../sid/compute_min_dcf.py'\n",
    "    p = subprocess.Popen([bin, scores_filepath, trials_filepath], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output, err = p.communicate()\n",
    "    rc = p.returncode\n",
    "    if rc == 0:\n",
    "        output = output.decode(\"utf-8\")\n",
    "        return float(output)\n",
    "    else:\n",
    "        exit('compute_min_dcf.py fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plda_score(ref_vector, test_vector, plda_filepath):\n",
    "    ref_string = str(list(ref_vector)).replace(',', '').replace('[', '[ ').replace(']', ' ]')\n",
    "    test_string = str(list(test_vector)).replace(',', '').replace('[', '[ ').replace(']', ' ]')\n",
    "\n",
    "    bin = '../plda_score.sh'\n",
    "    p = subprocess.Popen([bin, plda_filepath, ref_string, test_string], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output, err = p.communicate()\n",
    "    rc = p.returncode\n",
    "    if rc == 0:\n",
    "        lines =  output.decode(\"utf-8\").split('\\n')\n",
    "        pldaLine = [line for line in lines if 'reference test' in line][0]\n",
    "        return float(re.findall('\\d+\\.\\d+', pldaLine)[0])\n",
    "    else:\n",
    "        print(err)\n",
    "        exit('plda_socre.sh fail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracking_tester(recordings_segments,\n",
    "                    recordings_ids = None,\n",
    "                    scoring_function = None,\n",
    "                    groundtruth_filepath = '',\n",
    "                    groundtruth_valid_speakers_ids = ['A', 'B'],\n",
    "                    vector = 'ivectors',\n",
    "                    models_container_length = 2,\n",
    "                    models_container_include_overlaps = False,\n",
    "                    models_generation_length = 3,\n",
    "                    models_generation_selection = 'first'):\n",
    "\n",
    "    if recordings_ids is None:\n",
    "        recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "    recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "    recordings_ids.sort()\n",
    "    \n",
    "    results = {}\n",
    "    results_reduced = {}\n",
    "    results_rttm = ''\n",
    "    results_scores = {}\n",
    "    eer_scores = ''\n",
    "    dcf_scores = ''\n",
    "    dcf_trials = ''\n",
    "    for recording_id in recordings_ids:\n",
    "        recording_dataset = Recordings_dataset(recordings_segments,\n",
    "                                               recording_id,\n",
    "                                               vector = vector,\n",
    "                                               models_container_length = models_container_length,\n",
    "                                               models_container_include_zeros = False,\n",
    "                                               models_container_include_overlaps = models_container_include_overlaps,\n",
    "                                               models_generation_lengths = [models_generation_length],\n",
    "                                               models_generation_selection = models_generation_selection,\n",
    "                                               balance_segments = False,\n",
    "                                               balance_segments_selection = 'copy')\n",
    "        speakers_models = recording_dataset.recordings_data[recording_id]['speakers_models']\n",
    "        speakers_ids = [speakers_ids for speakers_ids in speakers_models]\n",
    "        models_container = [speakers_models[speakers_ids][models_generation_length][0] for speakers_ids in speakers_models if models_container_include_overlaps or len(speakers_ids.split(',')) == 1]\n",
    "        for i in range(models_container_length - len(models_container)):\n",
    "            models_container.append(np.random.uniform(-0.1, 0.1, len(models_container[0])))\n",
    "        # At this point there is no information about the speaker identity, only the model\n",
    "        results[recording_id] = []\n",
    "        results_scores[recording_id] = []\n",
    "        for segment in recordings_segments[recording_id]:\n",
    "            segment_vector = np.asarray(segment[vector][0]['value'])\n",
    "            segment_vector_id = segment[vector][0]['ivector_id' if vector == 'ivectors' else 'xvector_id']\n",
    "            \n",
    "            scores = scoring_function(segment_vector, models_container)\n",
    "            \n",
    "            targets_ids = [speaker['speaker_id'] for speaker in segment['speakers']]\n",
    "            targets_ids.sort()\n",
    "            labels = ['target' if targets_ids == sorted(speaker_id.split(',')) else 'nontarget' for speaker_id in speakers_ids]\n",
    "            \n",
    "            utterances = [recording_id + '_' + speaker_id for speaker_id in speakers_ids]\n",
    "            \n",
    "            # utt1, utt2, score, target/nontarget\n",
    "            scores_labels = list(zip([segment_vector_id for speaker_id in speakers_ids], utterances, labels, scores))\n",
    "            results_scores[recording_id].append(scores_labels)\n",
    "            \n",
    "            index = np.argmax(scores)\n",
    "            results[recording_id].append({ 'begining': segment['begining'], 'ending': segment['ending'], 'speaker_id': index })\n",
    "            if len(results[recording_id]) > 2:\n",
    "                if results[recording_id][len(results[recording_id]) - 1]['speaker_id'] == results[recording_id][len(results[recording_id]) - 3]['speaker_id']:\n",
    "                    if results[recording_id][len(results[recording_id]) - 1]['speaker_id'] != results[recording_id][len(results[recording_id]) - 2]['speaker_id']:\n",
    "                        results[recording_id][len(results[recording_id]) - 2]['speaker_id'] = results[recording_id][len(results[recording_id]) - 1]['speaker_id']\n",
    "                        results[recording_id][len(results[recording_id]) - 1]['modified'] = True\n",
    "        results_reduced[recording_id] = []\n",
    "        last_speaker_id = -1\n",
    "        last_speaker = { 'begining': 0, 'ending': 0, 'speaker_id': -1 }\n",
    "        for segment in results[recording_id] + [{ 'begining': 0, 'ending': 0, 'speaker_id': -1 }]:\n",
    "            begining = segment['begining']\n",
    "            ending = segment['ending']\n",
    "            speaker_id = segment['speaker_id']\n",
    "            if last_speaker_id != speaker_id:\n",
    "                if last_speaker_id != -1:\n",
    "                    results_reduced[recording_id].append(last_speaker)\n",
    "                last_speaker_id = speaker_id\n",
    "                last_speaker = { 'begining': begining, 'ending': ending, 'speaker_id': speaker_id }\n",
    "            else:\n",
    "                if begining <= last_speaker['ending']:\n",
    "                    last_speaker['ending'] = ending\n",
    "                else:\n",
    "                    if last_speaker_id != -1:\n",
    "                        results_reduced[recording_id].append(last_speaker)\n",
    "                    last_speaker_id = speaker_id\n",
    "                    last_speaker = { 'begining': begining, 'ending': ending, 'speaker_id': speaker_id }\n",
    "        for scores_labels in results_scores[recording_id]:\n",
    "            for score_label in scores_labels:\n",
    "                # ('iaab_000-00000000-00000099', 'iaab_B', 'target', 0.9978078)\n",
    "                eer_score = '{:f}'.format(score_label[3]) + ' ' + score_label[2]\n",
    "                eer_scores += eer_score + '\\n'\n",
    "                dcf_score = score_label[0] + ' ' + score_label[1] + ' ' + '{:f}'.format(score_label[3])\n",
    "                dcf_scores += dcf_score + '\\n'\n",
    "                dcf_trial = score_label[0] + ' ' + score_label[1] + ' '+ score_label[2]\n",
    "                dcf_trials += dcf_trial + '\\n'\n",
    "        for segment in results_reduced[recording_id]:\n",
    "            result_rttm = 'SPEAKER ' + recording_id + ' 0 ' + str(segment['begining']) + ' ' + str(round(segment['ending'] - segment['begining'], 2)) + ' <NA> <NA> ' + str(segment['speaker_id']) + ' <NA> <NA>'\n",
    "            results_rttm += result_rttm + '\\n'\n",
    "\n",
    "    file = open(groundtruth_filepath, 'r')\n",
    "    groundtruth_rttm = ''.join([line for line in file.readlines() if (line.split(' ')[1] in recordings_ids) and \\\n",
    "                    (line.split(' ')[7] in ['A', 'B'])])\n",
    "    file.close()\n",
    "    \n",
    "    !mkdir -p tmp\n",
    "    \n",
    "    file = open('tmp/eer.scores', 'w')\n",
    "    file.write(eer_scores)\n",
    "    file.close()\n",
    "    \n",
    "    file = open('tmp/dcf.scores', 'w')\n",
    "    file.write(dcf_scores)\n",
    "    file.close()\n",
    "    \n",
    "    file = open('tmp/dcf.trials', 'w')\n",
    "    file.write(dcf_trials)\n",
    "    file.close()\n",
    "    \n",
    "    file = open('tmp/groundtruth.rttm', 'w')\n",
    "    file.write(groundtruth_rttm)\n",
    "    file.close()\n",
    "    \n",
    "    file = open('tmp/results.rttm', 'w')\n",
    "    file.write(results_rttm)\n",
    "    file.close()\n",
    "\n",
    "    print('eer:', eer('notebooks/tmp/eer.scores'))\n",
    "    print('dcf:', dcf('tmp/dcf.scores', 'tmp/dcf.trials'))\n",
    "    return md_eval('tmp/groundtruth.rttm', 'tmp/results.rttm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading recordings segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_directory = '../exp/pre_norm/callhome1/json'\n",
    "b_directory = '../exp/pre_norm/callhome2/json'\n",
    "maximum_speakers_length = 2\n",
    "valid_speakers_ids = ['A', 'B']\n",
    "include_overlaps = False\n",
    "vector = 'ivectors'\n",
    "vector_length = 128\n",
    "models_container_length = 2\n",
    "models_container_include_zeros = True\n",
    "models_container_include_overlaps = False\n",
    "models_generation_length = 3\n",
    "models_generation_selection = 'first'\n",
    "balance_segments_selection = 'copy'\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../exp/pre_norm/callhome1/json loaded 249/249, 0.74 segments left.\n",
      "../exp/pre_norm/callhome2/json loaded 250/250, 0.77 segments left.\n"
     ]
    }
   ],
   "source": [
    "a_recordings_segments = load_recordings_segments(a_directory,\n",
    "                                                 lambda segment: is_valid_segment(segment, maximum_speakers_length, valid_speakers_ids))\n",
    "b_recordings_segments = load_recordings_segments(b_directory,\n",
    "                                                 lambda segment: is_valid_segment(segment, maximum_speakers_length, valid_speakers_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recordings left: 246/249\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training.29/1029          \n"
     ]
    }
   ],
   "source": [
    "a_trainer = Trainer()\n",
    "a_net = a_trainer.get_net(balance_segments(a_recordings_segments, \n",
    "                                           maximum_speakers_length,\n",
    "                                           models_generation_length,\n",
    "                                           include_overlaps),\n",
    "                          vector = vector,\n",
    "                          vector_length = vector_length,\n",
    "                          models_container_length = models_container_length,\n",
    "                          models_container_include_zeros = models_container_include_zeros,\n",
    "                          models_container_include_overlaps = models_container_include_overlaps,\n",
    "                          models_generation_lengths = [models_generation_length],\n",
    "                          models_generation_selection = models_generation_selection,\n",
    "                          balance_segments_selection = balance_segments_selection,\n",
    "                          batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_selector(vector, models_container, net):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    with torch.no_grad():\n",
    "        input = [torch.Tensor([nparray]).to(device, non_blocking = True).float() for nparray in [vector] + models_container]\n",
    "        output = net(input)\n",
    "        return output.cpu().data.numpy()[0]\n",
    "    \n",
    "def plda_selector(vector, models_container, plda_filepath):\n",
    "    return [plda_score(ref_vector, vector, plda_filepath) for ref_vector in models_container]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../exp/pre_norm/callhome2/json loaded 250/250, 0.7 segments left.\n"
     ]
    }
   ],
   "source": [
    "b_recordings_segments = load_recordings_segments(b_directory,\n",
    "                                                 lambda segment: is_single_speaker_segment(segment, ['A', 'B']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eer: 6.947\n",
      "dcf: 0.5991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.04"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_tester(b_recordings_segments,\n",
    "                scoring_function = lambda vector, models_container: net_selector(vector, models_container, a_net),\n",
    "                groundtruth_filepath = '../data/callhome2_1.0_0.5.rttm',\n",
    "                groundtruth_valid_speakers_ids = ['A', 'B'],\n",
    "                vector = vector,\n",
    "                models_container_length = models_container_length,\n",
    "                models_container_include_overlaps = models_container_include_overlaps,\n",
    "                models_generation_length = models_generation_length,\n",
    "                models_generation_selection = models_generation_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eer: 19.27\n",
      "dcf: 0.9228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_tester(b_recordings_segments,\n",
    "                scoring_function = lambda vector, models_container: plda_selector(vector,\n",
    "                                                                                  models_container,\n",
    "                                                                                  'exp/plda/callhome1/ivectors.plda'),\n",
    "                groundtruth_filepath = '../data/callhome2_1.0_0.5.rttm',\n",
    "                groundtruth_valid_speakers_ids = ['A', 'B'],\n",
    "                vector = vector,\n",
    "                models_container_length = models_container_length,\n",
    "                models_container_include_overlaps = models_container_include_overlaps,\n",
    "                models_generation_length = models_generation_length,\n",
    "                models_generation_selection = models_generation_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
