{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recordings segments loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from functools import reduce\n",
    "\n",
    "# is_single_speaker_segment [VALIDATED]\n",
    "# validates if a segment has a single speaker who belongs to the speakers list. \n",
    "def is_single_speaker_segment(segment, valid_speakers_ids = ['A', 'B']):\n",
    "    return len(segment['speakers']) == 1 and segment['speakers'][0]['speaker_id'] in valid_speakers_ids\n",
    "\n",
    "# is_valid_segment [VALIDATED]\n",
    "# validates if a segment meets a maximum number of speakers,\n",
    "# and that all the speakers in the segment belong to a list.\n",
    "def is_valid_segment(segment, maximum_speakers_length = 2, valid_speakers_ids = ['A', 'B']):\n",
    "    speakers_ids = [speaker['speaker_id'] for speaker in segment['speakers']]\n",
    "    speakers_ids = list(set(speakers_ids))\n",
    "    return len(speakers_ids) <= maximum_speakers_length and \\\n",
    "        all(speaker_id in valid_speakers_ids for speaker_id in speakers_ids)\n",
    "\n",
    "# load_recordings_segments [VALIDATED]\n",
    "# loads the recordings segments data from the .json files located in a directory \n",
    "def load_recordings_segments(directory, validation_function):\n",
    "    filenames = [filename for filename in os.listdir(directory) if os.path.isfile(os.path.join(directory, filename))]\n",
    "    filenames.sort()\n",
    "    recordings_segments = {}\n",
    "    recordings_length = len(filenames)\n",
    "    recordings_count = 0\n",
    "    segments_original = 0\n",
    "    segments_filtered = 0\n",
    "    for filename in filenames:\n",
    "        recording_id = filename.split('.')[0]\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        file = open(filepath, 'r')\n",
    "        recordings_segments[recording_id] = [json.loads(line) for line in file.readlines()]\n",
    "        file.close()\n",
    "        segments_original += len(recordings_segments[recording_id])\n",
    "        recordings_segments[recording_id] = list(filter(validation_function, recordings_segments[recording_id]))\n",
    "        segments_filtered += len(recordings_segments[recording_id])\n",
    "        recordings_count += 1\n",
    "        print(directory + ' loading ' + str(recordings_count) + '/' + str(recordings_length), end = '\\r')\n",
    "    print(directory, 'loaded', str(recordings_count) + '/' + str(recordings_length) + ',', round(segments_filtered / segments_original, 2), 'segments left.')\n",
    "    return recordings_segments\n",
    "\n",
    "# speakers_get_indexes [VALIDATED]\n",
    "# used to convert a (speakers_ids, index) list to a speakers_ids => [indexes] dictionary\n",
    "def speakers_get_indexes(accumulator, speakers_tuple):\n",
    "    speaker_ids, index = speakers_tuple\n",
    "    speaker_ids = ','.join(speaker_ids)\n",
    "    if speaker_ids in accumulator:\n",
    "        accumulator[speaker_ids].append(index)\n",
    "    else:\n",
    "        accumulator[speaker_ids] = [index]\n",
    "    return accumulator\n",
    "\n",
    "# balance_segments [VALIDATED]\n",
    "# balances the recording segments data to meet a minimum of speakers per recording,\n",
    "# and a minimum of segments per speaker.\n",
    "def balance_segments(recordings_segments,\n",
    "                     minimum_speakers_length = 2,\n",
    "                     minimum_speaker_segments = 3,\n",
    "                     include_overlaps = False):\n",
    "    new_recordings_segments = {}\n",
    "    for recording_id in recordings_segments:\n",
    "        recording_segments = recordings_segments[recording_id]\n",
    "        # ----- Obtaining speakers indexes ----- #\n",
    "        speakers_indexes = [(sorted(list(set([speaker['speaker_id'] for speaker in segment['speakers']]))), index) for index, segment in enumerate(recording_segments)]\n",
    "        speakers_indexes = reduce(speakers_get_indexes, speakers_indexes, {})\n",
    "        # ----- Removing overlaps ----- #\n",
    "        if not include_overlaps:\n",
    "            for speakers_ids in list(speakers_indexes.keys()):\n",
    "                if len(speakers_ids.split(',')) > 1:\n",
    "                    del speakers_indexes[speakers_ids]\n",
    "        speakers_lengths = [(speakers_ids, len(speakers_indexes[speakers_ids])) for speakers_ids in speakers_indexes]\n",
    "        speakers_lengths.sort(key = lambda x: x[1])\n",
    "        speakers_lengths_min = speakers_lengths[0][1]\n",
    "        if len(speakers_lengths) >= minimum_speakers_length and speakers_lengths_min >= minimum_speaker_segments:\n",
    "            recording_indexes = []\n",
    "            for speakers_ids in speakers_indexes:\n",
    "                speakers_indexes[speakers_ids] = speakers_indexes[speakers_ids][:speakers_lengths_min]\n",
    "                recording_indexes += speakers_indexes[speakers_ids]\n",
    "            new_recordings_segments[recording_id] = [segment for index, segment in enumerate(recordings_segments[recording_id]) if index in recording_indexes]\n",
    "    print('Recordings left: ' + str(len(new_recordings_segments)) + '/' + str(len(recordings_segments)))\n",
    "    return new_recordings_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recordings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def generate_speaker_model(recording_segments,\n",
    "                           speaker_indexes,\n",
    "                           segments_length,\n",
    "                           vector = 'ivectors',\n",
    "                           selection = 'first',\n",
    "                           indexes = []):\n",
    "    #if segments_length > len(speaker_indexes):\n",
    "    #    print('WARNING: there are less speaker indexes than segments.')\n",
    "    if selection == 'first':\n",
    "        selected_segments = [segment for index, segment in enumerate(recording_segments) if index in speaker_indexes[:segments_length]]\n",
    "    elif selection == 'random':\n",
    "        selected_segments = [recording_segments[index] for index in random.sample(speaker_indexes, segments_length if segments_length < len(speaker_indexes) else len(speaker_indexes))]\n",
    "    elif selection == 'indexes':\n",
    "        selected_segments = [recording_segments[index] for index in indexes]\n",
    "    else:\n",
    "        print('ERROR: unknown speaker model segments selection strategy.')\n",
    "    selected_vectors = [np.asarray(segment[vector][0]['value']) for segment in selected_segments]\n",
    "    return np.sum(selected_vectors, 0) / len(selected_vectors)\n",
    "    \n",
    "\n",
    "class Recordings_dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 recordings_segments,\n",
    "                 recordings_ids = None,\n",
    "                 vector = 'ivectors',\n",
    "                 models_container_length = 2,\n",
    "                 models_container_include_zeros = True,\n",
    "                 models_container_include_overlaps = False,\n",
    "                 models_generation_lengths = [3],\n",
    "                 models_generation_selection = 'first',\n",
    "                 balance_segments = True,\n",
    "                 balance_segments_selection = 'copy'):\n",
    "        # -----------------------------------------------------Saving input data----- #\n",
    "        if recordings_ids is None:\n",
    "            recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "        self.recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "        self.recordings_segments = {}\n",
    "        for recording_id in self.recordings_ids:\n",
    "            self.recordings_segments[recording_id] = recordings_segments[recording_id]\n",
    "        self.vector = vector\n",
    "        self.models_container_length = models_container_length\n",
    "        self.models_container_include_zeros = models_container_include_zeros\n",
    "        self.models_container_include_overlaps = models_container_include_overlaps\n",
    "        self.models_generation_lengths = models_generation_lengths\n",
    "        self.models_generation_selection = models_generation_selection\n",
    "        self.balance_segments = balance_segments\n",
    "        self.balance_segments_selection = balance_segments_selection\n",
    "        # --------------------------------------------------------------------------- #\n",
    "        self.recordings_data = {}\n",
    "        # -------------------------------------------------- #\n",
    "        self.recordings_map = []\n",
    "        self.recordings_length = 0\n",
    "        for recording_id in self.recordings_ids:\n",
    "            self.recordings_data[recording_id] = {}\n",
    "            recording_segments = self.recordings_segments[recording_id]\n",
    "            recording_data = self.recordings_data[recording_id]\n",
    "            # ----- Obtaining speakers indexes ----- #\n",
    "            recording_data['speakers_indexes'] = [(sorted(list(set([speaker['speaker_id'] for speaker in segment['speakers']]))), index) for index, segment in enumerate(recording_segments)]\n",
    "            recording_data['speakers_indexes'] = reduce(speakers_get_indexes, recording_data['speakers_indexes'], {})\n",
    "            # ----- Balancing speakers segments ----- #\n",
    "            recording_data['speakers_indexes_lengths_max'] = max([len(recording_data['speakers_indexes'][speakers_ids]) for speakers_ids in recording_data['speakers_indexes']])\n",
    "            if self.balance_segments:\n",
    "                if self.balance_segments_selection == 'copy':\n",
    "                    for speakers_ids in recording_data['speakers_indexes']:\n",
    "                        for i in range(recording_data['speakers_indexes_lengths_max'] - len(recording_data['speakers_indexes'][speakers_ids])):\n",
    "                            index = random.choice(recording_data['speakers_indexes'][speakers_ids])\n",
    "                            recording_segments.append(recording_segments[index])\n",
    "                            recording_data['speakers_indexes'][speakers_ids].append(len(recording_segments) - 1)\n",
    "                else:\n",
    "                    print('ERROR: unknown balancing segments selection strategy.')\n",
    "            # ----- Generating speakers models ----- #\n",
    "            recording_data['speakers_models'] = {}\n",
    "            for speakers_ids in recording_data['speakers_indexes']:\n",
    "                recording_data['speakers_models'][speakers_ids] = {}\n",
    "                for models_generation_length in models_generation_lengths:\n",
    "                    speakers_model = generate_speaker_model(recording_segments, recording_data['speakers_indexes'][speakers_ids], models_generation_length, self.vector, self.models_generation_selection)\n",
    "                    recording_data['speakers_models'][speakers_ids][models_generation_length] = [speakers_model]\n",
    "            # ----- Generating permutations ----- #\n",
    "            if self.models_container_include_zeros:\n",
    "                recording_data['permutations'] = list(itertools.permutations(list(recording_data['speakers_models'].keys()) \\\n",
    "                + ['0' for i in range(self.models_container_length)], self.models_container_length))\n",
    "            else:\n",
    "                recording_data['permutations'] = list(itertools.permutations(list(recording_data['speakers_models'].keys()), self.models_container_length))\n",
    "            recording_data['permutations'] = list(set(recording_data['permutations']))\n",
    "            recording_data['permutations'].sort()\n",
    "            if not self.models_container_include_overlaps:\n",
    "                recording_data['permutations'] = [permutation for permutation in recording_data['permutations'] if all(len(speakers_ids.split(',')) == 1 for speakers_ids in permutation)]\n",
    "            # -------------------------------------------------- #\n",
    "            recording_data['permutations_map'] = []\n",
    "            recording_data['permutations_length'] = 0\n",
    "            for index, permutation in enumerate(recording_data['permutations']):\n",
    "                speakers_models_length = int(np.prod([np.sum([len(recording_data['speakers_models'][speakers_ids][models_generation_length]) for models_generation_length in recording_data['speakers_models'][speakers_ids]]) for speakers_ids in permutation if speakers_ids != '0']))\n",
    "                recording_data['permutations_map'].append((recording_data['permutations_length'], recording_data['permutations_length'] + speakers_models_length - 1, index))\n",
    "                recording_data['permutations_length'] += speakers_models_length\n",
    "            recording_data['length'] = len(recording_segments) * recording_data['permutations_length']\n",
    "            self.recordings_map.append((self.recordings_length, self.recordings_length + recording_data['length'] - 1, recording_id))\n",
    "            self.recordings_length += recording_data['length']\n",
    "    def __len__(self):\n",
    "        return self.recordings_length\n",
    "    def __getitem__(self, idx):\n",
    "        recording_limits = list(filter(lambda recording_limits: recording_limits[0] <= idx and idx <= recording_limits[1], self.recordings_map))[0]\n",
    "        recording_idx = idx - recording_limits[0]\n",
    "        recording_id = recording_limits[2]\n",
    "        recording_data = self.recordings_data[recording_id]\n",
    "        \n",
    "        segment_index, segment_idx = divmod(recording_idx, recording_data['permutations_length'])\n",
    "        segment = self.recordings_segments[recording_id][segment_index]\n",
    "        vector = np.asarray(segment[self.vector][0]['value'])\n",
    "        \n",
    "        permutation_limits = list(filter(lambda permutation_limits: permutation_limits[0] <= segment_idx and segment_idx <= permutation_limits[1], recording_data['permutations_map']))[0]\n",
    "        permutation_idx = segment_idx - permutation_limits[0]\n",
    "        permutation_index = permutation_limits[2]\n",
    "        permutation = recording_data['permutations'][permutation_index]\n",
    "        \n",
    "        speakers_models_lengths = [np.sum([len(recording_data['speakers_models'][speakers_ids][models_generation_length]) for models_generation_length in recording_data['speakers_models'][speakers_ids]])  if speakers_ids != '0' else 1 for speakers_ids in permutation]\n",
    "        models_container = []\n",
    "        model_index = permutation_idx\n",
    "        for i, length_i in enumerate(speakers_models_lengths):\n",
    "            if i != len(speakers_models_lengths) - 1:\n",
    "                model_index, remainder = divmod(model_index, np.sum(speakers_models_lengths[i + 1:]))\n",
    "            else:\n",
    "                model_index = remainder\n",
    "            models_container.append(recording_data['speakers_models'][permutation[i]][self.models_generation_lengths[model_index]][0] if permutation[i] != '0' else np.random.uniform(-0.1, 0.1, len(vector)))\n",
    "        \n",
    "        models_weigths = np.asarray([len(recording_data['speakers_indexes'][speakers_ids]) if speakers_ids != '0' else recording_data['speakers_indexes_lengths_max'] for speakers_ids in permutation])\n",
    "        models_weigths_sum = np.sum(models_weigths)\n",
    "        models_weigths = np.ones(len(models_weigths)) - models_weigths / models_weigths_sum\n",
    "        \n",
    "        targets_ids = [speaker['speaker_id'] for speaker in segment['speakers']]\n",
    "        \n",
    "        x = [vector] + models_container\n",
    "        if self.models_container_include_overlaps:\n",
    "            targets_ids = ','.join(sorted(list(set(targets_ids))))\n",
    "            y = np.asarray([speakers_ids == targets_ids for speakers_ids in permutation], dtype = float)\n",
    "        else:\n",
    "            y = np.asarray([speaker_id in targets_ids for speaker_id in permutation], dtype = float) / len(targets_ids)\n",
    "        z = models_weigths\n",
    "        \n",
    "        return x, y, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load live_graph.py\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Live_graph:\n",
    "    def __init__(self, validation_threshold):\n",
    "        self.plt_count = -1\n",
    "        self.validation_threshold = validation_threshold\n",
    "        self.plt_thr = ([self.plt_count], [self.validation_threshold])\n",
    "        self.plt_loss = ([self.plt_count], [1])\n",
    "        self.plt_valid = ([self.plt_count], [1])\n",
    "        self.plt_test = ([self.plt_count], [1])\n",
    "        self.fig = plt.figure()\n",
    "        self.ax = self.fig.add_subplot()\n",
    "        self.line0, = self.ax.plot(self.plt_thr[0], self.plt_thr[1], 'k--', label = 'Threshold') # Threshold line\n",
    "        self.line1, = self.ax.plot(self.plt_loss[0], self.plt_loss[1], '--', label = 'Training') # Training loss\n",
    "        self.line2, = self.ax.plot(self.plt_valid[0], self.plt_valid[1], label = 'Validation')   # Validation loss\n",
    "        self.line3, = self.ax.plot(self.plt_test[0], self.plt_test[1], label = 'Test')           # Test loss\n",
    "        self.ax.set_xlabel('Epoch')\n",
    "        self.ax.set_ylabel('Loss')\n",
    "        self.ax.legend()\n",
    "        self.ax.set_xlim(-1, 0)\n",
    "        self.ax.set_ylim(0, 0.5)\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.canvas.flush_events()\n",
    "    def step(self, training, validation, test = -1):\n",
    "        self.plt_count += 1\n",
    "        self.plt_thr[0].append(self.plt_count)\n",
    "        self.plt_thr[1].append(self.validation_threshold)\n",
    "        self.plt_loss[0].append(self.plt_count)\n",
    "        self.plt_loss[1].append(training)\n",
    "        self.plt_valid[0].append(self.plt_count)\n",
    "        self.plt_valid[1].append(validation)\n",
    "        self.plt_test[0].append(self.plt_count)\n",
    "        self.plt_test[1].append(test)\n",
    "        self.line0.set_xdata(self.plt_thr[0])\n",
    "        self.line0.set_ydata(self.plt_thr[1])\n",
    "        self.line1.set_xdata(self.plt_loss[0])\n",
    "        self.line1.set_ydata(self.plt_loss[1])\n",
    "        self.line2.set_xdata(self.plt_valid[0])\n",
    "        self.line2.set_ydata(self.plt_valid[1])\n",
    "        self.line3.set_xdata(self.plt_test[0])\n",
    "        self.line3.set_ydata(self.plt_test[1])\n",
    "        self.ax.set_xlim(0, self.plt_count + 1)\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.canvas.flush_events()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, models_container_length, vector_length):\n",
    "        super().__init__()\n",
    "        n = models_container_length\n",
    "        m = vector_length\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv1d((n + 1), n ** 3, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(n ** 3, n ** 2, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(n ** 2, n, 3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(n * (m - 6), n * 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n * 16, n * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n * 4, n),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = torch.stack(input, 1)\n",
    "        x = self.cnn1(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self):\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device('cuda:0')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "    def get_net(self,\n",
    "                recordings_segments,\n",
    "                recordings_ids = None,\n",
    "                vector = 'ivectors',\n",
    "                vector_length = 128,\n",
    "                models_container_length = 2,\n",
    "                models_container_include_zeros = True,\n",
    "                models_container_include_overlaps = False,\n",
    "                models_generation_lengths = [3],\n",
    "                models_generation_selection = 'first',\n",
    "                balance_segments = True,\n",
    "                balance_segments_selection = 'copy',\n",
    "                batch_size = 16,\n",
    "                num_workers = 8,\n",
    "                test_recordings_segments = None):\n",
    "        \n",
    "        if recordings_ids is None:\n",
    "            recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "        self.recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "\n",
    "        train_dataset = Recordings_dataset(recordings_segments,\n",
    "                                           recordings_ids, \n",
    "                                           vector,\n",
    "                                           models_container_length,\n",
    "                                           models_container_include_zeros,\n",
    "                                           models_container_include_overlaps,\n",
    "                                           models_generation_lengths,\n",
    "                                           models_generation_selection,\n",
    "                                           balance_segments,\n",
    "                                           balance_segments_selection)\n",
    "\n",
    "        train_length = int(len(train_dataset) * 0.7)\n",
    "        valid_length = len(train_dataset) - train_length\n",
    "\n",
    "        train_dataset, valid_dataset = random_split(train_dataset, [train_length, valid_length])\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers = num_workers)\n",
    "        valid_dataloader = DataLoader(valid_dataset, batch_size = batch_size, num_workers = num_workers)\n",
    "        \n",
    "        if test_recordings_segments is not None:\n",
    "            test_recordings_ids = [recording_id for recording_id in test_recordings_segments]\n",
    "            test_dataset = Recordings_dataset(test_recordings_segments,\n",
    "                                              test_recordings_ids,\n",
    "                                              vector,\n",
    "                                              models_container_length,\n",
    "                                              models_container_include_zeros,\n",
    "                                              models_container_include_overlaps,\n",
    "                                              models_generation_lengths,\n",
    "                                              models_generation_selection,\n",
    "                                              balance_segments,\n",
    "                                              balance_segments_selection)\n",
    "            test_dataloader = DataLoader(test_dataset, batch_size = batch_size, num_workers = num_workers)\n",
    "\n",
    "        net = Net(models_container_length, vector_length).to(self.device)\n",
    "        optimizer = optim.Adam(net.parameters(), lr = 0.0001)\n",
    "\n",
    "        epochs = 30\n",
    "        validation_threshold = 0.07\n",
    "\n",
    "        live_graph = Live_graph(validation_threshold)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_losses = []\n",
    "            for input, target, weigth in train_dataloader:\n",
    "                input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                target = target.to(self.device, non_blocking = True).float()\n",
    "                weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                criterion = nn.BCELoss(weigth)\n",
    "                net.zero_grad()\n",
    "                output = net(input)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_losses.append(loss.data)\n",
    "                print('train: ' + str(len(train_losses)) + '/' + str(len(train_dataloader)) + '          ', end = '\\r')\n",
    "            train_loss = np.sum(train_losses) / len(train_losses)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                validation_losses = []\n",
    "                for input, target, weigth in valid_dataloader:\n",
    "                    input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                    target = target.to(self.device, non_blocking = True).float()\n",
    "                    weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                    criterion = nn.BCELoss(weigth)\n",
    "                    output = net(input)\n",
    "                    loss = criterion(output, target)\n",
    "                    validation_losses.append(loss.data)\n",
    "                    print('validation: ' + str(len(validation_losses)) + '/' + str(len(valid_dataloader)) + '          ', end = '\\r')\n",
    "                validation_loss = np.sum(validation_losses) / len(validation_losses)\n",
    "                \n",
    "                test_loss = -1\n",
    "                if test_recordings_segments is not None:\n",
    "                    test_losses = []\n",
    "                    for input, target, weigth in test_dataloader:\n",
    "                        input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                        target = target.to(self.device, non_blocking = True).float()\n",
    "                        weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                        criterion = nn.BCELoss(weigth)\n",
    "                        output = net(input)\n",
    "                        loss = criterion(output, target)\n",
    "                        test_losses.append(loss.data)\n",
    "                        print('test: ' + str(len(test_losses)) + '/' + str(len(test_dataloader)) + '          ', end = '\\r')\n",
    "                    test_loss = np.sum(test_losses) / len(test_losses)\n",
    "\n",
    "            live_graph.step(train_loss, validation_loss, test_loss)\n",
    "\n",
    "            if validation_loss <= validation_threshold:\n",
    "                print('Done training.')\n",
    "                break\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load md_eval.py\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "def md_eval(ref_filepath, res_filepath, save_filepath = None):\n",
    "    bin = '../../../../tools/sctk-2.4.10/src/md-eval/md-eval.pl'\n",
    "    p = subprocess.Popen([bin, '-r', ref_filepath, '-s', res_filepath], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output, err = p.communicate()\n",
    "    rc = p.returncode\n",
    "    if rc == 0:\n",
    "        output = output.decode(\"utf-8\")\n",
    "        if save_filepath is not None:\n",
    "            file = open(save_filepath, 'w')\n",
    "            file.write(output)\n",
    "            file.close()\n",
    "        lines =  output.split('\\n')\n",
    "        derLine = [line for line in lines if 'OVERALL SPEAKER DIARIZATION ERROR' in line][0]\n",
    "        return float(re.findall('\\d+\\.\\d+', derLine)[0])\n",
    "    else:\n",
    "        exit('md-eval.pl fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eer(res_filepath):\n",
    "    bin = '../eer_score.sh'\n",
    "    p = subprocess.Popen([bin, res_filepath], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output, err = p.communicate()\n",
    "    rc = p.returncode\n",
    "    if rc == 0:\n",
    "        output = output.decode(\"utf-8\")\n",
    "        return float(output)\n",
    "    else:\n",
    "        exit('eer_score.sh fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plda_score(ref_vector, test_vector, plda_filepath):\n",
    "    ref_string = str(list(ref_vector)).replace(',', '').replace('[', '[ ').replace(']', ' ]')\n",
    "    test_string = str(list(test_vector)).replace(',', '').replace('[', '[ ').replace(']', ' ]')\n",
    "\n",
    "    bin = '../plda_score.sh'\n",
    "    p = subprocess.Popen([bin, plda_filepath, ref_string, test_string], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output, err = p.communicate()\n",
    "    rc = p.returncode\n",
    "    if rc == 0:\n",
    "        lines =  output.decode(\"utf-8\").split('\\n')\n",
    "        pldaLine = [line for line in lines if 'reference test' in line][0]\n",
    "        return float(re.findall('\\d+\\.\\d+', pldaLine)[0])\n",
    "    else:\n",
    "        print(err)\n",
    "        exit('plda_socre.sh fail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracking_tester(recordings_segments,\n",
    "                    recordings_ids = None,\n",
    "                    scoring_function = None,\n",
    "                    groundtruth_filepath = '',\n",
    "                    groundtruth_valid_speakers_ids = ['A', 'B'],\n",
    "                    vector = 'ivectors',\n",
    "                    models_container_length = 2,\n",
    "                    models_container_include_overlaps = False,\n",
    "                    models_generation_length = 3,\n",
    "                    models_generation_selection = 'first'):\n",
    "\n",
    "    if recordings_ids is None:\n",
    "        recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "    recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "    recordings_ids.sort()\n",
    "    \n",
    "    results = {}\n",
    "    results_reduced = {}\n",
    "    results_rttm = ''\n",
    "    results_scores = {}\n",
    "    results_eer = ''\n",
    "    for recording_id in recordings_ids:\n",
    "        recording_dataset = Recordings_dataset(recordings_segments,\n",
    "                                               recording_id,\n",
    "                                               vector = vector,\n",
    "                                               models_container_length = models_container_length,\n",
    "                                               models_container_include_zeros = False,\n",
    "                                               models_container_include_overlaps = models_container_include_overlaps,\n",
    "                                               models_generation_lengths = [models_generation_length],\n",
    "                                               models_generation_selection = models_generation_selection,\n",
    "                                               balance_segments = False,\n",
    "                                               balance_segments_selection = 'copy')\n",
    "        speakers_models = recording_dataset.recordings_data[recording_id]['speakers_models']\n",
    "        speakers_ids = [speakers_ids for speakers_ids in speakers_models]\n",
    "        models_container = [speakers_models[speakers_ids][models_generation_length][0] for speakers_ids in speakers_models if models_container_include_overlaps or len(speakers_ids.split(',')) == 1]\n",
    "        for i in range(models_container_length - len(models_container)):\n",
    "            models_container.append(np.random.uniform(-0.1, 0.1, len(models_container[0])))\n",
    "        # At this point there is no information about the speaker identity, only the model\n",
    "        results[recording_id] = []\n",
    "        results_scores[recording_id] = []\n",
    "        for segment in recordings_segments[recording_id]:\n",
    "            segment_vector = np.asarray(segment[vector][0]['value'])\n",
    "            scores = scoring_function(segment_vector, models_container)\n",
    "            targets_ids = [speaker['speaker_id'] for speaker in segment['speakers']]\n",
    "            targets_ids.sort()\n",
    "            labels = ['target' if targets_ids == sorted(speaker_id.split(',')) else 'nontarget' for speaker_id in speakers_ids]\n",
    "            scores_labels = list(zip(scores, labels))\n",
    "            results_scores[recording_id].append(scores_labels)\n",
    "            index = np.argmax(scores)\n",
    "            results[recording_id].append({ 'begining': segment['begining'], 'ending': segment['ending'], 'speaker_id': index })\n",
    "            if len(results[recording_id]) > 2:\n",
    "                if results[recording_id][len(results[recording_id]) - 1]['speaker_id'] == results[recording_id][len(results[recording_id]) - 3]['speaker_id']:\n",
    "                    if results[recording_id][len(results[recording_id]) - 1]['speaker_id'] != results[recording_id][len(results[recording_id]) - 2]['speaker_id']:\n",
    "                        results[recording_id][len(results[recording_id]) - 2]['speaker_id'] = results[recording_id][len(results[recording_id]) - 1]['speaker_id']\n",
    "                        results[recording_id][len(results[recording_id]) - 1]['modified'] = True\n",
    "        results_reduced[recording_id] = []\n",
    "        last_speaker_id = -1\n",
    "        last_speaker = { 'begining': 0, 'ending': 0, 'speaker_id': -1 }\n",
    "        for segment in results[recording_id] + [{ 'begining': 0, 'ending': 0, 'speaker_id': -1 }]:\n",
    "            begining = segment['begining']\n",
    "            ending = segment['ending']\n",
    "            speaker_id = segment['speaker_id']\n",
    "            if last_speaker_id != speaker_id:\n",
    "                if last_speaker_id != -1:\n",
    "                    results_reduced[recording_id].append(last_speaker)\n",
    "                last_speaker_id = speaker_id\n",
    "                last_speaker = { 'begining': begining, 'ending': ending, 'speaker_id': speaker_id }\n",
    "            else:\n",
    "                if begining <= last_speaker['ending']:\n",
    "                    last_speaker['ending'] = ending\n",
    "                else:\n",
    "                    if last_speaker_id != -1:\n",
    "                        results_reduced[recording_id].append(last_speaker)\n",
    "                    last_speaker_id = speaker_id\n",
    "                    last_speaker = { 'begining': begining, 'ending': ending, 'speaker_id': speaker_id }\n",
    "        for scores_labels in results_scores[recording_id]:\n",
    "            for score_label in scores_labels:\n",
    "                result_eer = '{:f}'.format(score_label[0]) + ' ' + score_label[1]\n",
    "                results_eer += result_eer + '\\n'\n",
    "        for segment in results_reduced[recording_id]:\n",
    "            result_rttm = 'SPEAKER ' + recording_id + ' 0 ' + str(segment['begining']) + ' ' + str(round(segment['ending'] - segment['begining'], 2)) + ' <NA> <NA> ' + str(segment['speaker_id']) + ' <NA> <NA>'\n",
    "            results_rttm += result_rttm + '\\n'\n",
    "\n",
    "    file = open(groundtruth_filepath, 'r')\n",
    "    groundtruth_rttm = ''.join([line for line in file.readlines() if (line.split(' ')[1] in recordings_ids) and \\\n",
    "                    (line.split(' ')[7] in ['A', 'B'])])\n",
    "    file.close()\n",
    "    \n",
    "    !mkdir -p tmp\n",
    "    \n",
    "    file = open('tmp/results.eer', 'w')\n",
    "    file.write(results_eer)\n",
    "    file.close()\n",
    "    \n",
    "    file = open('tmp/groundtruth.rttm', 'w')\n",
    "    file.write(groundtruth_rttm)\n",
    "    file.close()\n",
    "    \n",
    "    file = open('tmp/results.rttm', 'w')\n",
    "    file.write(results_rttm)\n",
    "    file.close()\n",
    "\n",
    "    print(eer('notebooks/tmp/results.eer'))\n",
    "    return md_eval('tmp/groundtruth.rttm', 'tmp/results.rttm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading recordings segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_directory = '../exp/pre_norm/callhome1/json'\n",
    "b_directory = '../exp/pre_norm/callhome2/json'\n",
    "maximum_speakers_length = 2\n",
    "valid_speakers_ids = ['A', 'B']\n",
    "include_overlaps = False\n",
    "vector = 'ivectors'\n",
    "vector_length = 128\n",
    "models_container_length = 2\n",
    "models_container_include_zeros = True\n",
    "models_container_include_overlaps = False\n",
    "models_generation_length = 3\n",
    "models_generation_selection = 'first'\n",
    "balance_segments_selection = 'copy'\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../exp/pre_norm/callhome1/json loaded 249/249, 0.74 segments left.\n",
      "../exp/pre_norm/callhome2/json loaded 250/250, 0.77 segments left.\n"
     ]
    }
   ],
   "source": [
    "a_recordings_segments = load_recordings_segments(a_directory,\n",
    "                                                 lambda segment: is_valid_segment(segment, maximum_speakers_length, valid_speakers_ids))\n",
    "b_recordings_segments = load_recordings_segments(b_directory,\n",
    "                                                 lambda segment: is_valid_segment(segment, maximum_speakers_length, valid_speakers_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recordings left: 246/249\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training.29/1029          \n"
     ]
    }
   ],
   "source": [
    "a_trainer = Trainer()\n",
    "a_net = a_trainer.get_net(balance_segments(a_recordings_segments, \n",
    "                                           maximum_speakers_length,\n",
    "                                           models_generation_length,\n",
    "                                           include_overlaps),\n",
    "                          vector = vector,\n",
    "                          vector_length = vector_length,\n",
    "                          models_container_length = models_container_length,\n",
    "                          models_container_include_zeros = models_container_include_zeros,\n",
    "                          models_container_include_overlaps = models_container_include_overlaps,\n",
    "                          models_generation_lengths = [models_generation_length],\n",
    "                          models_generation_selection = models_generation_selection,\n",
    "                          balance_segments_selection = balance_segments_selection,\n",
    "                          batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_selector(vector, models_container, net):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    with torch.no_grad():\n",
    "        input = [torch.Tensor([nparray]).to(device, non_blocking = True).float() for nparray in [vector] + models_container]\n",
    "        output = net(input)\n",
    "        return output.cpu().data.numpy()[0]\n",
    "    \n",
    "def plda_selector(vector, models_container, plda_filepath):\n",
    "    return [plda_score(ref_vector, vector, plda_filepath) for ref_vector in models_container]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../exp/pre_norm/callhome2/json loaded 250/250, 0.7 segments left.\n"
     ]
    }
   ],
   "source": [
    "b_recordings_segments = load_recordings_segments(b_directory,\n",
    "                                                 lambda segment: is_single_speaker_segment(segment, ['A', 'B']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.16"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_tester(b_recordings_segments,\n",
    "                scoring_function = lambda vector, models_container: net_selector(vector, models_container, a_net),\n",
    "                groundtruth_filepath = '../data/callhome2_1.0_0.5.rttm',\n",
    "                groundtruth_valid_speakers_ids = ['A', 'B'],\n",
    "                vector = vector,\n",
    "                models_container_length = models_container_length,\n",
    "                models_container_include_overlaps = models_container_include_overlaps,\n",
    "                models_generation_length = models_generation_length,\n",
    "                models_generation_selection = models_generation_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.84"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_tester(b_recordings_segments,\n",
    "                scoring_function = lambda vector, models_container: plda_selector(vector,\n",
    "                                                                                  models_container,\n",
    "                                                                                  'exp/plda/callhome1/ivectors.plda'),\n",
    "                groundtruth_filepath = '../data/callhome2_1.0_0.5.rttm',\n",
    "                groundtruth_valid_speakers_ids = ['A', 'B'],\n",
    "                vector = vector,\n",
    "                models_container_length = models_container_length,\n",
    "                models_container_include_overlaps = models_container_include_overlaps,\n",
    "                models_generation_length = models_generation_length,\n",
    "                models_generation_selection = models_generation_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
