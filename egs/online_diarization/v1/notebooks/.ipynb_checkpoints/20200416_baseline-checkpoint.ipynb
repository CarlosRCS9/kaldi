{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recordings segments loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from functools import reduce\n",
    "\n",
    "# is_single_speaker_segment [VALIDATED]\n",
    "# validates if a segment has a single speaker who belongs to the speakers list. \n",
    "def is_single_speaker_segment(segment, valid_speakers_ids = ['A', 'B']):\n",
    "    return len(segment['speakers']) == 1 and segment['speakers'][0]['speaker_id'] in valid_speakers_ids\n",
    "\n",
    "# is_valid_segment [VALIDATED]\n",
    "# validates if a segment meets a maximum number of speakers,\n",
    "# and that all the speakers in the segment belong to a list.\n",
    "def is_valid_segment(segment, maximum_speakers_length = 2, valid_speakers_ids = ['A', 'B']):\n",
    "    speakers_ids = [speaker['speaker_id'] for speaker in segment['speakers']]\n",
    "    speakers_ids = list(set(speakers_ids))\n",
    "    return len(speakers_ids) <= maximum_speakers_length and \\\n",
    "        all(speaker_id in valid_speakers_ids for speaker_id in speakers_ids)\n",
    "\n",
    "# load_recordings_segments [VALIDATED]\n",
    "# loads the recordings segments data from the .json files located in a directory \n",
    "def load_recordings_segments(directory, validation_function):\n",
    "    filenames = [filename for filename in os.listdir(directory) if os.path.isfile(os.path.join(directory, filename))]\n",
    "    filenames.sort()\n",
    "    recordings_segments = {}\n",
    "    recordings_length = len(filenames)\n",
    "    recordings_count = 0\n",
    "    segments_original = 0\n",
    "    segments_filtered = 0\n",
    "    for filename in filenames:\n",
    "        recording_id = filename.split('.')[0]\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        file = open(filepath, 'r')\n",
    "        recordings_segments[recording_id] = [json.loads(line) for line in file.readlines()]\n",
    "        file.close()\n",
    "        segments_original += len(recordings_segments[recording_id])\n",
    "        recordings_segments[recording_id] = list(filter(validation_function, recordings_segments[recording_id]))\n",
    "        segments_filtered += len(recordings_segments[recording_id])\n",
    "        recordings_count += 1\n",
    "        print(directory + ' loading ' + str(recordings_count) + '/' + str(recordings_length), end = '\\r')\n",
    "    print(directory, 'loaded', str(recordings_count) + '/' + str(recordings_length) + ',', round(segments_filtered / segments_original, 2), 'segments left.')\n",
    "    return recordings_segments\n",
    "\n",
    "# speakers_get_indexes [VALIDATED]\n",
    "# used to convert a (speakers_ids, index) list to a speakers_ids => [indexes] dictionary\n",
    "def speakers_get_indexes(accumulator, speakers_tuple):\n",
    "    speaker_ids, index = speakers_tuple\n",
    "    speaker_ids = ','.join(speaker_ids)\n",
    "    if speaker_ids in accumulator:\n",
    "        accumulator[speaker_ids].append(index)\n",
    "    else:\n",
    "        accumulator[speaker_ids] = [index]\n",
    "    return accumulator\n",
    "\n",
    "# balance_segments [VALIDATED]\n",
    "# balances the recording segments data to meet a minimum of speakers per recording,\n",
    "# and a minimum of segments per speaker.\n",
    "def balance_segments(recordings_segments,\n",
    "                     minimum_speakers_length = 2,\n",
    "                     minimum_speaker_segments = 3,\n",
    "                     include_overlaps = False):\n",
    "    new_recordings_segments = {}\n",
    "    for recording_id in recordings_segments:\n",
    "        recording_segments = recordings_segments[recording_id]\n",
    "        # ----- Obtaining speakers indexes ----- #\n",
    "        speakers_indexes = [(sorted(list(set([speaker['speaker_id'] for speaker in segment['speakers']]))), index) for index, segment in enumerate(recording_segments)]\n",
    "        speakers_indexes = reduce(speakers_get_indexes, speakers_indexes, {})\n",
    "        # ----- Removing overlaps ----- #\n",
    "        if not include_overlaps:\n",
    "            for speakers_ids in list(speakers_indexes.keys()):\n",
    "                if len(speakers_ids.split(',')) > 1:\n",
    "                    del speakers_indexes[speakers_ids]\n",
    "        speakers_lengths = [(speakers_ids, len(speakers_indexes[speakers_ids])) for speakers_ids in speakers_indexes]\n",
    "        speakers_lengths.sort(key = lambda x: x[1])\n",
    "        speakers_lengths_min = speakers_lengths[0][1]\n",
    "        if len(speakers_lengths) >= minimum_speakers_length and speakers_lengths_min >= minimum_speaker_segments:\n",
    "            recording_indexes = []\n",
    "            for speakers_ids in speakers_indexes:\n",
    "                speakers_indexes[speakers_ids] = speakers_indexes[speakers_ids][:speakers_lengths_min]\n",
    "                recording_indexes += speakers_indexes[speakers_ids]\n",
    "            new_recordings_segments[recording_id] = [segment for index, segment in enumerate(recordings_segments[recording_id]) if index in recording_indexes]\n",
    "    print('Recordings left: ' + str(len(new_recordings_segments)) + '/' + str(len(recordings_segments)))\n",
    "    return new_recordings_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../exp/augmented/callhome1/json loaded 249/249, 1.0 segments left.\n"
     ]
    }
   ],
   "source": [
    "a_recordings_segments = load_recordings_segments('../exp/augmented/callhome1/json',\n",
    "  lambda segment: True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recordings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def generate_speaker_model(recording_segments,\n",
    "                           speakers_segments_indexes,\n",
    "                           segments_length,\n",
    "                           vector = 'ivectors',\n",
    "                           selection = 'first',\n",
    "                           indexes = []):\n",
    "    #if segments_length > len(speaker_indexes):\n",
    "    #    print('WARNING: there are less speaker indexes than segments.')\n",
    "    if selection == 'first':\n",
    "        selected_segments = [recording_segments[index] for _, index, _ in speakers_segments_indexes[:segments_length]]\n",
    "    elif selection == 'random':\n",
    "        selected_segments = [recording_segments[index] for _, index, _ in random.sample(speakers_segments_indexes, segments_length if segments_length < len(speakers_segments_indexes) else len(speakers_segments_indexes))]\n",
    "    else:\n",
    "        print('ERROR: unknown speaker model segments selection strategy.')\n",
    "    selected_vectors = [np.asarray(segment[vector][0]['value']) for segment in selected_segments]\n",
    "    return np.sum(selected_vectors, 0) / len(selected_vectors)\n",
    "\n",
    "def get_speakers_segments_indexes(acc, recording_id_index_real, recording_segments):\n",
    "    _, index, _ = recording_id_index_real\n",
    "    segment = recording_segments[index]\n",
    "    speakers_ids = ','.join(sorted([speaker['speaker_id'] for speaker in segment['speakers']]))\n",
    "    if speakers_ids not in acc:\n",
    "        acc[speakers_ids] = []\n",
    "    acc[speakers_ids].append(recording_id_index_real)\n",
    "    return acc\n",
    "\n",
    "class Recordings_dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 recordings_segments,\n",
    "                 recordings_ids = None,\n",
    "                 vector = 'ivectors',\n",
    "                 models_container_length = 2,\n",
    "                 models_container_include_zeros = True,\n",
    "                 models_container_include_overlaps = False,\n",
    "                 models_generation_lengths = [3],\n",
    "                 models_generation_selection = 'first',\n",
    "                 balance_segments = True,\n",
    "                 balance_segments_selection = 'copy'):\n",
    "        # -----------------------------------------------------Saving input data----- #\n",
    "        if recordings_ids is None:\n",
    "            recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "        self.recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "        self.recordings_segments = {}\n",
    "        for recording_id in self.recordings_ids:\n",
    "            self.recordings_segments[recording_id] = recordings_segments[recording_id]\n",
    "        self.vector = vector\n",
    "        self.models_container_length = models_container_length\n",
    "        self.models_container_include_zeros = models_container_include_zeros\n",
    "        self.models_container_include_overlaps = models_container_include_overlaps\n",
    "        self.models_generation_lengths = models_generation_lengths\n",
    "        self.models_generation_selection = models_generation_selection\n",
    "        self.balance_segments = balance_segments\n",
    "        self.balance_segments_selection = balance_segments_selection\n",
    "        # --------------------------------------------------------------------------- #\n",
    "        self.recordings_data = {}\n",
    "        # -------------------------------------------------- #\n",
    "        self.recordings_map = []\n",
    "        self.recordings_length = 0\n",
    "        for recording_id in self.recordings_ids:\n",
    "            self.recordings_data[recording_id] = {}\n",
    "            recording_data = self.recordings_data[recording_id]\n",
    "            recording_segments = self.recordings_segments[recording_id]\n",
    "            recording_segments_indexes = [(recording_id, index, True) for index, segment in enumerate(recording_segments)]            \n",
    "            # ----- Obtaining speakers indexes ----- #\n",
    "            recording_data['speakers_segments_indexes'] = reduce(lambda acc, recording_id_index_real: get_speakers_segments_indexes(acc, recording_id_index_real, self.recordings_segments[recording_id]), recording_segments_indexes, {})\n",
    "            \n",
    "            # ----- Balancing speakers segments ----- #\n",
    "            recording_data['speakers_segments_indexes_lengths_max'] = max([len(recording_data['speakers_segments_indexes'][speakers_ids]) for speakers_ids in recording_data['speakers_segments_indexes']])\n",
    "            '''if self.balance_segments:\n",
    "                if self.balance_segments_selection == 'copy':\n",
    "                    for speakers_ids in recording_data['speakers_indexes']:\n",
    "                        for i in range(recording_data['speakers_indexes_lengths_max'] - len(recording_data['speakers_indexes'][speakers_ids])):\n",
    "                            index = random.choice(recording_data['speakers_indexes'][speakers_ids])\n",
    "                            recording_segments.append(recording_segments[index])\n",
    "                            recording_data['speakers_indexes'][speakers_ids].append(len(recording_segments) - 1)\n",
    "                else:\n",
    "                    print('ERROR: unknown balancing segments selection strategy.')'''\n",
    "            \n",
    "            # ----- Generating speakers models ----- #\n",
    "            recording_data['speakers_models'] = {}\n",
    "            for speakers_ids in recording_data['speakers_segments_indexes']:\n",
    "                recording_data['speakers_models'][speakers_ids] = {}\n",
    "                for models_generation_length in models_generation_lengths:\n",
    "                    speakers_model = generate_speaker_model(recording_segments, recording_data['speakers_segments_indexes'][speakers_ids], models_generation_length, self.vector, self.models_generation_selection)\n",
    "                    recording_data['speakers_models'][speakers_ids][models_generation_length] = [speakers_model]\n",
    "            \n",
    "            # ----- Generating permutations ----- #\n",
    "            if self.models_container_include_zeros:\n",
    "                recording_data['permutations'] = list(itertools.permutations(list(recording_data['speakers_models'].keys()) \\\n",
    "                + ['0' for i in range(self.models_container_length)], self.models_container_length))\n",
    "            else:\n",
    "                recording_data['permutations'] = list(itertools.permutations(list(recording_data['speakers_models'].keys()), self.models_container_length))\n",
    "            recording_data['permutations'] = sorted(list(set(recording_data['permutations'])))\n",
    "            if not self.models_container_include_overlaps:\n",
    "                recording_data['permutations'] = [permutation for permutation in recording_data['permutations'] if all(len(speakers_ids.split(',')) == 1 for speakers_ids in permutation)]\n",
    "            # -------------------------------------------------- #\n",
    "            recording_data['permutations_map'] = []\n",
    "            recording_data['permutations_length'] = 0\n",
    "            for index, permutation in enumerate(recording_data['permutations']):\n",
    "                speakers_models_length = int(np.prod([np.sum([len(recording_data['speakers_models'][speakers_ids][models_generation_length]) for models_generation_length in recording_data['speakers_models'][speakers_ids]]) for speakers_ids in permutation if speakers_ids != '0']))\n",
    "                recording_data['permutations_map'].append((recording_data['permutations_length'], recording_data['permutations_length'] + speakers_models_length - 1, index))\n",
    "                recording_data['permutations_length'] += speakers_models_length\n",
    "            recording_data['length'] = len(recording_segments_indexes) * recording_data['permutations_length']\n",
    "            self.recordings_map.append((self.recordings_length, self.recordings_length + recording_data['length'] - 1, recording_id))\n",
    "            self.recordings_length += recording_data['length']\n",
    "    def __len__(self):\n",
    "        return self.recordings_length\n",
    "    def __getitem__(self, idx):\n",
    "        recording_limits = list(filter(lambda recording_limits: recording_limits[0] <= idx and idx <= recording_limits[1], self.recordings_map))[0]\n",
    "        recording_idx = idx - recording_limits[0]\n",
    "        recording_id = recording_limits[2]\n",
    "        recording_data = self.recordings_data[recording_id]\n",
    "        \n",
    "        segment_index, segment_idx = divmod(recording_idx, recording_data['permutations_length'])\n",
    "        segment = self.recordings_segments[recording_id][segment_index]\n",
    "        vector = np.asarray(segment[self.vector][0]['value'])\n",
    "        \n",
    "        permutation_limits = list(filter(lambda permutation_limits: permutation_limits[0] <= segment_idx and segment_idx <= permutation_limits[1], recording_data['permutations_map']))[0]\n",
    "        permutation_idx = segment_idx - permutation_limits[0]\n",
    "        permutation_index = permutation_limits[2]\n",
    "        permutation = recording_data['permutations'][permutation_index]\n",
    "        \n",
    "        speakers_models_lengths = [np.sum([len(recording_data['speakers_models'][speakers_ids][models_generation_length]) for models_generation_length in recording_data['speakers_models'][speakers_ids]])  if speakers_ids != '0' else 1 for speakers_ids in permutation]\n",
    "        models_container = []\n",
    "        model_index = permutation_idx\n",
    "        for i, length_i in enumerate(speakers_models_lengths):\n",
    "            if i != len(speakers_models_lengths) - 1:\n",
    "                model_index, remainder = divmod(model_index, np.sum(speakers_models_lengths[i + 1:]))\n",
    "            else:\n",
    "                model_index = remainder\n",
    "            models_container.append(recording_data['speakers_models'][permutation[i]][self.models_generation_lengths[model_index]][0] if permutation[i] != '0' else np.random.uniform(-0.1, 0.1, len(vector)))\n",
    "        \n",
    "        models_weigths = np.asarray([len(recording_data['speakers_segments_indexes'][speakers_ids]) if speakers_ids != '0' else recording_data['speakers_segments_indexes_lengths_max'] for speakers_ids in permutation])\n",
    "        models_weigths_sum = np.sum(models_weigths)\n",
    "        models_weigths = np.ones(len(models_weigths)) - models_weigths / models_weigths_sum\n",
    "        \n",
    "        targets_ids = [speaker['speaker_id'] for speaker in segment['speakers']]\n",
    "        \n",
    "        x = [vector] + models_container\n",
    "        if self.models_container_include_overlaps:\n",
    "            targets_ids = ','.join(sorted(list(set(targets_ids))))\n",
    "            y = np.asarray([speakers_ids == targets_ids for speakers_ids in permutation], dtype = float)\n",
    "        else:\n",
    "            y = np.asarray([speaker_id in targets_ids for speaker_id in permutation], dtype = float) / len(targets_ids)\n",
    "        z = models_weigths\n",
    "        \n",
    "        return x, y, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load live_graph.py\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Live_graph:\n",
    "    def __init__(self, validation_threshold):\n",
    "        self.plt_count = -1\n",
    "        self.validation_threshold = validation_threshold\n",
    "        self.plt_thr = ([self.plt_count], [self.validation_threshold])\n",
    "        self.plt_loss = ([self.plt_count], [1])\n",
    "        self.plt_valid = ([self.plt_count], [1])\n",
    "        self.plt_test = ([self.plt_count], [1])\n",
    "        self.fig = plt.figure()\n",
    "        self.ax = self.fig.add_subplot()\n",
    "        self.line0, = self.ax.plot(self.plt_thr[0], self.plt_thr[1], 'k--', label = 'Threshold') # Threshold line\n",
    "        self.line1, = self.ax.plot(self.plt_loss[0], self.plt_loss[1], '--', label = 'Training') # Training loss\n",
    "        self.line2, = self.ax.plot(self.plt_valid[0], self.plt_valid[1], label = 'Validation')   # Validation loss\n",
    "        self.line3, = self.ax.plot(self.plt_test[0], self.plt_test[1], label = 'Test')           # Test loss\n",
    "        self.ax.set_xlabel('Epoch')\n",
    "        self.ax.set_ylabel('Loss')\n",
    "        self.ax.legend()\n",
    "        self.ax.set_xlim(-1, 0)\n",
    "        self.ax.set_ylim(0, 0.5)\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.canvas.flush_events()\n",
    "    def step(self, training, validation, test = -1):\n",
    "        self.plt_count += 1\n",
    "        self.plt_thr[0].append(self.plt_count)\n",
    "        self.plt_thr[1].append(self.validation_threshold)\n",
    "        self.plt_loss[0].append(self.plt_count)\n",
    "        self.plt_loss[1].append(training)\n",
    "        self.plt_valid[0].append(self.plt_count)\n",
    "        self.plt_valid[1].append(validation)\n",
    "        self.plt_test[0].append(self.plt_count)\n",
    "        self.plt_test[1].append(test)\n",
    "        self.line0.set_xdata(self.plt_thr[0])\n",
    "        self.line0.set_ydata(self.plt_thr[1])\n",
    "        self.line1.set_xdata(self.plt_loss[0])\n",
    "        self.line1.set_ydata(self.plt_loss[1])\n",
    "        self.line2.set_xdata(self.plt_valid[0])\n",
    "        self.line2.set_ydata(self.plt_valid[1])\n",
    "        self.line3.set_xdata(self.plt_test[0])\n",
    "        self.line3.set_ydata(self.plt_test[1])\n",
    "        self.ax.set_xlim(0, self.plt_count + 1)\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.canvas.flush_events()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, models_container_length, vector_length):\n",
    "        super().__init__()\n",
    "        n = models_container_length\n",
    "        m = vector_length\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv1d((n + 1), n ** 3, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(n ** 3, n ** 2, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(n ** 2, n, 3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.lstm1 = nn.Sequential(\n",
    "            nn.LSTM(m - 6, 32, bidirectional = True),\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(128, n * 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n * 32, n * 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n * 16, n),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = torch.stack(input, 1)\n",
    "        x = self.cnn1(x)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self):\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device('cuda:0')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "    def get_net(self,\n",
    "                recordings_segments,\n",
    "                recordings_ids = None,\n",
    "                vector = 'ivectors',\n",
    "                vector_length = 128,\n",
    "                models_container_length = 2,\n",
    "                models_container_include_zeros = True,\n",
    "                models_container_include_overlaps = False,\n",
    "                models_generation_lengths = [3],\n",
    "                models_generation_selection = 'first',\n",
    "                balance_segments = True,\n",
    "                balance_segments_selection = 'copy',\n",
    "                batch_size = 16,\n",
    "                num_workers = 8,\n",
    "                test_recordings_segments = None):\n",
    "        \n",
    "        if recordings_ids is None:\n",
    "            recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "        self.recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "\n",
    "        train_dataset = Recordings_dataset(recordings_segments,\n",
    "                                           recordings_ids, \n",
    "                                           vector,\n",
    "                                           models_container_length,\n",
    "                                           models_container_include_zeros,\n",
    "                                           models_container_include_overlaps,\n",
    "                                           models_generation_lengths,\n",
    "                                           models_generation_selection,\n",
    "                                           balance_segments,\n",
    "                                           balance_segments_selection)\n",
    "\n",
    "        train_length = int(len(train_dataset) * 0.7)\n",
    "        valid_length = len(train_dataset) - train_length\n",
    "\n",
    "        train_dataset, valid_dataset = random_split(train_dataset, [train_length, valid_length])\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle=False, num_workers = num_workers)\n",
    "        valid_dataloader = DataLoader(valid_dataset, batch_size = batch_size, num_workers = num_workers)\n",
    "        \n",
    "        if test_recordings_segments is not None:\n",
    "            test_recordings_ids = [recording_id for recording_id in test_recordings_segments]\n",
    "            test_dataset = Recordings_dataset(test_recordings_segments,\n",
    "                                              test_recordings_ids,\n",
    "                                              vector,\n",
    "                                              models_container_length,\n",
    "                                              models_container_include_zeros,\n",
    "                                              models_container_include_overlaps,\n",
    "                                              models_generation_lengths,\n",
    "                                              models_generation_selection,\n",
    "                                              balance_segments,\n",
    "                                              balance_segments_selection)\n",
    "            test_dataloader = DataLoader(test_dataset, batch_size = batch_size, num_workers = num_workers)\n",
    "\n",
    "        net = Net(models_container_length, vector_length).to(self.device)\n",
    "        optimizer = optim.Adam(net.parameters(), lr = 0.0001)\n",
    "\n",
    "        epochs = 10\n",
    "        validation_threshold = 0.05\n",
    "\n",
    "        live_graph = Live_graph(validation_threshold)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_losses = []\n",
    "            for input, target, weigth in train_dataloader:\n",
    "                input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                target = target.to(self.device, non_blocking = True).float()\n",
    "                weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                criterion = nn.BCELoss(weigth)\n",
    "                net.zero_grad()\n",
    "                output = net(input)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_losses.append(loss.data)\n",
    "                print('train: ' + str(len(train_losses)) + '/' + str(len(train_dataloader)) + '          ', end = '\\r')\n",
    "            train_loss = np.sum(train_losses) / len(train_losses)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                validation_losses = []\n",
    "                for input, target, weigth in valid_dataloader:\n",
    "                    input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                    target = target.to(self.device, non_blocking = True).float()\n",
    "                    weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                    criterion = nn.BCELoss(weigth)\n",
    "                    output = net(input)\n",
    "                    loss = criterion(output, target)\n",
    "                    validation_losses.append(loss.data)\n",
    "                    print('validation: ' + str(len(validation_losses)) + '/' + str(len(valid_dataloader)) + '          ', end = '\\r')\n",
    "                validation_loss = np.sum(validation_losses) / len(validation_losses)\n",
    "                \n",
    "                test_loss = -1\n",
    "                if test_recordings_segments is not None:\n",
    "                    test_losses = []\n",
    "                    for input, target, weigth in test_dataloader:\n",
    "                        input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                        target = target.to(self.device, non_blocking = True).float()\n",
    "                        weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                        criterion = nn.BCELoss(weigth)\n",
    "                        output = net(input)\n",
    "                        loss = criterion(output, target)\n",
    "                        test_losses.append(loss.data)\n",
    "                        print('test: ' + str(len(test_losses)) + '/' + str(len(test_dataloader)) + '          ', end = '\\r')\n",
    "                    test_loss = np.sum(test_losses) / len(test_losses)\n",
    "\n",
    "            live_graph.step(train_loss, validation_loss, test_loss)\n",
    "\n",
    "            if validation_loss <= validation_threshold:\n",
    "                print('Done training.')\n",
    "                break\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load md_eval.py\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "def md_eval(ref_filepath, res_filepath, save_dir = None):\n",
    "    bin = '../../../../tools/sctk-2.4.10/src/md-eval/md-eval.pl'\n",
    "    p = subprocess.Popen([bin, '-r', ref_filepath, '-s', res_filepath], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output, err = p.communicate()\n",
    "    rc = p.returncode\n",
    "    if rc == 0:\n",
    "        output = output.decode(\"utf-8\")\n",
    "        if save_dir is not None:\n",
    "            file = open(save_dir + '/der.log', 'w')\n",
    "            file.write(output)\n",
    "            file.close()\n",
    "        lines =  output.split('\\n')\n",
    "        derLine = [line for line in lines if 'OVERALL SPEAKER DIARIZATION ERROR' in line][0]\n",
    "        return float(re.findall('\\d+\\.\\d+', derLine)[0])\n",
    "    else:\n",
    "        exit('md-eval.pl fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eer(res_filepath, save_dir = None):\n",
    "    bin = '../eer_score.sh'\n",
    "    p = subprocess.Popen([bin, res_filepath], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output, err = p.communicate()\n",
    "    rc = p.returncode\n",
    "    if rc == 0:\n",
    "        output = output.decode(\"utf-8\")\n",
    "        if save_dir is not None:\n",
    "            file = open(save_dir + '/eer.log', 'w')\n",
    "            file.write(output)\n",
    "            file.close()\n",
    "        return float(output)\n",
    "    else:\n",
    "        exit('eer_score.sh fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcf(scores_filepath, trials_filepath, save_dir = None):\n",
    "    bin = '../sid/compute_min_dcf.py'\n",
    "    p = subprocess.Popen([bin, scores_filepath, trials_filepath], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output, err = p.communicate()\n",
    "    rc = p.returncode\n",
    "    if rc == 0:\n",
    "        output = output.decode(\"utf-8\")\n",
    "        if save_dir is not None:\n",
    "            file = open(save_dir + '/dcf.log', 'w')\n",
    "            file.write(output)\n",
    "            file.close()\n",
    "        return float(output)\n",
    "    else:\n",
    "        exit('compute_min_dcf.py fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plda_score(ref_vector, test_vector, plda_filepath):\n",
    "    ref_string = str(list(ref_vector)).replace(',', '').replace('[', '[ ').replace(']', ' ]')\n",
    "    test_string = str(list(test_vector)).replace(',', '').replace('[', '[ ').replace(']', ' ]')\n",
    "\n",
    "    bin = '../plda_score.sh'\n",
    "    p = subprocess.Popen([bin, plda_filepath, ref_string, test_string], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output, err = p.communicate()\n",
    "    rc = p.returncode\n",
    "    if rc == 0:\n",
    "        lines =  output.decode(\"utf-8\").split('\\n')\n",
    "        pldaLine = [line for line in lines if 'reference test' in line][0]\n",
    "        return float(re.findall('\\d+\\.\\d+', pldaLine)[0])\n",
    "    else:\n",
    "        print(err)\n",
    "        exit('plda_socre.sh fail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracking_tester(recordings_segments,\n",
    "                    recordings_ids = None,\n",
    "                    scoring_function = None,\n",
    "                    groundtruth_filepath = '',\n",
    "                    groundtruth_valid_speakers_ids = ['A', 'B'],\n",
    "                    vector = 'ivectors',\n",
    "                    models_container_length = 2,\n",
    "                    models_container_include_overlaps = False,\n",
    "                    models_generation_length = 3,\n",
    "                    models_generation_selection = 'first',\n",
    "                    save_dir = 'tmp'):\n",
    "\n",
    "    if recordings_ids is None:\n",
    "        recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "    recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "    recordings_ids.sort()\n",
    "    \n",
    "    results = {}\n",
    "    results_reduced = {}\n",
    "    results_rttm = ''\n",
    "    results_scores = {}\n",
    "    eer_scores = ''\n",
    "    dcf_scores = ''\n",
    "    dcf_trials = ''\n",
    "    for i, recording_id in enumerate(recordings_ids):\n",
    "        print('tracking running: recording ' + str(i + 1) + '/' + str(len(recordings_ids)), end = '\\r')\n",
    "        recording_dataset = Recordings_dataset(recordings_segments,\n",
    "                                               recording_id,\n",
    "                                               vector = vector,\n",
    "                                               models_container_length = models_container_length,\n",
    "                                               models_container_include_zeros = False,\n",
    "                                               models_container_include_overlaps = models_container_include_overlaps,\n",
    "                                               models_generation_lengths = [models_generation_length],\n",
    "                                               models_generation_selection = models_generation_selection,\n",
    "                                               balance_segments = False,\n",
    "                                               balance_segments_selection = 'copy')\n",
    "        speakers_models = recording_dataset.recordings_data[recording_id]['speakers_models']\n",
    "        speakers_ids = [speakers_ids for speakers_ids in speakers_models]\n",
    "        models_container = [speakers_models[speakers_ids][models_generation_length][0] for speakers_ids in speakers_models if models_container_include_overlaps or len(speakers_ids.split(',')) == 1]\n",
    "        for i in range(models_container_length - len(models_container)):\n",
    "            models_container.append(np.random.uniform(-0.1, 0.1, len(models_container[0])))\n",
    "        # At this point there is no information about the speaker identity, only the model\n",
    "        results[recording_id] = []\n",
    "        results_scores[recording_id] = []\n",
    "        for segment in recordings_segments[recording_id]:\n",
    "            segment_vector = np.asarray(segment[vector][0]['value'])\n",
    "            segment_vector_id = segment[vector][0]['ivector_id' if vector == 'ivectors' else 'xvector_id']\n",
    "            \n",
    "            scores = scoring_function(segment_vector, models_container)\n",
    "            \n",
    "            targets_ids = [speaker['speaker_id'] for speaker in segment['speakers']]\n",
    "            targets_ids.sort()\n",
    "            labels = ['target' if targets_ids == sorted(speaker_id.split(',')) else 'nontarget' for speaker_id in speakers_ids]\n",
    "            \n",
    "            utterances = [recording_id + '_' + speaker_id for speaker_id in speakers_ids]\n",
    "            \n",
    "            # utt1, utt2, score, target/nontarget\n",
    "            scores_labels = list(zip([segment_vector_id for speaker_id in speakers_ids], utterances, labels, scores))\n",
    "            results_scores[recording_id].append(scores_labels)\n",
    "            \n",
    "            index = np.argmax(scores)\n",
    "            results[recording_id].append({ 'begining': segment['begining'], 'ending': segment['ending'], 'speaker_id': index })\n",
    "            if len(results[recording_id]) > 2:\n",
    "                if results[recording_id][len(results[recording_id]) - 1]['speaker_id'] == results[recording_id][len(results[recording_id]) - 3]['speaker_id']:\n",
    "                    if results[recording_id][len(results[recording_id]) - 1]['speaker_id'] != results[recording_id][len(results[recording_id]) - 2]['speaker_id']:\n",
    "                        results[recording_id][len(results[recording_id]) - 2]['speaker_id'] = results[recording_id][len(results[recording_id]) - 1]['speaker_id']\n",
    "                        results[recording_id][len(results[recording_id]) - 1]['modified'] = True\n",
    "        results_reduced[recording_id] = []\n",
    "        last_speaker_id = -1\n",
    "        last_speaker = { 'begining': 0, 'ending': 0, 'speaker_id': -1 }\n",
    "        for segment in results[recording_id] + [{ 'begining': 0, 'ending': 0, 'speaker_id': -1 }]:\n",
    "            begining = segment['begining']\n",
    "            ending = segment['ending']\n",
    "            speaker_id = segment['speaker_id']\n",
    "            if last_speaker_id != speaker_id:\n",
    "                if last_speaker_id != -1:\n",
    "                    results_reduced[recording_id].append(last_speaker)\n",
    "                last_speaker_id = speaker_id\n",
    "                last_speaker = { 'begining': begining, 'ending': ending, 'speaker_id': speaker_id }\n",
    "            else:\n",
    "                if begining <= last_speaker['ending']:\n",
    "                    last_speaker['ending'] = ending\n",
    "                else:\n",
    "                    if last_speaker_id != -1:\n",
    "                        results_reduced[recording_id].append(last_speaker)\n",
    "                    last_speaker_id = speaker_id\n",
    "                    last_speaker = { 'begining': begining, 'ending': ending, 'speaker_id': speaker_id }\n",
    "        for scores_labels in results_scores[recording_id]:\n",
    "            for score_label in scores_labels:\n",
    "                # ('iaab_000-00000000-00000099', 'iaab_B', 'target', 0.9978078)\n",
    "                eer_score = '{:f}'.format(score_label[3]) + ' ' + score_label[2]\n",
    "                eer_scores += eer_score + '\\n'\n",
    "                dcf_score = score_label[0] + ' ' + score_label[1] + ' ' + '{:f}'.format(score_label[3])\n",
    "                dcf_scores += dcf_score + '\\n'\n",
    "                dcf_trial = score_label[0] + ' ' + score_label[1] + ' '+ score_label[2]\n",
    "                dcf_trials += dcf_trial + '\\n'\n",
    "        for segment in results_reduced[recording_id]:\n",
    "            result_rttm = 'SPEAKER ' + recording_id + ' 0 ' + str(segment['begining']) + ' ' + str(round(segment['ending'] - segment['begining'], 2)) + ' <NA> <NA> ' + str(segment['speaker_id']) + ' <NA> <NA>'\n",
    "            results_rttm += result_rttm + '\\n'\n",
    "    print('traking done: recording', str(i + 1) + '/' + str(len(recordings_ids)), '          ')\n",
    "\n",
    "    file = open(groundtruth_filepath, 'r')\n",
    "    groundtruth_rttm = ''.join([line for line in file.readlines() if (line.split(' ')[1] in recordings_ids) and \\\n",
    "                    (line.split(' ')[7] in groundtruth_valid_speakers_ids)])\n",
    "    file.close()\n",
    "    \n",
    "    !mkdir -p $save_dir\n",
    "    \n",
    "    file = open(save_dir + '/eer.scores', 'w')\n",
    "    file.write(eer_scores)\n",
    "    file.close()\n",
    "    \n",
    "    file = open(save_dir + '/dcf.scores', 'w')\n",
    "    file.write(dcf_scores)\n",
    "    file.close()\n",
    "    \n",
    "    file = open(save_dir + '/dcf.trials', 'w')\n",
    "    file.write(dcf_trials)\n",
    "    file.close()\n",
    "    \n",
    "    file = open(save_dir + '/groundtruth.rttm', 'w')\n",
    "    file.write(groundtruth_rttm)\n",
    "    file.close()\n",
    "    \n",
    "    file = open(save_dir + '/results.rttm', 'w')\n",
    "    file.write(results_rttm)\n",
    "    file.close()\n",
    "    \n",
    "    output_der = md_eval(save_dir + '/groundtruth.rttm', save_dir + '/results.rttm', save_dir)\n",
    "    output_eer = eer('notebooks/' + save_dir + '/eer.scores', save_dir)\n",
    "    output_dcf = dcf(save_dir + '/dcf.scores', save_dir + '/dcf.trials', save_dir)\n",
    "\n",
    "    return { 'der': output_der, 'eer': output_eer, 'dcf': output_dcf }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading recordings segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_directory = '../exp/augmented2/callhome1/json'\n",
    "a_groundtruth = '../exp/augmented2/callhome1/segments_augmented_1.0_0.5_ABZ.rttm'\n",
    "b_directory = '../exp/augmented2/callhome2/json'\n",
    "b_groundtruth = '../exp/augmented2/callhome2/segments_augmented_1.0_0.5_ABZ.rttm'\n",
    "maximum_speakers_length = 1\n",
    "valid_speakers_ids = ['A', 'B']\n",
    "models_container_length = 2\n",
    "models_container_include_zeros = True\n",
    "models_container_include_overlaps = False\n",
    "models_generation_selection = 'first'\n",
    "balance_segments_selection = 'copy'\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../exp/augmented/callhome1/json loaded 249/249, 0.56 segments left.\n",
      "../exp/augmented/callhome2/json loaded 250/250, 0.58 segments left.\n"
     ]
    }
   ],
   "source": [
    "a_recordings_segments = load_recordings_segments(a_directory,\n",
    "  lambda segment: is_valid_segment(segment, maximum_speakers_length, valid_speakers_ids))\n",
    "b_recordings_segments = load_recordings_segments(b_directory,\n",
    "  lambda segment: is_valid_segment(segment, maximum_speakers_length, valid_speakers_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../exp/augmented/callhome1/json loaded 249/249, 0.56 segments left.\n",
      "../exp/augmented/callhome2/json loaded 250/250, 0.58 segments left.\n"
     ]
    }
   ],
   "source": [
    "a_recordings_test_segments = load_recordings_segments(a_directory,\n",
    "  lambda segment: is_valid_segment(segment, maximum_speakers_length, valid_speakers_ids))\n",
    "b_recordings_test_segments = load_recordings_segments(b_directory,\n",
    "  lambda segment: is_valid_segment(segment, maximum_speakers_length, valid_speakers_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_selector(vector, models_container, net):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    with torch.no_grad():\n",
    "        input = [torch.Tensor([nparray]).to(device, non_blocking = True).float() for nparray in [vector] + models_container]\n",
    "        output = net(input)\n",
    "        return output.cpu().data.numpy()[0]\n",
    "    \n",
    "def plda_selector(vector, models_container, plda_filepath):\n",
    "    return [plda_score(ref_vector, vector, plda_filepath) for ref_vector in models_container]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ivectors 128 20 0\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training.22/2022          \n",
      "traking done: recording 249/249           \n",
      "traking done: recording 250/250           \n",
      "{'der': 3.99, 'eer': 2.374, 'dcf': 0.3548}\n",
      "{'der': 4.79, 'eer': 2.704, 'dcf': 0.3583}\n",
      "{'der': 4.390000000000001, 'eer': 2.539, 'dcf': 0.35655000000000003}\n"
     ]
    }
   ],
   "source": [
    "for vector in ['ivectors']:\n",
    "    vector_length = 128 if vector == 'ivectors' else 128\n",
    "    for models_generation_length in [20]:\n",
    "        for i in range(1):\n",
    "            print(vector, vector_length, models_generation_length, i)\n",
    "            a_trainer = Trainer()\n",
    "            a_net = a_trainer.get_net(a_recordings_segments,\n",
    "                                      vector = vector,\n",
    "                                      vector_length = vector_length,\n",
    "                                      models_container_length = models_container_length,\n",
    "                                      models_container_include_zeros = models_container_include_zeros,\n",
    "                                      models_container_include_overlaps = models_container_include_overlaps,\n",
    "                                      models_generation_lengths = [models_generation_length],\n",
    "                                      models_generation_selection = models_generation_selection,\n",
    "                                      balance_segments_selection = balance_segments_selection,\n",
    "                                      batch_size = batch_size)\n",
    "            '''b_trainer = Trainer()\n",
    "            b_net = b_trainer.get_net(b_recordings_segments,\n",
    "                                      vector = vector,\n",
    "                                      vector_length = vector_length,\n",
    "                                      models_container_length = models_container_length,\n",
    "                                      models_container_include_zeros = models_container_include_zeros,\n",
    "                                      models_container_include_overlaps = models_container_include_overlaps,\n",
    "                                      models_generation_lengths = [models_generation_length],\n",
    "                                      models_generation_selection = models_generation_selection,\n",
    "                                      balance_segments_selection = balance_segments_selection,\n",
    "                                      batch_size = batch_size)'''\n",
    "            \n",
    "            test_id = 'dihard2019_lstm32_' + vector + '_' + str(models_generation_length) + '_' + str(i)\n",
    "            \n",
    "            a_results = tracking_tester(a_recordings_test_segments,\n",
    "                                        scoring_function = lambda vector, models_container: net_selector(vector, models_container, b_net),\n",
    "                                        groundtruth_filepath = a_groundtruth,\n",
    "                                        groundtruth_valid_speakers_ids = ['A', 'B'],\n",
    "                                        vector = vector,\n",
    "                                        models_container_length = models_container_length,\n",
    "                                        models_container_include_overlaps = models_container_include_overlaps,\n",
    "                                        models_generation_length = models_generation_length,\n",
    "                                        models_generation_selection = models_generation_selection,\n",
    "                                        save_dir = 'batch/' + test_id + '_a')\n",
    "        \n",
    "\n",
    "            b_results = tracking_tester(b_recordings_test_segments,\n",
    "                                        scoring_function = lambda vector, models_container: net_selector(vector, models_container, a_net),\n",
    "                                        groundtruth_filepath = b_groundtruth,\n",
    "                                        groundtruth_valid_speakers_ids = ['A', 'B'],\n",
    "                                        vector = vector,\n",
    "                                        models_container_length = models_container_length,\n",
    "                                        models_container_include_overlaps = models_container_include_overlaps,\n",
    "                                        models_generation_length = models_generation_length,\n",
    "                                        models_generation_selection = models_generation_selection,\n",
    "                                        save_dir = 'batch/' + test_id + '_b')\n",
    "            \n",
    "            print(a_results)\n",
    "            print(b_results)\n",
    "            output_der = (a_results['der'] + b_results['der']) / 2\n",
    "            output_eer = (a_results['eer'] + b_results['eer']) / 2\n",
    "            output_dcf = (a_results['dcf'] + b_results['dcf']) / 2\n",
    "            results = { 'der': output_der, 'eer': output_eer, 'dcf': output_dcf }\n",
    "            print(results)\n",
    "            \n",
    "            file = open('batch/results.csv', 'a')\n",
    "            file.write(test_id + ', ' + json.dumps(a_results) + ', ' + json.dumps(b_results) + ', ' + json.dumps(results) + '\\n')\n",
    "            file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"tracking_tester(b_recordings_segments,\\n                scoring_function = lambda vector, models_container: plda_selector(vector,\\n                                                                                  models_container,\\n                                                                                  'exp/plda/callhome1/ivectors.plda'),\\n                groundtruth_filepath = '../data/callhome2_1.0_0.5.rttm',\\n                groundtruth_valid_speakers_ids = ['A', 'B'],\\n                vector = vector,\\n                models_container_length = models_container_length,\\n                models_container_include_overlaps = models_container_include_overlaps,\\n                models_generation_length = models_generation_length,\\n                models_generation_selection = models_generation_selection)\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''tracking_tester(b_recordings_segments,\n",
    "                scoring_function = lambda vector, models_container: plda_selector(vector,\n",
    "                                                                                  models_container,\n",
    "                                                                                  'exp/plda/callhome1/ivectors.plda'),\n",
    "                groundtruth_filepath = '../data/callhome2_1.0_0.5.rttm',\n",
    "                groundtruth_valid_speakers_ids = ['A', 'B'],\n",
    "                vector = vector,\n",
    "                models_container_length = models_container_length,\n",
    "                models_container_include_overlaps = models_container_include_overlaps,\n",
    "                models_generation_length = models_generation_length,\n",
    "                models_generation_selection = models_generation_selection)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
