{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recordings segments loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from functools import reduce\n",
    "\n",
    "# is_single_speaker_segment [VALIDATED]\n",
    "# validates if a segment has a single speaker who belongs to the speakers list. \n",
    "def is_single_speaker_segment(segment, valid_speakers_ids = ['A', 'B']):\n",
    "    return len(segment['speakers']) == 1 and segment['speakers'][0]['speaker_id'] in valid_speakers_ids\n",
    "\n",
    "# is_valid_segment [VALIDATED]\n",
    "# validates if a segment meets a maximum number of speakers,\n",
    "# and that all the speakers in the segment belong to a list.\n",
    "def is_valid_segment(segment, maximum_speakers_length = 2, valid_speakers_ids = ['A', 'B']):\n",
    "    speakers_ids = [speaker['speaker_id'] for speaker in segment['speakers']]\n",
    "    speakers_ids = list(set(speakers_ids))\n",
    "    return len(speakers_ids) <= maximum_speakers_length and \\\n",
    "        all(speaker_id in valid_speakers_ids for speaker_id in speakers_ids)\n",
    "\n",
    "# load_recordings_segments [VALIDATED]\n",
    "# loads the recordings segments data from the .json files located in a directory \n",
    "def load_recordings_segments(directory, validation_function):\n",
    "    filenames = [filename for filename in os.listdir(directory) if os.path.isfile(os.path.join(directory, filename))]\n",
    "    filenames.sort()\n",
    "    recordings_segments = {}\n",
    "    recordings_length = len(filenames)\n",
    "    recordings_count = 0\n",
    "    segments_original = 0\n",
    "    segments_filtered = 0\n",
    "    for filename in filenames:\n",
    "        recording_id = filename.split('.')[0]\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        file = open(filepath, 'r')\n",
    "        recordings_segments[recording_id] = [json.loads(line) for line in file.readlines()]\n",
    "        file.close()\n",
    "        segments_original += len(recordings_segments[recording_id])\n",
    "        recordings_segments[recording_id] = list(filter(validation_function, recordings_segments[recording_id]))\n",
    "        segments_filtered += len(recordings_segments[recording_id])\n",
    "        recordings_count += 1\n",
    "        print(directory + ' loading ' + str(recordings_count) + '/' + str(recordings_length), end = '\\r')\n",
    "    print(directory, 'loaded', str(recordings_count) + '/' + str(recordings_length) + ',', round(segments_filtered / segments_original, 2), 'segments left.')\n",
    "    return recordings_segments\n",
    "\n",
    "# speakers_get_indexes [VALIDATED]\n",
    "# used to convert a (speakers_ids, index) list to a speakers_ids => [indexes] dictionary\n",
    "def speakers_get_indexes(accumulator, speakers_tuple):\n",
    "    speaker_ids, index = speakers_tuple\n",
    "    speaker_ids = ','.join(speaker_ids)\n",
    "    if speaker_ids in accumulator:\n",
    "        accumulator[speaker_ids].append(index)\n",
    "    else:\n",
    "        accumulator[speaker_ids] = [index]\n",
    "    return accumulator\n",
    "\n",
    "# balance_segments [VALIDATED]\n",
    "# balances the recording segments data to meet a minimum of speakers per recording,\n",
    "# and a minimum of segments per speaker.\n",
    "def balance_segments(recordings_segments,\n",
    "                     minimum_speakers_length = 2,\n",
    "                     minimum_speaker_segments = 3,\n",
    "                     include_overlaps = False):\n",
    "    new_recordings_segments = {}\n",
    "    for recording_id in recordings_segments:\n",
    "        recording_segments = recordings_segments[recording_id]\n",
    "        # ----- Obtaining speakers indexes ----- #\n",
    "        speakers_indexes = [(sorted(list(set([speaker['speaker_id'] for speaker in segment['speakers']]))), index) for index, segment in enumerate(recording_segments)]\n",
    "        speakers_indexes = reduce(speakers_get_indexes, speakers_indexes, {})\n",
    "        # ----- Removing overlaps ----- #\n",
    "        if not include_overlaps:\n",
    "            for speakers_ids in list(speakers_indexes.keys()):\n",
    "                if len(speakers_ids.split(',')) > 1:\n",
    "                    del speakers_indexes[speakers_ids]\n",
    "        speakers_lengths = [(speakers_ids, len(speakers_indexes[speakers_ids])) for speakers_ids in speakers_indexes]\n",
    "        speakers_lengths.sort(key = lambda x: x[1])\n",
    "        speakers_lengths_min = speakers_lengths[0][1]\n",
    "        if len(speakers_lengths) >= minimum_speakers_length and speakers_lengths_min >= minimum_speaker_segments:\n",
    "            recording_indexes = []\n",
    "            for speakers_ids in speakers_indexes:\n",
    "                speakers_indexes[speakers_ids] = speakers_indexes[speakers_ids][:speakers_lengths_min]\n",
    "                recording_indexes += speakers_indexes[speakers_ids]\n",
    "            new_recordings_segments[recording_id] = [segment for index, segment in enumerate(recordings_segments[recording_id]) if index in recording_indexes]\n",
    "    print('Recordings left: ' + str(len(new_recordings_segments)) + '/' + str(len(recordings_segments)))\n",
    "    return new_recordings_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recordings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def generate_speaker_model(recording_segments,\n",
    "                           speaker_indexes,\n",
    "                           segments_length,\n",
    "                           vector = 'ivectors',\n",
    "                           selection = 'first',\n",
    "                           indexes = []):\n",
    "    #if segments_length > len(speaker_indexes):\n",
    "    #    print('WARNING: there are less speaker indexes than segments.')\n",
    "    if selection == 'first':\n",
    "        selected_segments = [segment for index, segment in enumerate(recording_segments) if index in speaker_indexes[:segments_length]]\n",
    "    elif selection == 'random':\n",
    "        selected_segments = [recording_segments[index] for index in random.sample(speaker_indexes, segments_length if segments_length < len(speaker_indexes) else len(speaker_indexes))]\n",
    "    elif selection == 'indexes':\n",
    "        selected_segments = [recording_segments[index] for index in indexes]\n",
    "    else:\n",
    "        print('ERROR: unknown speaker model segments selection strategy.')\n",
    "    selected_vectors = [np.asarray(segment[vector][0]['value']) for segment in selected_segments]\n",
    "    return np.sum(selected_vectors, 0) / len(selected_vectors)\n",
    "    \n",
    "\n",
    "class Recordings_dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 recordings_segments,\n",
    "                 recordings_ids = None,\n",
    "                 vector = 'ivectors',\n",
    "                 models_container_length = 2,\n",
    "                 models_container_include_zeros = True,\n",
    "                 models_container_include_overlaps = False,\n",
    "                 models_generation_lengths = [3],\n",
    "                 models_generation_selection = 'first',\n",
    "                 balance_segments = True,\n",
    "                 balance_segments_selection = 'copy'):\n",
    "        # -----------------------------------------------------Saving input data----- #\n",
    "        if recordings_ids is None:\n",
    "            recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "        self.recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "        self.recordings_segments = {}\n",
    "        for recording_id in self.recordings_ids:\n",
    "            self.recordings_segments[recording_id] = recordings_segments[recording_id]\n",
    "        self.vector = vector\n",
    "        self.models_container_length = models_container_length\n",
    "        self.models_container_include_zeros = models_container_include_zeros\n",
    "        self.models_container_include_overlaps = models_container_include_overlaps\n",
    "        self.models_generation_lengths = models_generation_lengths\n",
    "        self.models_generation_selection = models_generation_selection\n",
    "        self.balance_segments = balance_segments\n",
    "        self.balance_segments_selection = balance_segments_selection\n",
    "        # --------------------------------------------------------------------------- #\n",
    "        self.recordings_data = {}\n",
    "        # -------------------------------------------------- #\n",
    "        self.recordings_map = []\n",
    "        self.recordings_length = 0\n",
    "        for recording_id in self.recordings_ids:\n",
    "            self.recordings_data[recording_id] = {}\n",
    "            recording_segments = self.recordings_segments[recording_id]\n",
    "            recording_data = self.recordings_data[recording_id]\n",
    "            # ----- Obtaining speakers indexes ----- #\n",
    "            recording_data['speakers_indexes'] = [(sorted(list(set([speaker['speaker_id'] for speaker in segment['speakers']]))), index) for index, segment in enumerate(recording_segments)]\n",
    "            recording_data['speakers_indexes'] = reduce(speakers_get_indexes, recording_data['speakers_indexes'], {})\n",
    "            # ----- Balancing speakers segments ----- #\n",
    "            recording_data['speakers_indexes_lengths_max'] = max([len(recording_data['speakers_indexes'][speakers_ids]) for speakers_ids in recording_data['speakers_indexes']])\n",
    "            if self.balance_segments:\n",
    "                if self.balance_segments_selection == 'copy':\n",
    "                    for speakers_ids in recording_data['speakers_indexes']:\n",
    "                        for i in range(recording_data['speakers_indexes_lengths_max'] - len(recording_data['speakers_indexes'][speakers_ids])):\n",
    "                            index = random.choice(recording_data['speakers_indexes'][speakers_ids])\n",
    "                            recording_segments.append(recording_segments[index])\n",
    "                            recording_data['speakers_indexes'][speakers_ids].append(len(recording_segments) - 1)\n",
    "                else:\n",
    "                    print('ERROR: unknown balancing segments selection strategy.')\n",
    "            # ----- Generating speakers models ----- #\n",
    "            recording_data['speakers_models'] = {}\n",
    "            for speakers_ids in recording_data['speakers_indexes']:\n",
    "                recording_data['speakers_models'][speakers_ids] = {}\n",
    "                for models_generation_length in models_generation_lengths:\n",
    "                    speakers_model = generate_speaker_model(recording_segments, recording_data['speakers_indexes'][speakers_ids], models_generation_length, self.vector, self.models_generation_selection)\n",
    "                    recording_data['speakers_models'][speakers_ids][models_generation_length] = [speakers_model]\n",
    "            # ----- Generating permutations ----- #\n",
    "            if self.models_container_include_zeros:\n",
    "                recording_data['permutations'] = list(itertools.permutations(list(recording_data['speakers_models'].keys()) \\\n",
    "                + ['0' for i in range(self.models_container_length)], self.models_container_length))\n",
    "            else:\n",
    "                recording_data['permutations'] = list(itertools.permutations(list(recording_data['speakers_models'].keys()), self.models_container_length))\n",
    "            recording_data['permutations'] = list(set(recording_data['permutations']))\n",
    "            recording_data['permutations'].sort()\n",
    "            if not self.models_container_include_overlaps:\n",
    "                recording_data['permutations'] = [permutation for permutation in recording_data['permutations'] if all(len(speakers_ids.split(',')) == 1 for speakers_ids in permutation)]\n",
    "            # -------------------------------------------------- #\n",
    "            recording_data['permutations_map'] = []\n",
    "            recording_data['permutations_length'] = 0\n",
    "            for index, permutation in enumerate(recording_data['permutations']):\n",
    "                speakers_models_length = int(np.prod([np.sum([len(recording_data['speakers_models'][speakers_ids][models_generation_length]) for models_generation_length in recording_data['speakers_models'][speakers_ids]]) for speakers_ids in permutation if speakers_ids != '0']))\n",
    "                recording_data['permutations_map'].append((recording_data['permutations_length'], recording_data['permutations_length'] + speakers_models_length - 1, index))\n",
    "                recording_data['permutations_length'] += speakers_models_length\n",
    "            recording_data['length'] = len(recording_segments) * recording_data['permutations_length']\n",
    "            self.recordings_map.append((self.recordings_length, self.recordings_length + recording_data['length'] - 1, recording_id))\n",
    "            self.recordings_length += recording_data['length']\n",
    "    def __len__(self):\n",
    "        return self.recordings_length\n",
    "    def __getitem__(self, idx):\n",
    "        recording_limits = list(filter(lambda recording_limits: recording_limits[0] <= idx and idx <= recording_limits[1], self.recordings_map))[0]\n",
    "        recording_idx = idx - recording_limits[0]\n",
    "        recording_id = recording_limits[2]\n",
    "        recording_data = self.recordings_data[recording_id]\n",
    "        \n",
    "        segment_index, segment_idx = divmod(recording_idx, recording_data['permutations_length'])\n",
    "        segment = self.recordings_segments[recording_id][segment_index]\n",
    "        vector = np.asarray(segment[self.vector][0]['value'])\n",
    "        \n",
    "        permutation_limits = list(filter(lambda permutation_limits: permutation_limits[0] <= segment_idx and segment_idx <= permutation_limits[1], recording_data['permutations_map']))[0]\n",
    "        permutation_idx = segment_idx - permutation_limits[0]\n",
    "        permutation_index = permutation_limits[2]\n",
    "        permutation = recording_data['permutations'][permutation_index]\n",
    "        \n",
    "        speakers_models_lengths = [np.sum([len(recording_data['speakers_models'][speakers_ids][models_generation_length]) for models_generation_length in recording_data['speakers_models'][speakers_ids]])  if speakers_ids != '0' else 1 for speakers_ids in permutation]\n",
    "        models_container = []\n",
    "        model_index = permutation_idx\n",
    "        for i, length_i in enumerate(speakers_models_lengths):\n",
    "            if i != len(speakers_models_lengths) - 1:\n",
    "                model_index, remainder = divmod(model_index, np.sum(speakers_models_lengths[i + 1:]))\n",
    "            else:\n",
    "                model_index = remainder\n",
    "            models_container.append(recording_data['speakers_models'][permutation[i]][self.models_generation_lengths[model_index]][0] if permutation[i] != '0' else np.random.uniform(-0.1, 0.1, len(vector)))\n",
    "        \n",
    "        models_weigths = np.asarray([len(recording_data['speakers_indexes'][speakers_ids]) if speakers_ids != '0' else recording_data['speakers_indexes_lengths_max'] for speakers_ids in permutation])\n",
    "        models_weigths_sum = np.sum(models_weigths)\n",
    "        models_weigths = np.ones(len(models_weigths)) - models_weigths / models_weigths_sum\n",
    "        \n",
    "        targets_ids = [speaker['speaker_id'] for speaker in segment['speakers']]\n",
    "        \n",
    "        x = [vector] + models_container\n",
    "        if self.models_container_include_overlaps:\n",
    "            targets_ids = ','.join(sorted(list(set(targets_ids))))\n",
    "            y = np.asarray([speakers_ids == targets_ids for speakers_ids in permutation], dtype = float)\n",
    "        else:\n",
    "            y = np.asarray([speaker_id in targets_ids for speaker_id in permutation], dtype = float) / len(targets_ids)\n",
    "        z = models_weigths\n",
    "        \n",
    "        return x, y, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load live_graph.py\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Live_graph:\n",
    "    def __init__(self, validation_threshold):\n",
    "        self.plt_count = -1\n",
    "        self.validation_threshold = validation_threshold\n",
    "        self.plt_thr = ([self.plt_count], [self.validation_threshold])\n",
    "        self.plt_loss = ([self.plt_count], [1])\n",
    "        self.plt_valid = ([self.plt_count], [1])\n",
    "        self.plt_test = ([self.plt_count], [1])\n",
    "        self.fig = plt.figure()\n",
    "        self.ax = self.fig.add_subplot()\n",
    "        self.line0, = self.ax.plot(self.plt_thr[0], self.plt_thr[1], 'k--', label = 'Threshold') # Threshold line\n",
    "        self.line1, = self.ax.plot(self.plt_loss[0], self.plt_loss[1], '--', label = 'Training') # Training loss\n",
    "        self.line2, = self.ax.plot(self.plt_valid[0], self.plt_valid[1], label = 'Validation')   # Validation loss\n",
    "        self.line3, = self.ax.plot(self.plt_test[0], self.plt_test[1], label = 'Test')           # Test loss\n",
    "        self.ax.set_xlabel('Epoch')\n",
    "        self.ax.set_ylabel('Loss')\n",
    "        self.ax.legend()\n",
    "        self.ax.set_xlim(-1, 0)\n",
    "        self.ax.set_ylim(0, 0.5)\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.canvas.flush_events()\n",
    "    def step(self, training, validation, test = -1):\n",
    "        self.plt_count += 1\n",
    "        self.plt_thr[0].append(self.plt_count)\n",
    "        self.plt_thr[1].append(self.validation_threshold)\n",
    "        self.plt_loss[0].append(self.plt_count)\n",
    "        self.plt_loss[1].append(training)\n",
    "        self.plt_valid[0].append(self.plt_count)\n",
    "        self.plt_valid[1].append(validation)\n",
    "        self.plt_test[0].append(self.plt_count)\n",
    "        self.plt_test[1].append(test)\n",
    "        self.line0.set_xdata(self.plt_thr[0])\n",
    "        self.line0.set_ydata(self.plt_thr[1])\n",
    "        self.line1.set_xdata(self.plt_loss[0])\n",
    "        self.line1.set_ydata(self.plt_loss[1])\n",
    "        self.line2.set_xdata(self.plt_valid[0])\n",
    "        self.line2.set_ydata(self.plt_valid[1])\n",
    "        self.line3.set_xdata(self.plt_test[0])\n",
    "        self.line3.set_ydata(self.plt_test[1])\n",
    "        self.ax.set_xlim(0, self.plt_count + 1)\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.canvas.flush_events()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, models_container_length, vector_length):\n",
    "        super().__init__()\n",
    "        n = models_container_length\n",
    "        m = vector_length\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv1d((n + 1), n ** 3, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(n ** 3, n ** 2, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(n ** 2, n, 3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(n * (m - 6), n * 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n * 16, n * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n * 4, n),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = torch.stack(input, 1)\n",
    "        x = self.cnn1(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self):\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device('cuda:0')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "    def get_net(self,\n",
    "                recordings_segments,\n",
    "                recordings_ids = None,\n",
    "                vector = 'ivectors',\n",
    "                vector_length = 128,\n",
    "                models_container_length = 2,\n",
    "                models_container_include_zeros = True,\n",
    "                models_container_include_overlaps = False,\n",
    "                models_generation_lengths = [3],\n",
    "                models_generation_selection = 'first',\n",
    "                balance_segments = True,\n",
    "                balance_segments_selection = 'copy',\n",
    "                batch_size = 16,\n",
    "                num_workers = 8,\n",
    "                test_recordings_segments = None):\n",
    "        \n",
    "        if recordings_ids is None:\n",
    "            recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "        self.recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "\n",
    "        train_dataset = Recordings_dataset(recordings_segments,\n",
    "                                           recordings_ids, \n",
    "                                           vector,\n",
    "                                           models_container_length,\n",
    "                                           models_container_include_zeros,\n",
    "                                           models_container_include_overlaps,\n",
    "                                           models_generation_lengths,\n",
    "                                           models_generation_selection,\n",
    "                                           balance_segments,\n",
    "                                           balance_segments_selection)\n",
    "\n",
    "        train_length = int(len(train_dataset) * 0.7)\n",
    "        valid_length = len(train_dataset) - train_length\n",
    "\n",
    "        train_dataset, valid_dataset = random_split(train_dataset, [train_length, valid_length])\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers = num_workers)\n",
    "        valid_dataloader = DataLoader(valid_dataset, batch_size = batch_size, num_workers = num_workers)\n",
    "        \n",
    "        if test_recordings_segments is not None:\n",
    "            test_recordings_ids = [recording_id for recording_id in test_recordings_segments]\n",
    "            test_dataset = Recordings_dataset(test_recordings_segments,\n",
    "                                              test_recordings_ids,\n",
    "                                              vector,\n",
    "                                              models_container_length,\n",
    "                                              models_container_include_zeros,\n",
    "                                              models_container_include_overlaps,\n",
    "                                              models_generation_lengths,\n",
    "                                              models_generation_selection,\n",
    "                                              balance_segments,\n",
    "                                              balance_segments_selection)\n",
    "            test_dataloader = DataLoader(test_dataset, batch_size = batch_size, num_workers = num_workers)\n",
    "\n",
    "        net = Net(models_container_length, vector_length).to(self.device)\n",
    "        optimizer = optim.Adam(net.parameters(), lr = 0.0001)\n",
    "\n",
    "        epochs = 30\n",
    "        validation_threshold = 0.06\n",
    "\n",
    "        live_graph = Live_graph(validation_threshold)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_losses = []\n",
    "            for input, target, weigth in train_dataloader:\n",
    "                input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                target = target.to(self.device, non_blocking = True).float()\n",
    "                weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                criterion = nn.BCELoss(weigth)\n",
    "                net.zero_grad()\n",
    "                output = net(input)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_losses.append(loss.data)\n",
    "                print('train: ' + str(len(train_losses)) + '/' + str(len(train_dataloader)) + '          ', end = '\\r')\n",
    "            train_loss = np.sum(train_losses) / len(train_losses)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                validation_losses = []\n",
    "                for input, target, weigth in valid_dataloader:\n",
    "                    input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                    target = target.to(self.device, non_blocking = True).float()\n",
    "                    weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                    criterion = nn.BCELoss(weigth)\n",
    "                    output = net(input)\n",
    "                    loss = criterion(output, target)\n",
    "                    validation_losses.append(loss.data)\n",
    "                    print('validation: ' + str(len(validation_losses)) + '/' + str(len(valid_dataloader)) + '          ', end = '\\r')\n",
    "                validation_loss = np.sum(validation_losses) / len(validation_losses)\n",
    "                \n",
    "                test_loss = -1\n",
    "                if test_recordings_segments is not None:\n",
    "                    test_losses = []\n",
    "                    for input, target, weigth in test_dataloader:\n",
    "                        input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                        target = target.to(self.device, non_blocking = True).float()\n",
    "                        weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                        criterion = nn.BCELoss(weigth)\n",
    "                        output = net(input)\n",
    "                        loss = criterion(output, target)\n",
    "                        test_losses.append(loss.data)\n",
    "                        print('test: ' + str(len(test_losses)) + '/' + str(len(test_dataloader)) + '          ', end = '\\r')\n",
    "                    test_loss = np.sum(test_losses) / len(test_losses)\n",
    "\n",
    "            live_graph.step(train_loss, validation_loss, test_loss)\n",
    "\n",
    "            if validation_loss <= validation_threshold:\n",
    "                print('Done training.')\n",
    "                break\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load md_eval.py\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "def md_eval(ref_filepath, res_filepath, save_filepath = None):\n",
    "    bin = '../../../../tools/sctk-2.4.10/src/md-eval/md-eval.pl'\n",
    "    p = subprocess.Popen([bin, '-r', ref_filepath, '-s', res_filepath], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output, err = p.communicate()\n",
    "    rc = p.returncode\n",
    "    if rc == 0:\n",
    "        output = output.decode(\"utf-8\")\n",
    "        if save_filepath is not None:\n",
    "            file = open(save_filepath, 'w')\n",
    "            file.write(output)\n",
    "            file.close()\n",
    "        lines =  output.split('\\n')\n",
    "        derLine = [line for line in lines if 'OVERALL SPEAKER DIARIZATION ERROR' in line][0]\n",
    "        return float(re.findall('\\d+\\.\\d+', derLine)[0])\n",
    "    else:\n",
    "        exit('md-eval.pl fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eer(res_filepath):\n",
    "    bin = '../eer_score.sh'\n",
    "    p = subprocess.Popen([bin, res_filepath], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output, err = p.communicate()\n",
    "    rc = p.returncode\n",
    "    if rc == 0:\n",
    "        output = output.decode(\"utf-8\")\n",
    "        return float(output)\n",
    "    else:\n",
    "        exit('eer_score.sh fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcf(scores_filepath, trials_filepath):\n",
    "    bin = '../sid/compute_min_dcf.py'\n",
    "    p = subprocess.Popen([bin, scores_filepath, trials_filepath], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output, err = p.communicate()\n",
    "    rc = p.returncode\n",
    "    if rc == 0:\n",
    "        output = output.decode(\"utf-8\")\n",
    "        return float(output)\n",
    "    else:\n",
    "        exit('compute_min_dcf.py fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plda_score(ref_vector, test_vector, plda_filepath):\n",
    "    ref_string = str(list(ref_vector)).replace(',', '').replace('[', '[ ').replace(']', ' ]')\n",
    "    test_string = str(list(test_vector)).replace(',', '').replace('[', '[ ').replace(']', ' ]')\n",
    "\n",
    "    bin = '../plda_score.sh'\n",
    "    p = subprocess.Popen([bin, plda_filepath, ref_string, test_string], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output, err = p.communicate()\n",
    "    rc = p.returncode\n",
    "    if rc == 0:\n",
    "        lines =  output.decode(\"utf-8\").split('\\n')\n",
    "        pldaLine = [line for line in lines if 'reference test' in line][0]\n",
    "        return float(re.findall('\\d+\\.\\d+', pldaLine)[0])\n",
    "    else:\n",
    "        print(err)\n",
    "        exit('plda_socre.sh fail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracking_tester(recordings_segments,\n",
    "                    recordings_ids = None,\n",
    "                    scoring_function = None,\n",
    "                    groundtruth_filepath = '',\n",
    "                    groundtruth_valid_speakers_ids = ['A', 'B'],\n",
    "                    vector = 'ivectors',\n",
    "                    models_container_length = 2,\n",
    "                    models_container_include_overlaps = False,\n",
    "                    models_generation_length = 3,\n",
    "                    models_generation_selection = 'first'):\n",
    "\n",
    "    if recordings_ids is None:\n",
    "        recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "    recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "    recordings_ids.sort()\n",
    "    \n",
    "    results = {}\n",
    "    results_reduced = {}\n",
    "    results_rttm = ''\n",
    "    results_scores = {}\n",
    "    eer_scores = ''\n",
    "    dcf_scores = ''\n",
    "    dcf_trials = ''\n",
    "    for i, recording_id in enumerate(recordings_ids):\n",
    "        print('tracking running: recording ' + str(i + 1) + '/' + str(len(recordings_ids)), end = '\\r')\n",
    "        recording_dataset = Recordings_dataset(recordings_segments,\n",
    "                                               recording_id,\n",
    "                                               vector = vector,\n",
    "                                               models_container_length = models_container_length,\n",
    "                                               models_container_include_zeros = False,\n",
    "                                               models_container_include_overlaps = models_container_include_overlaps,\n",
    "                                               models_generation_lengths = [models_generation_length],\n",
    "                                               models_generation_selection = models_generation_selection,\n",
    "                                               balance_segments = False,\n",
    "                                               balance_segments_selection = 'copy')\n",
    "        speakers_models = recording_dataset.recordings_data[recording_id]['speakers_models']\n",
    "        speakers_ids = [speakers_ids for speakers_ids in speakers_models]\n",
    "        models_container = [speakers_models[speakers_ids][models_generation_length][0] for speakers_ids in speakers_models if models_container_include_overlaps or len(speakers_ids.split(',')) == 1]\n",
    "        for i in range(models_container_length - len(models_container)):\n",
    "            models_container.append(np.random.uniform(-0.1, 0.1, len(models_container[0])))\n",
    "        # At this point there is no information about the speaker identity, only the model\n",
    "        results[recording_id] = []\n",
    "        results_scores[recording_id] = []\n",
    "        for segment in recordings_segments[recording_id]:\n",
    "            segment_vector = np.asarray(segment[vector][0]['value'])\n",
    "            segment_vector_id = segment[vector][0]['ivector_id' if vector == 'ivectors' else 'xvector_id']\n",
    "            \n",
    "            scores = scoring_function(segment_vector, models_container)\n",
    "            \n",
    "            targets_ids = [speaker['speaker_id'] for speaker in segment['speakers']]\n",
    "            targets_ids.sort()\n",
    "            labels = ['target' if targets_ids == sorted(speaker_id.split(',')) else 'nontarget' for speaker_id in speakers_ids]\n",
    "            \n",
    "            utterances = [recording_id + '_' + speaker_id for speaker_id in speakers_ids]\n",
    "            \n",
    "            # utt1, utt2, score, target/nontarget\n",
    "            scores_labels = list(zip([segment_vector_id for speaker_id in speakers_ids], utterances, labels, scores))\n",
    "            results_scores[recording_id].append(scores_labels)\n",
    "            \n",
    "            index = np.argmax(scores)\n",
    "            results[recording_id].append({ 'begining': segment['begining'], 'ending': segment['ending'], 'speaker_id': index })\n",
    "            if len(results[recording_id]) > 2:\n",
    "                if results[recording_id][len(results[recording_id]) - 1]['speaker_id'] == results[recording_id][len(results[recording_id]) - 3]['speaker_id']:\n",
    "                    if results[recording_id][len(results[recording_id]) - 1]['speaker_id'] != results[recording_id][len(results[recording_id]) - 2]['speaker_id']:\n",
    "                        results[recording_id][len(results[recording_id]) - 2]['speaker_id'] = results[recording_id][len(results[recording_id]) - 1]['speaker_id']\n",
    "                        results[recording_id][len(results[recording_id]) - 1]['modified'] = True\n",
    "        results_reduced[recording_id] = []\n",
    "        last_speaker_id = -1\n",
    "        last_speaker = { 'begining': 0, 'ending': 0, 'speaker_id': -1 }\n",
    "        for segment in results[recording_id] + [{ 'begining': 0, 'ending': 0, 'speaker_id': -1 }]:\n",
    "            begining = segment['begining']\n",
    "            ending = segment['ending']\n",
    "            speaker_id = segment['speaker_id']\n",
    "            if last_speaker_id != speaker_id:\n",
    "                if last_speaker_id != -1:\n",
    "                    results_reduced[recording_id].append(last_speaker)\n",
    "                last_speaker_id = speaker_id\n",
    "                last_speaker = { 'begining': begining, 'ending': ending, 'speaker_id': speaker_id }\n",
    "            else:\n",
    "                if begining <= last_speaker['ending']:\n",
    "                    last_speaker['ending'] = ending\n",
    "                else:\n",
    "                    if last_speaker_id != -1:\n",
    "                        results_reduced[recording_id].append(last_speaker)\n",
    "                    last_speaker_id = speaker_id\n",
    "                    last_speaker = { 'begining': begining, 'ending': ending, 'speaker_id': speaker_id }\n",
    "        for scores_labels in results_scores[recording_id]:\n",
    "            for score_label in scores_labels:\n",
    "                # ('iaab_000-00000000-00000099', 'iaab_B', 'target', 0.9978078)\n",
    "                eer_score = '{:f}'.format(score_label[3]) + ' ' + score_label[2]\n",
    "                eer_scores += eer_score + '\\n'\n",
    "                dcf_score = score_label[0] + ' ' + score_label[1] + ' ' + '{:f}'.format(score_label[3])\n",
    "                dcf_scores += dcf_score + '\\n'\n",
    "                dcf_trial = score_label[0] + ' ' + score_label[1] + ' '+ score_label[2]\n",
    "                dcf_trials += dcf_trial + '\\n'\n",
    "        for segment in results_reduced[recording_id]:\n",
    "            result_rttm = 'SPEAKER ' + recording_id + ' 0 ' + str(segment['begining']) + ' ' + str(round(segment['ending'] - segment['begining'], 2)) + ' <NA> <NA> ' + str(segment['speaker_id']) + ' <NA> <NA>'\n",
    "            results_rttm += result_rttm + '\\n'\n",
    "    print('traking done: recording', str(i + 1) + '/' + str(len(recordings_ids)), '          ')\n",
    "\n",
    "    file = open(groundtruth_filepath, 'r')\n",
    "    groundtruth_rttm = ''.join([line for line in file.readlines() if (line.split(' ')[1] in recordings_ids) and \\\n",
    "                    (line.split(' ')[7] in ['A', 'B'])])\n",
    "    file.close()\n",
    "    \n",
    "    !mkdir -p tmp\n",
    "    \n",
    "    file = open('tmp/eer.scores', 'w')\n",
    "    file.write(eer_scores)\n",
    "    file.close()\n",
    "    \n",
    "    file = open('tmp/dcf.scores', 'w')\n",
    "    file.write(dcf_scores)\n",
    "    file.close()\n",
    "    \n",
    "    file = open('tmp/dcf.trials', 'w')\n",
    "    file.write(dcf_trials)\n",
    "    file.close()\n",
    "    \n",
    "    file = open('tmp/groundtruth.rttm', 'w')\n",
    "    file.write(groundtruth_rttm)\n",
    "    file.close()\n",
    "    \n",
    "    file = open('tmp/results.rttm', 'w')\n",
    "    file.write(results_rttm)\n",
    "    file.close()\n",
    "\n",
    "    return { \n",
    "            'der': md_eval('tmp/groundtruth.rttm', 'tmp/results.rttm'),\n",
    "            'eer': eer('notebooks/tmp/eer.scores'),\n",
    "            'dcf': dcf('tmp/dcf.scores', 'tmp/dcf.trials')\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading recordings segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_directory = '../exp/pre_norm/callhome1/json'\n",
    "b_directory = '../exp/pre_norm/callhome2/json'\n",
    "maximum_speakers_length = 2\n",
    "valid_speakers_ids = ['A', 'B']\n",
    "include_overlaps = False\n",
    "vector = 'ivectors'\n",
    "vector_length = 128\n",
    "models_container_length = 2\n",
    "models_container_include_zeros = True\n",
    "models_container_include_overlaps = False\n",
    "models_generation_length = 4\n",
    "models_generation_selection = 'first'\n",
    "balance_segments_selection = 'copy'\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../exp/pre_norm/callhome1/json loaded 249/249, 0.74 segments left.\n",
      "../exp/pre_norm/callhome2/json loaded 250/250, 0.77 segments left.\n"
     ]
    }
   ],
   "source": [
    "a_recordings_segments = load_recordings_segments(a_directory,\n",
    "                                                 lambda segment: is_valid_segment(segment, maximum_speakers_length, valid_speakers_ids))\n",
    "b_recordings_segments = load_recordings_segments(b_directory,\n",
    "                                                 lambda segment: is_valid_segment(segment, maximum_speakers_length, valid_speakers_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recordings left: 241/249\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training.27/1027          \n"
     ]
    }
   ],
   "source": [
    "a_trainer = Trainer()\n",
    "a_net = a_trainer.get_net(balance_segments(a_recordings_segments, \n",
    "                                           maximum_speakers_length,\n",
    "                                           models_generation_length,\n",
    "                                           include_overlaps),\n",
    "                          vector = vector,\n",
    "                          vector_length = vector_length,\n",
    "                          models_container_length = models_container_length,\n",
    "                          models_container_include_zeros = models_container_include_zeros,\n",
    "                          models_container_include_overlaps = models_container_include_overlaps,\n",
    "                          models_generation_lengths = [models_generation_length],\n",
    "                          models_generation_selection = models_generation_selection,\n",
    "                          balance_segments_selection = balance_segments_selection,\n",
    "                          batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_selector(vector, models_container, net):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    with torch.no_grad():\n",
    "        input = [torch.Tensor([nparray]).to(device, non_blocking = True).float() for nparray in [vector] + models_container]\n",
    "        output = net(input)\n",
    "        return output.cpu().data.numpy()[0]\n",
    "    \n",
    "def plda_selector(vector, models_container, plda_filepath):\n",
    "    return [plda_score(ref_vector, vector, plda_filepath) for ref_vector in models_container]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../exp/pre_norm/callhome2/json loaded 250/250, 0.7 segments left.\n"
     ]
    }
   ],
   "source": [
    "b_recordings_segments = load_recordings_segments(b_directory,\n",
    "                                                 lambda segment: is_single_speaker_segment(segment, ['A', 'B']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traking done: recording 250/250           \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'der': 6.39, 'eer': 5.493, 'dcf': 0.6015}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_tester(b_recordings_segments,\n",
    "                scoring_function = lambda vector, models_container: net_selector(vector, models_container, a_net),\n",
    "                groundtruth_filepath = '../data/callhome2_1.0_0.5.rttm',\n",
    "                groundtruth_valid_speakers_ids = ['A', 'B'],\n",
    "                vector = vector,\n",
    "                models_container_length = models_container_length,\n",
    "                models_container_include_overlaps = models_container_include_overlaps,\n",
    "                models_generation_length = models_generation_length,\n",
    "                models_generation_selection = models_generation_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traking done: recording 250/250           \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'der': 7.93, 'eer': 18.24, 'dcf': 0.9063}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_tester(b_recordings_segments,\n",
    "                scoring_function = lambda vector, models_container: plda_selector(vector,\n",
    "                                                                                  models_container,\n",
    "                                                                                  'exp/plda/callhome1/ivectors.plda'),\n",
    "                groundtruth_filepath = '../data/callhome2_1.0_0.5.rttm',\n",
    "                groundtruth_valid_speakers_ids = ['A', 'B'],\n",
    "                vector = vector,\n",
    "                models_container_length = models_container_length,\n",
    "                models_container_include_overlaps = models_container_include_overlaps,\n",
    "                models_generation_length = models_generation_length,\n",
    "                models_generation_selection = models_generation_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
