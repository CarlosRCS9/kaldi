{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recordings segments loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from functools import reduce\n",
    "\n",
    "# is_valid_segment [VALIDATED]\n",
    "# validates that a segment meets a maximum number of speakers,\n",
    "# and that all the speakers in the segment belong to a list.\n",
    "def is_valid_segment(segment, maximum_speakers_length = 2, valid_speakers_ids = ['A', 'B']):\n",
    "    speakers_ids = [speaker['speaker_id'] for speaker in segment['speakers']]\n",
    "    speakers_ids = list(set(speakers_ids))\n",
    "    return len(speakers_ids) <= maximum_speakers_length and \\\n",
    "        all(speaker_id in valid_speakers_ids for speaker_id in speakers_ids)\n",
    "\n",
    "# load_recordings_segments [VALIDATED]\n",
    "# loads the recordings segments data from the .json files located in a directory \n",
    "def load_recordings_segments(directory, maximum_speakers_length = 2, valid_speakers_ids = ['A', 'B']):\n",
    "    filenames = [filename for filename in os.listdir(directory) if os.path.isfile(os.path.join(directory, filename))]\n",
    "    filenames.sort()\n",
    "    recordings_segments = {}\n",
    "    recordings_length = len(filenames)\n",
    "    recordings_count = 0\n",
    "    segments_original = 0\n",
    "    segments_filtered = 0\n",
    "    for filename in filenames:\n",
    "        recording_id = filename.split('.')[0]\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        file = open(filepath, 'r')\n",
    "        recordings_segments[recording_id] = [json.loads(line) for line in file.readlines()]\n",
    "        file.close()\n",
    "        segments_original += len(recordings_segments[recording_id])\n",
    "        recordings_segments[recording_id] = list(filter(lambda segment: is_valid_segment(segment, maximum_speakers_length, valid_speakers_ids), recordings_segments[recording_id]))\n",
    "        segments_filtered += len(recordings_segments[recording_id])\n",
    "        recordings_count += 1\n",
    "        print(directory + ' loading ' + str(recordings_count) + '/' + str(recordings_length), end = '\\r')\n",
    "    print(directory, 'loaded', str(recordings_count) + '/' + str(recordings_length) + ',', round(segments_filtered / segments_original, 2), 'segments left.')\n",
    "    return recordings_segments\n",
    "\n",
    "# speakers_get_indexes [VALIDATED]\n",
    "# used to convert a (speakers_ids, index) list to a speakers_ids => [indexes] dictionary\n",
    "def speakers_get_indexes(accumulator, speakers_tuple):\n",
    "    speaker_ids, index = speakers_tuple\n",
    "    speaker_ids = ','.join(speaker_ids)\n",
    "    if speaker_ids in accumulator:\n",
    "        accumulator[speaker_ids].append(index)\n",
    "    else:\n",
    "        accumulator[speaker_ids] = [index]\n",
    "    return accumulator\n",
    "\n",
    "# balance_segments [VALIDATED]\n",
    "# balances the recording segments data to meet a minimum of speakers per recording,\n",
    "# and a minimum of segments per speaker.\n",
    "def balance_segments(recordings_segments,\n",
    "                     minimum_speakers_length = 2,\n",
    "                     minimum_speaker_segments = 3,\n",
    "                     include_overlaps = False):\n",
    "    new_recordings_segments = {}\n",
    "    for recording_id in recordings_segments:\n",
    "        recording_segments = recordings_segments[recording_id]\n",
    "        # ----- Obtaining speakers indexes ----- #\n",
    "        speakers_indexes = [(sorted(list(set([speaker['speaker_id'] for speaker in segment['speakers']]))), index) for index, segment in enumerate(recording_segments)]\n",
    "        speakers_indexes = reduce(speakers_get_indexes, speakers_indexes, {})\n",
    "        # ----- Removing overlaps ----- #\n",
    "        if not include_overlaps:\n",
    "            for speakers_ids in list(speakers_indexes.keys()):\n",
    "                if len(speakers_ids.split(',')) > 1:\n",
    "                    del speakers_indexes[speakers_ids]\n",
    "        speakers_lengths = [(speakers_ids, len(speakers_indexes[speakers_ids])) for speakers_ids in speakers_indexes]\n",
    "        speakers_lengths.sort(key = lambda x: x[1])\n",
    "        speakers_lengths_min = speakers_lengths[0][1]\n",
    "        if len(speakers_lengths) >= minimum_speakers_length and speakers_lengths_min >= minimum_speaker_segments:\n",
    "            recording_indexes = []\n",
    "            for speakers_ids in speakers_indexes:\n",
    "                speakers_indexes[speakers_ids] = speakers_indexes[speakers_ids][:speakers_lengths_min]\n",
    "                recording_indexes += speakers_indexes[speakers_ids]\n",
    "            new_recordings_segments[recording_id] = [segment for index, segment in enumerate(recordings_segments[recording_id]) if index in recording_indexes]\n",
    "    print('Recordings left: ' + str(len(new_recordings_segments)) + '/' + str(len(recordings_segments)))\n",
    "    return new_recordings_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recordings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def generate_speaker_model(recording_segments,\n",
    "                           speaker_indexes,\n",
    "                           segments_length,\n",
    "                           vector = 'ivectors',\n",
    "                           selection = 'first',\n",
    "                           indexes = []):\n",
    "    #if segments_length > len(speaker_indexes):\n",
    "    #    print('WARNING: there are less speaker indexes than segments.')\n",
    "    if selection == 'first':\n",
    "        selected_segments = [segment for index, segment in enumerate(recording_segments) if index in speaker_indexes[:segments_length]]\n",
    "    elif selection == 'random':\n",
    "        selected_segments = [recording_segments[index] for index in random.sample(speaker_indexes, segments_length if segments_length < len(speaker_indexes) else len(speaker_indexes))]\n",
    "    elif selection == 'indexes':\n",
    "        selected_segments = [recording_segments[index] for index in indexes]\n",
    "    else:\n",
    "        print('ERROR: unknown speaker model segments selection strategy.')\n",
    "    selected_vectors = [np.asarray(segment[vector][0]['value']) for segment in selected_segments]\n",
    "    return np.sum(selected_vectors, 0) / len(selected_vectors)\n",
    "    \n",
    "\n",
    "class Recordings_dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 recordings_segments,\n",
    "                 recordings_ids = None,\n",
    "                 vector = 'ivectors',\n",
    "                 models_container_length = 2,\n",
    "                 models_container_include_zeros = True,\n",
    "                 models_container_include_overlaps = False,\n",
    "                 models_generation_lengths = [3],\n",
    "                 models_generation_selection = 'first',\n",
    "                 balance_segments = True,\n",
    "                 balance_segments_selection = 'copy'):\n",
    "        # -----------------------------------------------------Saving input data----- #\n",
    "        if recordings_ids is None:\n",
    "            recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "        self.recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "        self.recordings_segments = {}\n",
    "        for recording_id in self.recordings_ids:\n",
    "            self.recordings_segments[recording_id] = recordings_segments[recording_id]\n",
    "        self.vector = vector\n",
    "        self.models_container_length = models_container_length\n",
    "        self.models_container_include_zeros = models_container_include_zeros\n",
    "        self.models_container_include_overlaps = models_container_include_overlaps\n",
    "        self.models_generation_lengths = models_generation_lengths\n",
    "        self.models_generation_selection = models_generation_selection\n",
    "        self.balance_segments = balance_segments\n",
    "        self.balance_segments_selection = balance_segments_selection\n",
    "        # --------------------------------------------------------------------------- #\n",
    "        self.recordings_data = {}\n",
    "        # -------------------------------------------------- #\n",
    "        self.recordings_map = []\n",
    "        self.recordings_length = 0\n",
    "        for recording_id in self.recordings_ids:\n",
    "            self.recordings_data[recording_id] = {}\n",
    "            recording_segments = self.recordings_segments[recording_id]\n",
    "            recording_data = self.recordings_data[recording_id]\n",
    "            # ----- Obtaining speakers indexes ----- #\n",
    "            recording_data['speakers_indexes'] = [(sorted(list(set([speaker['speaker_id'] for speaker in segment['speakers']]))), index) for index, segment in enumerate(recording_segments)]\n",
    "            recording_data['speakers_indexes'] = reduce(speakers_get_indexes, recording_data['speakers_indexes'], {})\n",
    "            # ----- Balancing speakers segments ----- #\n",
    "            recording_data['speakers_indexes_lengths_max'] = max([len(recording_data['speakers_indexes'][speakers_ids]) for speakers_ids in recording_data['speakers_indexes']])\n",
    "            if self.balance_segments:\n",
    "                if self.balance_segments_selection == 'copy':\n",
    "                    for speakers_ids in recording_data['speakers_indexes']:\n",
    "                        for i in range(recording_data['speakers_indexes_lengths_max'] - len(recording_data['speakers_indexes'][speakers_ids])):\n",
    "                            index = random.choice(recording_data['speakers_indexes'][speakers_ids])\n",
    "                            recording_segments.append(recording_segments[index])\n",
    "                            recording_data['speakers_indexes'][speakers_ids].append(len(recording_segments) - 1)\n",
    "                else:\n",
    "                    print('ERROR: unknown balancing segments selection strategy.')\n",
    "            # ----- Generating speakers models ----- #\n",
    "            recording_data['speakers_models'] = {}\n",
    "            for speakers_ids in recording_data['speakers_indexes']:\n",
    "                recording_data['speakers_models'][speakers_ids] = {}\n",
    "                for models_generation_length in models_generation_lengths:\n",
    "                    speakers_model = generate_speaker_model(recording_segments, recording_data['speakers_indexes'][speakers_ids], models_generation_length, self.vector, self.models_generation_selection)\n",
    "                    recording_data['speakers_models'][speakers_ids][models_generation_length] = [speakers_model]\n",
    "            # ----- Generating permutations ----- #\n",
    "            if self.models_container_include_zeros:\n",
    "                recording_data['permutations'] = list(itertools.permutations(list(recording_data['speakers_models'].keys()) \\\n",
    "                + ['0' for i in range(self.models_container_length)], self.models_container_length))\n",
    "            else:\n",
    "                recording_data['permutations'] = list(itertools.permutations(list(recording_data['speakers_models'].keys()), self.models_container_length))\n",
    "            recording_data['permutations'] = list(set(recording_data['permutations']))\n",
    "            recording_data['permutations'].sort()\n",
    "            if not self.models_container_include_overlaps:\n",
    "                recording_data['permutations'] = [permutation for permutation in recording_data['permutations'] if all(len(speakers_ids.split(',')) == 1 for speakers_ids in permutation)]\n",
    "            # -------------------------------------------------- #\n",
    "            recording_data['permutations_map'] = []\n",
    "            recording_data['permutations_length'] = 0\n",
    "            for index, permutation in enumerate(recording_data['permutations']):\n",
    "                speakers_models_length = int(np.prod([np.sum([len(recording_data['speakers_models'][speakers_ids][models_generation_length]) for models_generation_length in recording_data['speakers_models'][speakers_ids]]) for speakers_ids in permutation if speakers_ids != '0']))\n",
    "                recording_data['permutations_map'].append((recording_data['permutations_length'], recording_data['permutations_length'] + speakers_models_length - 1, index))\n",
    "                recording_data['permutations_length'] += speakers_models_length\n",
    "            recording_data['length'] = len(recording_segments) * recording_data['permutations_length']\n",
    "            self.recordings_map.append((self.recordings_length, self.recordings_length + recording_data['length'] - 1, recording_id))\n",
    "            self.recordings_length += recording_data['length']\n",
    "    def __len__(self):\n",
    "        return self.recordings_length\n",
    "    def __getitem__(self, idx):\n",
    "        recording_limits = list(filter(lambda recording_limits: recording_limits[0] <= idx and idx <= recording_limits[1], self.recordings_map))[0]\n",
    "        recording_idx = idx - recording_limits[0]\n",
    "        recording_id = recording_limits[2]\n",
    "        recording_data = self.recordings_data[recording_id]\n",
    "        \n",
    "        segment_index, segment_idx = divmod(recording_idx, recording_data['permutations_length'])\n",
    "        segment = self.recordings_segments[recording_id][segment_index]\n",
    "        vector = np.asarray(segment[self.vector][0]['value'])\n",
    "        \n",
    "        permutation_limits = list(filter(lambda permutation_limits: permutation_limits[0] <= segment_idx and segment_idx <= permutation_limits[1], recording_data['permutations_map']))[0]\n",
    "        permutation_idx = segment_idx - permutation_limits[0]\n",
    "        permutation_index = permutation_limits[2]\n",
    "        permutation = recording_data['permutations'][permutation_index]\n",
    "        \n",
    "        speakers_models_lengths = [np.sum([len(recording_data['speakers_models'][speakers_ids][models_generation_length]) for models_generation_length in recording_data['speakers_models'][speakers_ids]])  if speakers_ids != '0' else 1 for speakers_ids in permutation]\n",
    "        models_container = []\n",
    "        model_index = permutation_idx\n",
    "        for i, length_i in enumerate(speakers_models_lengths):\n",
    "            if i != len(speakers_models_lengths) - 1:\n",
    "                model_index, remainder = divmod(model_index, np.sum(speakers_models_lengths[i + 1:]))\n",
    "            else:\n",
    "                model_index = remainder\n",
    "            models_container.append(recording_data['speakers_models'][permutation[i]][self.models_generation_lengths[model_index]][0] if permutation[i] != '0' else np.random.uniform(-0.1, 0.1, len(vector)))\n",
    "        \n",
    "        models_weigths = np.asarray([len(recording_data['speakers_indexes'][speakers_ids]) if speakers_ids != '0' else recording_data['speakers_indexes_lengths_max'] for speakers_ids in permutation])\n",
    "        models_weigths_sum = np.sum(models_weigths)\n",
    "        models_weigths = np.ones(len(models_weigths)) - models_weigths / models_weigths_sum\n",
    "        \n",
    "        targets_ids = [speaker['speaker_id'] for speaker in segment['speakers']]\n",
    "        \n",
    "        x = [vector] + models_container\n",
    "        if self.models_container_include_overlaps:\n",
    "            targets_ids = ','.join(sorted(list(set(targets_ids))))\n",
    "            y = np.asarray([speakers_ids == targets_ids for speakers_ids in permutation], dtype = float)\n",
    "        else:\n",
    "            y = np.asarray([speaker_id in targets_ids for speaker_id in permutation], dtype = float) / len(targets_ids)\n",
    "        z = models_weigths\n",
    "        \n",
    "        return x, y, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load live_graph.py\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Live_graph:\n",
    "    def __init__(self, validation_threshold):\n",
    "        self.plt_count = -1\n",
    "        self.validation_threshold = validation_threshold\n",
    "        self.plt_thr = ([self.plt_count], [self.validation_threshold])\n",
    "        self.plt_loss = ([self.plt_count], [1])\n",
    "        self.plt_valid = ([self.plt_count], [1])\n",
    "        self.plt_test = ([self.plt_count], [1])\n",
    "        self.fig = plt.figure()\n",
    "        self.ax = self.fig.add_subplot()\n",
    "        self.line0, = self.ax.plot(self.plt_thr[0], self.plt_thr[1], 'k--', label = 'Threshold') # Threshold line\n",
    "        self.line1, = self.ax.plot(self.plt_loss[0], self.plt_loss[1], '--', label = 'Training') # Training loss\n",
    "        self.line2, = self.ax.plot(self.plt_valid[0], self.plt_valid[1], label = 'Validation')   # Validation loss\n",
    "        self.line3, = self.ax.plot(self.plt_test[0], self.plt_test[1], label = 'Test')           # Test loss\n",
    "        self.ax.set_xlabel('Epoch')\n",
    "        self.ax.set_ylabel('Loss')\n",
    "        self.ax.legend()\n",
    "        self.ax.set_xlim(-1, 0)\n",
    "        self.ax.set_ylim(0, 0.5)\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.canvas.flush_events()\n",
    "    def step(self, training, validation, test = -1):\n",
    "        self.plt_count += 1\n",
    "        self.plt_thr[0].append(self.plt_count)\n",
    "        self.plt_thr[1].append(self.validation_threshold)\n",
    "        self.plt_loss[0].append(self.plt_count)\n",
    "        self.plt_loss[1].append(training)\n",
    "        self.plt_valid[0].append(self.plt_count)\n",
    "        self.plt_valid[1].append(validation)\n",
    "        self.plt_test[0].append(self.plt_count)\n",
    "        self.plt_test[1].append(test)\n",
    "        self.line0.set_xdata(self.plt_thr[0])\n",
    "        self.line0.set_ydata(self.plt_thr[1])\n",
    "        self.line1.set_xdata(self.plt_loss[0])\n",
    "        self.line1.set_ydata(self.plt_loss[1])\n",
    "        self.line2.set_xdata(self.plt_valid[0])\n",
    "        self.line2.set_ydata(self.plt_valid[1])\n",
    "        self.line3.set_xdata(self.plt_test[0])\n",
    "        self.line3.set_ydata(self.plt_test[1])\n",
    "        self.ax.set_xlim(0, self.plt_count + 1)\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.canvas.flush_events()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, models_container_length, vector_length):\n",
    "        super().__init__()\n",
    "        n = models_container_length\n",
    "        m = vector_length\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv1d((n + 1), n ** 3, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(n ** 3, n ** 2, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(n ** 2, n, 3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(n * (m - 6), n * 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n * 16, n * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n * 4, n),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = torch.stack(input, 1)\n",
    "        x = self.cnn1(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self):\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device('cuda:0')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "    def get_net(self,\n",
    "                recordings_segments,\n",
    "                recordings_ids = None,\n",
    "                vector = 'ivectors',\n",
    "                vector_length = 128,\n",
    "                models_container_length = 2,\n",
    "                models_container_include_zeros = True,\n",
    "                models_container_include_overlaps = False,\n",
    "                models_generation_lengths = [3],\n",
    "                models_generation_selection = 'first',\n",
    "                balance_segments = True,\n",
    "                balance_segments_selection = 'copy',\n",
    "                batch_size = 16,\n",
    "                num_workers = 8,\n",
    "                test_recordings_segments = None):\n",
    "        \n",
    "        if recordings_ids is None:\n",
    "            recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "        self.recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "\n",
    "        train_dataset = Recordings_dataset(recordings_segments,\n",
    "                                           recordings_ids, \n",
    "                                           vector,\n",
    "                                           models_container_length,\n",
    "                                           models_container_include_zeros,\n",
    "                                           models_container_include_overlaps,\n",
    "                                           models_generation_lengths,\n",
    "                                           models_generation_selection,\n",
    "                                           balance_segments,\n",
    "                                           balance_segments_selection)\n",
    "\n",
    "        train_length = int(len(train_dataset) * 0.7)\n",
    "        valid_length = len(train_dataset) - train_length\n",
    "\n",
    "        train_dataset, valid_dataset = random_split(train_dataset, [train_length, valid_length])\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers = num_workers)\n",
    "        valid_dataloader = DataLoader(valid_dataset, batch_size = batch_size, num_workers = num_workers)\n",
    "        \n",
    "        if test_recordings_segments is not None:\n",
    "            test_recordings_ids = [recording_id for recording_id in test_recordings_segments]\n",
    "            test_dataset = Recordings_dataset(test_recordings_segments,\n",
    "                                              test_recordings_ids,\n",
    "                                              vector,\n",
    "                                              models_container_length,\n",
    "                                              models_container_include_zeros,\n",
    "                                              models_container_include_overlaps,\n",
    "                                              models_generation_lengths,\n",
    "                                              models_generation_selection,\n",
    "                                              balance_segments,\n",
    "                                              balance_segments_selection)\n",
    "            test_dataloader = DataLoader(test_dataset, batch_size = batch_size, num_workers = num_workers)\n",
    "\n",
    "        net = Net(models_container_length, vector_length).to(self.device)\n",
    "        optimizer = optim.Adam(net.parameters(), lr = 0.0001)\n",
    "\n",
    "        epochs = 50\n",
    "        validation_threshold = 0.08\n",
    "\n",
    "        live_graph = Live_graph(validation_threshold)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_losses = []\n",
    "            for input, target, weigth in train_dataloader:\n",
    "                input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                target = target.to(self.device, non_blocking = True).float()\n",
    "                weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                criterion = nn.BCELoss(weigth)\n",
    "                net.zero_grad()\n",
    "                output = net(input)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_losses.append(loss.data)\n",
    "                print('train: ' + str(len(train_losses)) + '/' + str(len(train_dataloader)) + '          ', end = '\\r')\n",
    "            train_loss = np.sum(train_losses) / len(train_losses)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                validation_losses = []\n",
    "                for input, target, weigth in valid_dataloader:\n",
    "                    input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                    target = target.to(self.device, non_blocking = True).float()\n",
    "                    weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                    criterion = nn.BCELoss(weigth)\n",
    "                    output = net(input)\n",
    "                    loss = criterion(output, target)\n",
    "                    validation_losses.append(loss.data)\n",
    "                    print('validation: ' + str(len(validation_losses)) + '/' + str(len(valid_dataloader)) + '          ', end = '\\r')\n",
    "                validation_loss = np.sum(validation_losses) / len(validation_losses)\n",
    "                \n",
    "                test_loss = -1\n",
    "                if test_recordings_segments is not None:\n",
    "                    test_losses = []\n",
    "                    for input, target, weigth in test_dataloader:\n",
    "                        input = [tensor.to(self.device, non_blocking = True).float() for tensor in input]\n",
    "                        target = target.to(self.device, non_blocking = True).float()\n",
    "                        weigth = weigth.to(self.device, non_blocking = True).float()\n",
    "\n",
    "                        criterion = nn.BCELoss(weigth)\n",
    "                        output = net(input)\n",
    "                        loss = criterion(output, target)\n",
    "                        test_losses.append(loss.data)\n",
    "                        print('test: ' + str(len(test_losses)) + '/' + str(len(test_dataloader)) + '          ', end = '\\r')\n",
    "                    test_loss = np.sum(test_losses) / len(test_losses)\n",
    "\n",
    "            live_graph.step(train_loss, validation_loss, test_loss)\n",
    "\n",
    "            if validation_loss <= validation_threshold:\n",
    "                print('Done training.')\n",
    "                break\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load md_eval.py\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "def md_eval(ref_filepath, res_filepath, save_filepath = None):\n",
    "    bin = '../../../../tools/sctk-2.4.10/src/md-eval/md-eval.pl'\n",
    "    p = subprocess.Popen([bin, '-r', ref_filepath, '-s', res_filepath], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output, err = p.communicate()\n",
    "    rc = p.returncode\n",
    "    if rc == 0:\n",
    "        output = output.decode(\"utf-8\")\n",
    "        if save_filepath is not None:\n",
    "            file = open(save_filepath, 'w')\n",
    "            file.write(output)\n",
    "            file.close()\n",
    "        lines =  output.split('\\n')\n",
    "        derLine = [line for line in lines if 'OVERALL SPEAKER DIARIZATION ERROR' in line][0]\n",
    "        return float(re.findall('\\d+\\.\\d+', derLine)[0])\n",
    "    else:\n",
    "        exit('md-eval.pl fail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracking_tester(recordings_segments,\n",
    "                    recordings_ids = None,\n",
    "                    selection_function = None,\n",
    "                    groundtruth_filepath = '',\n",
    "                    groundtruth_valid_speakers_ids = ['A', 'B'],\n",
    "                    vector = 'ivectors',\n",
    "                    models_container_length = 2,\n",
    "                    models_container_include_overlaps = False,\n",
    "                    models_generation_length = 3,\n",
    "                    models_generation_selection = 'first'):\n",
    "\n",
    "    if recordings_ids is None:\n",
    "        recordings_ids = [recording_id for recording_id in recordings_segments]\n",
    "    recordings_ids = recordings_ids if isinstance(recordings_ids, list) else [recordings_ids]\n",
    "    recordings_ids.sort()\n",
    "    \n",
    "    results = {}\n",
    "    results_reduced = {}\n",
    "    results_rttm = ''\n",
    "    for recording_id in recordings_ids:\n",
    "        recording_dataset = Recordings_dataset(recordings_segments,\n",
    "                                               recording_id,\n",
    "                                               vector = vector,\n",
    "                                               models_container_length = models_container_length,\n",
    "                                               models_container_include_zeros = False,\n",
    "                                               models_container_include_overlaps = models_container_include_overlaps,\n",
    "                                               models_generation_lengths = [models_generation_length],\n",
    "                                               models_generation_selection = models_generation_selection,\n",
    "                                               balance_segments = False,\n",
    "                                               balance_segments_selection = 'copy')\n",
    "        speakers_models = recording_dataset.recordings_data[recording_id]['speakers_models']\n",
    "        models_container = [speakers_models[speakers_ids][models_generation_length][0] for speakers_ids in speakers_models if models_container_include_overlaps or len(speakers_ids.split(',')) == 1]\n",
    "        for i in range(models_container_length - len(models_container)):\n",
    "            models_container.append(np.random.uniform(-0.1, 0.1, len(models_container[0])))\n",
    "        # At this point there is no information about the speaker identity, only the model\n",
    "        results[recording_id] = []\n",
    "        for segment in recordings_segments[recording_id]:\n",
    "            segment_vector = np.asarray(segment[vector][0]['value'])\n",
    "            selection = selection_function(segment_vector, models_container)\n",
    "            index = np.argmax(selection)\n",
    "            results[recording_id].append({ 'begining': segment['begining'], 'ending': segment['ending'], 'speaker_id': index })\n",
    "            if len(results[recording_id]) > 2:\n",
    "                if results[recording_id][len(results[recording_id]) - 1]['speaker_id'] == results[recording_id][len(results[recording_id]) - 3]['speaker_id']:\n",
    "                    if results[recording_id][len(results[recording_id]) - 1]['speaker_id'] != results[recording_id][len(results[recording_id]) - 2]['speaker_id']:\n",
    "                        results[recording_id][len(results[recording_id]) - 2]['speaker_id'] = results[recording_id][len(results[recording_id]) - 1]['speaker_id']\n",
    "                        results[recording_id][len(results[recording_id]) - 1]['modified'] = True\n",
    "        results_reduced[recording_id] = []\n",
    "        last_speaker_id = -1\n",
    "        last_speaker = { 'begining': 0, 'ending': 0, 'speaker_id': -1 }\n",
    "        for segment in results[recording_id] + [{ 'begining': 0, 'ending': 0, 'speaker_id': -1 }]:\n",
    "            begining = segment['begining']\n",
    "            ending = segment['ending']\n",
    "            speaker_id = segment['speaker_id']\n",
    "            if last_speaker_id != speaker_id:\n",
    "                if last_speaker_id != -1:\n",
    "                    results_reduced[recording_id].append(last_speaker)\n",
    "                last_speaker_id = speaker_id\n",
    "                last_speaker = { 'begining': begining, 'ending': ending, 'speaker_id': speaker_id }\n",
    "            else:\n",
    "                if begining <= last_speaker['ending']:\n",
    "                    last_speaker['ending'] = ending\n",
    "                else:\n",
    "                    if last_speaker_id != -1:\n",
    "                        results_reduced[recording_id].append(last_speaker)\n",
    "                    last_speaker_id = speaker_id\n",
    "                    last_speaker = { 'begining': begining, 'ending': ending, 'speaker_id': speaker_id }\n",
    "        for segment in results_reduced[recording_id]:\n",
    "            result_rttm = 'SPEAKER ' + recording_id + ' 0 ' + str(segment['begining']) + ' ' + str(round(segment['ending'] - segment['begining'], 2)) + ' <NA> <NA> ' + str(segment['speaker_id']) + ' <NA> <NA>'\n",
    "            results_rttm += result_rttm + '\\n'\n",
    "\n",
    "    file = open(groundtruth_filepath, 'r')\n",
    "    groundtruth_rttm = ''.join([line for line in file.readlines() if (line.split(' ')[1] in recordings_ids) and \\\n",
    "                    (line.split(' ')[7] in ['A', 'B'])])\n",
    "    file.close()\n",
    "    \n",
    "    file = open('jupyter_groundtruth.rttm', 'w')\n",
    "    file.write(groundtruth_rttm)\n",
    "    file.close()\n",
    "    \n",
    "    file = open('jupyter_results.rttm', 'w')\n",
    "    file.write(results_rttm)\n",
    "    file.close()\n",
    "\n",
    "    return md_eval('jupyter_groundtruth.rttm', 'jupyter_results.rttm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading recordings segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_directory = '../exp/pre_norm/callhome1/json'\n",
    "b_directory = '../exp/pre_norm/cal<lhome2/json'\n",
    "maximum_speakers_length = 2\n",
    "valid_speakers_ids = ['A', 'B']\n",
    "models_generation_length = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../exp/pre_norm/callhome1/json loaded 249/249, 0.74 segments left.\n"
     ]
    }
   ],
   "source": [
    "a_recordings_segments = load_recordings_segments(a_directory, maximum_speakers_length, valid_speakers_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../exp/pre_norm/callhome2/json loaded 250/250, 0.77 segments left.\n"
     ]
    }
   ],
   "source": [
    "b_recordings_segments = load_recordings_segments(b_directory, maximum_speakers_length, valid_speakers_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recordings left: 221/249\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training.09/1009          \n"
     ]
    }
   ],
   "source": [
    "a_trainer = Trainer()\n",
    "a_net = a_trainer.get_net(balance_segments(a_recordings_segments, 2, 10, False),\n",
    "                          vector = 'ivectors',\n",
    "                          vector_length = 128,\n",
    "                          models_container_length = 2,\n",
    "                          models_container_include_zeros = True,\n",
    "                          models_container_include_overlaps = False,\n",
    "                          models_generation_lengths = [models_generation_length],\n",
    "                          models_generation_selection = 'first',\n",
    "                          balance_segments = False,\n",
    "                          balance_segments_selection = 'copy',\n",
    "                          batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_valid_segment [DONE]\n",
    "def is_valid_segment(segment):\n",
    "    return len(segment['speakers']) == 1 \\\n",
    "            and len(segment['ivectors']) == 1 \\\n",
    "            and len(segment['xvectors']) == 1 \\\n",
    "            and segment['speakers'][0]['speaker_id'] in ['A', 'B']\n",
    "\n",
    "# load_recordings_segments [DONE]\n",
    "def load_recordings_segments(directory):\n",
    "    filenames = [filename for filename in os.listdir(directory) if os.path.isfile(os.path.join(directory, filename))]\n",
    "    recordings_segments = {}\n",
    "    recordings_length = len(filenames)\n",
    "    recordings_count = 0\n",
    "    for filename in filenames:\n",
    "        recording_id = filename.split('.')[0]\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        file = open(filepath, 'r')\n",
    "        recordings_segments[recording_id] = [json.loads(line) for line in file.readlines()]\n",
    "        file.close()\n",
    "        recordings_segments[recording_id] = list(filter(is_valid_segment, recordings_segments[recording_id]))\n",
    "        recordings_count += 1\n",
    "        print('Loading ' + directory + ' ' + str(recordings_count) + '/' + str(recordings_length), end = '\\r')\n",
    "    return recordings_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_selector(vector, models_container, net):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    with torch.no_grad():\n",
    "        input = [torch.Tensor([nparray]).to(device, non_blocking = True).float() for nparray in [vector] + models_container]\n",
    "        output = net(input)\n",
    "        return output.cpu().data.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../exp/pre_norm/callhome2/json 250/250\r"
     ]
    }
   ],
   "source": [
    "b_recordings_segments = load_recordings_segments(b_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.34"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_tester(b_recordings_segments, None,\n",
    "                lambda vector, models_container: net_selector(vector, models_container, a_net),\n",
    "                '../data/callhome2_1.0_0.5.rttm',\n",
    "                ['A', 'B'],\n",
    "                models_generation_length = models_generation_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
