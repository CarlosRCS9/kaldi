{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from copy import copy\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'ivectors'\n",
    "class Data:\n",
    "    def __init__(self, segment, oracle_models):\n",
    "        self.x = segment[mode][0]['value']\n",
    "        oracle_speakers = [oracle_model['speaker_id'] for oracle_model in oracle_models]\n",
    "        for oracle_model in oracle_models:\n",
    "            self.x  = numpy.concatenate((self.x, oracle_model[mode][0]))\n",
    "        self.y = numpy.asarray([oracle_speaker == segment['speakers'][0]['speaker_id'] for oracle_speaker in oracle_speakers], dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'exp/json'\n",
    "files = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "data = []\n",
    "for f in files:\n",
    "    # Getting data from json\n",
    "    f = open(os.path.join(folder, f))\n",
    "    recording = json.loads(f.readline())\n",
    "    # Removing multiple-speaker segments\n",
    "    recording['segments'] = [segment for segment in recording['segments'] if len(segment['speakers']) == 1]\n",
    "    # Removing extra speakers\n",
    "    recording['segments'] = [segment for segment in recording['segments'] if segment['speakers'][0]['speaker_id'] in ['A', 'B']]\n",
    "    # Dealing with multiple-vector segments and generating IDs\n",
    "    new_segments = []\n",
    "    new_segments_count = 0\n",
    "    for segment in recording['segments']:\n",
    "        for i in range(len(segment['ivectors'])):\n",
    "            new_segment = copy(segment)\n",
    "            new_segment['segment_id'] = str(new_segments_count).zfill(3)\n",
    "            new_segments_count += 1\n",
    "            new_segment['ivectors'] = [segment['ivectors'][i]]\n",
    "            new_segment['xvectors'] = [segment['xvectors'][i]]\n",
    "            new_segments.append(new_segment)\n",
    "    recording['segments'] = new_segments\n",
    "    # Lists to Numpy arrays\n",
    "    for segment in recording['segments']:\n",
    "        segment['ivectors'][0]['value'] = numpy.asarray(segment['ivectors'][0]['value'])\n",
    "        segment['xvectors'][0]['value'] = numpy.asarray(segment['xvectors'][0]['value'])\n",
    "    # Getting speakers list\n",
    "    speakers = list(set([segment['speakers'][0]['speaker_id'] for segment in recording['segments']]))\n",
    "    if len(speakers) == 2:\n",
    "        # Getting speakers oracle models\n",
    "        oracle_limit = 5\n",
    "        oracle_segments = [[segment for segment in recording['segments'] if segment['speakers'][0]['speaker_id'] == speaker][:oracle_limit] for speaker in speakers]\n",
    "        oracle_models = []\n",
    "        for n, speaker_n in enumerate(speakers):\n",
    "            ivector_n = oracle_segments[n][0]['ivectors'][0]['value']\n",
    "            xvector_n = oracle_segments[n][0]['xvectors'][0]['value']\n",
    "            for segment in oracle_segments[n][1:]:\n",
    "                ivector_n = ivector_n + segment['ivectors'][0]['value']\n",
    "                xvector_n = xvector_n + segment['xvectors'][0]['value']\n",
    "            ivector_n = ivector_n / len(oracle_segments[n])\n",
    "            xvector_n = xvector_n / len(oracle_segments[n])\n",
    "            oracle_models.append({ 'speaker_id': speaker_n, 'ivectors': [ivector_n], 'xvectors': [xvector_n] })\n",
    "        # Generating dataset\n",
    "        for segment in recording['segments']:\n",
    "            data.append(Data(segment, oracle_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc0 = nn.Linear(128 * 3, 384)\n",
    "        self.fc1 = nn.Linear(384, 384)\n",
    "        self.fc2 = nn.Linear(384, 384)\n",
    "        self.fc3 = nn.Linear(384, 192)\n",
    "        self.fc4 = nn.Linear(192, 192)\n",
    "        self.fc5 = nn.Linear(192, 192)\n",
    "        self.fc6 = nn.Linear(192, 96)\n",
    "        self.fc7 = nn.Linear(96, 2)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc0(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = self.fc7(x)\n",
    "        x = F.log_softmax(x, dim = 1)\n",
    "        return x'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.5956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.5598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.5599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.6470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.5598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.5597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.5598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.5598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.5597, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "'''import torch.optim as optim\n",
    "\n",
    "net = Net().cuda()\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.0001)\n",
    "\n",
    "def custom_loss(input, target):\n",
    "    return ((input - target) ** 2).sum() / input.data.nelement()\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for entry in data:\n",
    "        x = torch.FloatTensor(entry.x).cuda()\n",
    "        y = torch.FloatTensor(entry.y).cuda()\n",
    "        net.zero_grad()\n",
    "        output = net(x.view(-1, 128 * 3))\n",
    "        loss = custom_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
