{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obteniendo los índices de segmentos válidos por audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_segment(line):\n",
    "    segment = json.loads(line)\n",
    "    return len(segment['speakers']) == 1 \\\n",
    "            and segment['speakers'][0]['speaker_id'] in ['A', 'B'] \\\n",
    "            and len(segment['ivectors']) == 1 \\\n",
    "            and len(segment['xvectors']) == 1\n",
    "\n",
    "directory = 'exp/json'\n",
    "filenames = [filename for filename in os.listdir(directory) if os.path.isfile(os.path.join(directory, filename))]\n",
    "filenames.sort()\n",
    "recordings = {}\n",
    "for filename in filenames:\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    file = open(filepath)\n",
    "    indexes = [index for index, line in enumerate(file.readlines()) if is_valid_segment(line)]\n",
    "    file.close()\n",
    "    recording_id = filename.split('.')[0]\n",
    "    recordings[recording_id] = {}\n",
    "    recordings[recording_id]['recording_id'] = recording_id\n",
    "    recordings[recording_id]['filepath'] = filepath\n",
    "    recordings[recording_id]['indexes'] = indexes\n",
    "    recordings[recording_id]['indexes_length'] = len(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obteniendo los índices de locutores por audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_segments_limit = 2\n",
    "for recording_id in recordings:\n",
    "    recording = recordings[recording_id]\n",
    "    file = open(recording['filepath'])\n",
    "    segments = [(idx, json.loads(line)) for idx, line in enumerate(file.readlines()) if idx in recording['indexes']]\n",
    "    file.close()\n",
    "    recording['speakers_indexes'] = {}\n",
    "    for idx, segment in segments:\n",
    "        speaker_id = segment['speakers'][0]['speaker_id']\n",
    "        if speaker_id in recording['speakers_indexes']:\n",
    "            if len(recording['speakers_indexes'][speaker_id]) < speaker_segments_limit:\n",
    "                recording['speakers_indexes'][speaker_id].append(idx)\n",
    "        else:\n",
    "            recording['speakers_indexes'][speaker_id] = [idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obteniendo la longitud de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy\n",
    "\n",
    "models_container_size = 5\n",
    "recordings_length = 0\n",
    "recordings_map = []\n",
    "\n",
    "for recording_id in recordings:\n",
    "    recording = recordings[recording_id]\n",
    "    speakers_ids = list(recording['speakers_indexes'].keys())\n",
    "    permutations = list(itertools.permutations(speakers_ids + ['0' for i in range(models_container_size)], models_container_size))\n",
    "    permutations = list(set(permutations))\n",
    "    recording['permutations'] = permutations\n",
    "    permutations_length = 0\n",
    "    permutations_map = []\n",
    "    for idx, permutation in enumerate(permutations):\n",
    "        length = int(numpy.prod([len(recording['speakers_indexes'][speaker_id]) for speaker_id in permutation if speaker_id in recording['speakers_indexes']]))\n",
    "        permutations_map.append((permutations_length, permutations_length + length - 1, idx))\n",
    "        permutations_length += length\n",
    "    recording['permutations_length'] = permutations_length\n",
    "    recording['permutations_map'] = permutations_map\n",
    "    recording_length = permutations_length * recording['indexes_length']\n",
    "    recording['recording_length'] = recording_length\n",
    "    recordings_map.append((recordings_length, recordings_length + recording_length - 1, recording_id))\n",
    "    recordings_length += recording_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "class Recordings_dataset(Dataset):\n",
    "    def __init__(self, recordings, recordings_length, recordings_map, mode = 'ivectors'):\n",
    "        self.recordings = recordings\n",
    "        self.recordings_length = recordings_length\n",
    "        self.recordings_map = recordings_map\n",
    "        self.mode = mode\n",
    "    def __len__(self):\n",
    "        return self.recordings_length\n",
    "    def __getitem__(self, idx):\n",
    "        recording_tuple = list(filter(lambda recording_tuple: recording_tuple[0] <= idx and idx <= recording_tuple[1], self.recordings_map))[0]\n",
    "        recording_idx = idx - recording_tuple[0]\n",
    "        recording_id = recording_tuple[2] ###\n",
    "        recording = self.recordings[recording_id]\n",
    "        \n",
    "        segment_idx, remainder = divmod(recording_idx, recording['permutations_length'])\n",
    "        segment_id = recording['indexes'][segment_idx] ###\n",
    "        \n",
    "        permutation_tuple = list(filter(lambda permutation_tuple: permutation_tuple[0] <= remainder and remainder <= permutation_tuple[1], recording['permutations_map']))[0]\n",
    "        permutation_idx = remainder - permutation_tuple[0]\n",
    "        permutation_id = permutation_tuple[2] ###\n",
    "        permutation = recording['permutations'][permutation_id]\n",
    "                \n",
    "        models_container = []\n",
    "        for i, speaker_i in enumerate(permutation):\n",
    "            if speaker_i != '0':\n",
    "                else_length = int(numpy.prod([len(recording['speakers_indexes'][speaker_id]) for speaker_id in permutation[i + 1:] if speaker_id != '0']))\n",
    "                permutation_idx, remainder = divmod(permutation_idx, else_length)\n",
    "                models_container.append(recording['speakers_indexes'][speaker_i][permutation_idx])\n",
    "                permutation_idx = remainder\n",
    "            else:\n",
    "                models_container.append(-1)\n",
    "                \n",
    "        file = open(recording['filepath'])\n",
    "        lines = file.readlines()\n",
    "        file.close()\n",
    "                \n",
    "        segment = json.loads(lines[segment_id])\n",
    "        segment_vector = numpy.asarray(segment[self.mode][0]['value'])\n",
    "        models_container = [numpy.zeros(len(segment_vector)) if segment_id == -1 else numpy.asarray(json.loads(lines[segment_id])[self.mode][0]['value']) for segment_id in models_container]\n",
    "        permutation = numpy.asarray([speaker_id == segment['speakers'][0]['speaker_id'] for speaker_id in permutation], dtype = float)\n",
    "        \n",
    "        x = numpy.concatenate([segment_vector] + models_container)\n",
    "        y = permutation\n",
    "                \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3094915\n"
     ]
    }
   ],
   "source": [
    "recordings_dataset = Recordings_dataset(recordings, recordings_length, recordings_map)\n",
    "print(len(recordings_dataset))\n",
    "train_length = int(len(recordings_dataset) * 0.7)\n",
    "test_length = len(recordings_dataset) - train_length\n",
    "train_dataset, test_dataset = random_split(recordings_dataset, [train_length, test_length])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 10, shuffle=True, num_workers = 4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = 1, shuffle=False, num_workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc0 = nn.Linear(128 * (models_container_size + 1), 512)\n",
    "        self.fc1 = nn.Linear(512, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.fc4 = nn.Linear(512, 512)\n",
    "        self.fc5 = nn.Linear(512, 512)\n",
    "        self.fc6 = nn.Linear(512, 512)\n",
    "        self.fc7 = nn.Linear(512, models_container_size)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc0(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = F.sigmoid(self.fc7(x))\n",
    "        return x\n",
    "    \n",
    "net = Net().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4098, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\r"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.01)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.MSELoss()\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    for input, target in train_dataloader:\n",
    "        input = input.to('cuda', non_blocking=True)\n",
    "        target = target.to('cuda', non_blocking=True)\n",
    "        net.zero_grad()\n",
    "        output = net(input.float())\n",
    "        loss = criterion(output, target.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss, end = '\\r')\n",
    "    if (loss < 0.3):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for input, target in test_dataloader:\n",
    "        input = input.to('cuda', non_blocking=True)\n",
    "        output = net(input.float())\n",
    "        print('target:', target)\n",
    "        print('output:', output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
